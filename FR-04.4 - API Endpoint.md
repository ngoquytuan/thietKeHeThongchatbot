Náº¿u Ä‘Ã£ Ä‘á»§ thÃ´ng tin hÃ£y giÃºp tÃ´i viáº¿t tÃ i liá»‡u thiáº¿t káº¿ module dÆ°á»›i Ä‘Ã¢y.
TÃ i liá»‡u nÃ y cung cáº¥p roadmap Ä‘áº§y Ä‘á»§ Ä‘á»ƒ implement FR-04.4 mÃ  khÃ´ng cáº§n code cá»¥ thá»ƒ nhÆ°ng 
cÃ³ cÃ¡c bÆ°á»›c lÃ m cá»¥ thá»ƒ nhÆ° chuáº©n bá»‹ mÃ´i trÆ°á»ng PC tháº¿ nÃ o, pháº§n má»m gÃ¬?
 Ä‘á»ƒ Team ká»¹ thuáº­t cÃ³ thá»ƒ follow step-by-step guide nÃ y Ä‘á»ƒ thiáº¿t káº¿ tá»‘i Æ°u cho há»‡ thá»‘ng chatbot
 vÃ  cÃ³ mermaidchart luá»“ng cÃ´ng viá»‡c, Ä‘iá»ƒm quay Ä‘áº§u khi bá»‹ fail.

### 3.4 Module RAG Core Engine (FR-04)

**FR-04.4 - API Endpoint**
- `/api/ask` - Endpoint chÃ­nh cho chatbot
- Input: user_query, user_id, session_id
- Output: answer, references, confidence_score
---

# TÃ€I LIá»†U THIáº¾T Káº¾ MODULE RAG CORE ENGINE
## API ENDPOINT IMPLEMENTATION GUIDE (FR-04.4)

---

**Module:** RAG Core Engine - API Endpoint  
**Feature ID:** FR-04.4  
**PhiÃªn báº£n:** 1.0  
**NgÃ y táº¡o:** 01/09/2025  
**NgÆ°á»i soáº¡n tháº£o:** Technical Architecture Team  

---

## ğŸ“‹ **Má»¤C Lá»¤C**
1. [Tá»•ng quan Module](#1-tá»•ng-quan-module)
2. [Kiáº¿n trÃºc API Endpoint](#2-kiáº¿n-trÃºc-api-endpoint)
3. [Chuáº©n bá»‹ MÃ´i trÆ°á»ng PhÃ¡t triá»ƒn](#3-chuáº©n-bá»‹-mÃ´i-trÆ°á»ng-phÃ¡t-triá»ƒn)
4. [Roadmap Implementation](#4-roadmap-implementation)
5. [Luá»“ng xá»­ lÃ½ chi tiáº¿t](#5-luá»“ng-xá»­-lÃ½-chi-tiáº¿t)
6. [Error Handling & Recovery](#6-error-handling--recovery)
7. [Testing Strategy](#7-testing-strategy)
8. [Monitoring & Performance](#8-monitoring--performance)

---

## 1. **Tá»”NG QUAN MODULE**

### 1.1 MÃ´ táº£ chá»©c nÄƒng
API Endpoint `/api/ask` lÃ  trÃ¡i tim cá»§a há»‡ thá»‘ng RAG, xá»­ lÃ½ táº¥t cáº£ cÃ¡c yÃªu cáº§u tá»« chatbot frontend vÃ  tráº£ vá» cÃ¢u tráº£ lá»i thÃ´ng minh dá»±a trÃªn tri thá»©c ná»™i bá»™.

### 1.2 Input/Output Specification

**ğŸ“¥ INPUT:**
```json
{
  "user_query": "Quy trÃ¬nh mua hÃ ng trÃ¬nh giÃ¡m Ä‘á»‘c nhÆ° tháº¿ nÃ o?",
  "user_id": "emp001", 
  "session_id": "sess_20250901_001",
  "department": "rd",
  "language": "vi",
  "context_history": ["previous_question_1", "previous_question_2"],
  "max_results": 5,
  "include_citations": true
}
```

**ğŸ“¤ OUTPUT:**
```json
{
  "status": "success",
  "answer": "Quy trÃ¬nh mua hÃ ng trÃ¬nh giÃ¡m Ä‘á»‘c gá»“m 5 bÆ°á»›c chÃ­nh...",
  "references": [
    {
      "doc_id": "proc_001",
      "title": "Quy trÃ¬nh Mua hÃ ng CÃ´ng ty",
      "chunk_text": "BÆ°á»›c 1: Táº¡o yÃªu cáº§u mua hÃ ng trong há»‡ thá»‘ng...",
      "confidence_score": 0.95,
      "page_number": 3,
      "section": "2.1 Quy trÃ¬nh cÆ¡ báº£n"
    }
  ],
  "confidence_score": 0.89,
  "response_time_ms": 2340,
  "session_id": "sess_20250901_001",
  "cached": false,
  "fallback_used": false
}
```

### 1.3 Performance Requirements
- **Response Time**: < 60 seconds (target: < 10 seconds)
- **Throughput**: 100 concurrent requests
- **Availability**: 99.5% uptime
- **Accuracy**: â‰¥80% relevant responses

---

## 2. **KIáº¾N TRÃšC API ENDPOINT**

### 2.1 Component Architecture

```mermaid
graph TB
    subgraph "ğŸŒ API Layer"
        FastAPI[âš¡ FastAPI Server<br/>Python 3.11+]
        Router[ğŸ›¤ï¸ API Router<br/>/api/ask endpoint]
        Validator[âœ… Request Validator<br/>Pydantic models]
        Auth[ğŸ” Authentication<br/>JWT + RBAC]
    end
    
    subgraph "ğŸ§  RAG Processing Layer" 
        Orchestrator[ğŸ¯ RAG Orchestrator<br/>Main business logic]
        
        subgraph "Query Processing"
            QueryProcessor[ğŸ” Query Processor<br/>NLP preprocessing]
            IntentDetector[ğŸ¯ Intent Detector<br/>Question classification]
        end
        
        subgraph "Document Retrieval"
            VectorSearch[ğŸ“Š Vector Search<br/>Semantic similarity]
            PermissionFilter[ğŸ›¡ï¸ Permission Filter<br/>Access control]
            ResultRanker[ğŸ“ˆ Result Ranker<br/>Relevance scoring]
        end
        
        subgraph "Response Generation"
            ContextBuilder[ğŸ§© Context Builder<br/>Prompt construction]
            LLMCaller[ğŸ¤– LLM Caller<br/>External API calls]
            ResponseParser[ğŸ“ Response Parser<br/>Extract answer + citations]
        end
    end
    
    subgraph "ğŸ’¾ Data Layer"
        VectorDB[(ğŸ”¢ Vector Database)]
        PostgreSQL[(ğŸ˜ PostgreSQL)]
        Redis[(ğŸ”´ Redis Cache)]
    end
    
    subgraph "ğŸŒ External Services"
        OpenAI[ğŸ§  OpenAI API]
        Claude[ğŸ¤– Anthropic Claude]
        LocalLLM[ğŸ  Local LLM]
    end
    
    %% Flow
    Router --> Validator
    Validator --> Auth
    Auth --> Orchestrator
    
    Orchestrator --> QueryProcessor
    QueryProcessor --> IntentDetector
    IntentDetector --> VectorSearch
    VectorSearch --> PermissionFilter
    PermissionFilter --> ResultRanker
    
    ResultRanker --> ContextBuilder
    ContextBuilder --> LLMCaller
    LLMCaller --> ResponseParser
    ResponseParser --> Orchestrator
    
    %% Data connections
    VectorSearch -.-> VectorDB
    PermissionFilter -.-> PostgreSQL
    Orchestrator -.-> Redis
    
    %% External connections  
    LLMCaller -.-> OpenAI
    LLMCaller -.-> Claude
    LLMCaller -.-> LocalLLM
    
    %% Styling
    classDef api fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef processing fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef data fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef external fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    class FastAPI,Router,Validator,Auth api
    class Orchestrator,QueryProcessor,IntentDetector,VectorSearch,PermissionFilter,ResultRanker,ContextBuilder,LLMCaller,ResponseParser processing
    class VectorDB,PostgreSQL,Redis data
    class OpenAI,Claude,LocalLLM external
```

---

## 3. **CHUáº¨N Bá»Š MÃ”I TRÆ¯á»œNG PHÃT TRIá»‚N**

### 3.1 Hardware Requirements

| Component | Minimum | Recommended | Optimal |
|-----------|---------|-------------|---------|
| **CPU** | 8 cores | 16 cores | 32 cores |
| **RAM** | 16GB | 32GB | 64GB |
| **Storage** | 500GB SSD | 1TB NVMe SSD | 2TB NVMe SSD |
| **GPU** | None | RTX 3080 (12GB) | RTX 4090 (24GB) |
| **Network** | 1Gbps | 10Gbps | 10Gbps+ |

### 3.2 Software Stack Setup

#### 3.2.1 Operating System
```bash
# Ubuntu 22.04 LTS (Recommended)
sudo apt update && sudo apt upgrade -y
sudo apt install build-essential curl wget git -y
```

#### 3.2.2 Python Environment
```bash
# Python 3.11+ vá»›i pyenv
curl https://pyenv.run | bash
pyenv install 3.11.5
pyenv global 3.11.5

# Poetry cho dependency management  
curl -sSL https://install.python-poetry.org | python3 -
```

#### 3.2.3 Database Setup
```bash
# PostgreSQL 15+
sudo apt install postgresql-15 postgresql-contrib-15
sudo systemctl enable postgresql
sudo systemctl start postgresql

# Redis 7+
sudo apt install redis-server
sudo systemctl enable redis-server
sudo systemctl start redis-server
```

#### 3.2.4 Vector Database
```bash
# Option 1: Chroma (Recommended for development)
pip install chromadb

# Option 2: FAISS (For production)
conda install faiss-cpu  # or faiss-gpu

# Option 3: Weaviate (Docker)
docker run -p 8080:8080 semitechnologies/weaviate:latest
```

#### 3.2.5 Development Tools
```bash
# Docker & Docker Compose
sudo apt install docker.io docker-compose-v2
sudo usermod -aG docker $USER

# VS Code vá»›i Python extensions
wget -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor > packages.microsoft.gpg
sudo install -o root -g root -m 644 packages.microsoft.gpg /etc/apt/trusted.gpg.d/
```

### 3.3 Project Structure
```
rag-core-engine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ settings.py      # Environment configs
â”‚   â”‚   â””â”€â”€ database.py      # DB connections
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ ask.py       # /api/ask endpoint
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ request.py   # Pydantic request models
â”‚   â”‚   â”‚   â””â”€â”€ response.py  # Pydantic response models
â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ auth.py      # Authentication
â”‚   â”‚       â””â”€â”€ cors.py      # CORS handling
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag_orchestrator.py    # Main RAG logic
â”‚   â”‚   â”œâ”€â”€ query_processor.py     # Query preprocessing
â”‚   â”‚   â”œâ”€â”€ vector_search.py       # Vector operations
â”‚   â”‚   â”œâ”€â”€ permission_service.py  # Access control
â”‚   â”‚   â”œâ”€â”€ llm_service.py         # LLM integrations
â”‚   â”‚   â””â”€â”€ cache_service.py       # Redis operations
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ security.py      # JWT, password hashing
â”‚   â”‚   â”œâ”€â”€ logging.py       # Structured logging
â”‚   â”‚   â””â”€â”€ exceptions.py    # Custom exceptions
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ embeddings.py    # Embedding utilities
â”‚       â”œâ”€â”€ text_processing.py
â”‚       â””â”€â”€ monitoring.py    # Metrics collection
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py         # Pytest configurations
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ api_spec.yaml       # OpenAPI specification
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_dev.sh        # Development setup
â”‚   â”œâ”€â”€ run_tests.sh        # Test runner
â”‚   â””â”€â”€ deploy.sh           # Deployment script
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ .dockerignore
â”œâ”€â”€ pyproject.toml          # Poetry dependencies
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## 4. **ROADMAP IMPLEMENTATION**

### 4.1 Timeline Overview (8 tuáº§n)

| Phase | Duration | Tasks | Deliverables |
|-------|----------|-------|--------------|
| **Phase 1: Foundation** | Week 1-2 | Setup + Core Structure | Working API skeleton |
| **Phase 2: Core Logic** | Week 3-4 | RAG components | Basic query processing |
| **Phase 3: Integration** | Week 5-6 | LLM + Vector DB | End-to-end flow |
| **Phase 4: Optimization** | Week 7-8 | Performance + Testing | Production-ready API |

### 4.2 Phase-by-Phase Implementation

#### **ğŸ—ï¸ Phase 1: Foundation Setup (Week 1-2)**

**Week 1: Environment & Project Structure**
- [ ] Day 1-2: Setup development environment theo section 3
- [ ] Day 3: Initialize project structure
- [ ] Day 4: Setup FastAPI basic app vá»›i health check
- [ ] Day 5: Configure logging, metrics, database connections

**Week 2: API Framework**  
- [ ] Day 1-2: Implement Pydantic request/response models
- [ ] Day 3: Setup authentication middleware (JWT)
- [ ] Day 4: Implement basic /api/ask endpoint (mock response)
- [ ] Day 5: Add CORS, rate limiting, request validation

**ğŸ¯ Deliverable:** Working API server vá»›i basic endpoint

#### **ğŸ§  Phase 2: Core RAG Logic (Week 3-4)**

**Week 3: Query Processing**
- [ ] Day 1-2: Implement QueryProcessor (text cleaning, intent detection)
- [ ] Day 2-3: Build VectorSearch service (connect to vector DB)
- [ ] Day 4: Implement PermissionFilter (RBAC logic)
- [ ] Day 5: Create ResultRanker (relevance scoring)

**Week 4: Response Generation**
- [ ] Day 1-2: Build ContextBuilder (prompt engineering)
- [ ] Day 3: Implement LLMService (OpenAI/Claude integration)
- [ ] Day 4: Create ResponseParser (extract answer + citations)
- [ ] Day 5: Integrate all components trong RAGOrchestrator

**ğŸ¯ Deliverable:** Complete RAG processing pipeline

#### **ğŸ”— Phase 3: System Integration (Week 5-6)**

**Week 5: Database Integration**
- [ ] Day 1-2: Connect PostgreSQL cho metadata vÃ  user management
- [ ] Day 3: Integrate Redis cho caching vÃ  session
- [ ] Day 4: Setup vector database (Chroma/FAISS)  
- [ ] Day 5: Test end-to-end data flow

**Week 6: LLM & External Services**
- [ ] Day 1-2: Implement multiple LLM providers (fallback logic)
- [ ] Day 3: Add embeddings service integration
- [ ] Day 4: Build retry mechanisms vÃ  circuit breakers
- [ ] Day 5: Comprehensive integration testing

**ğŸ¯ Deliverable:** Fully integrated system vá»›i real data

#### **âš¡ Phase 4: Production Optimization (Week 7-8)**

**Week 7: Performance & Reliability**
- [ ] Day 1-2: Implement advanced caching strategies
- [ ] Day 3: Add async processing cho heavy operations
- [ ] Day 4: Optimize database queries vÃ  vector search
- [ ] Day 5: Load testing vÃ  performance tuning

**Week 8: Final Polish**
- [ ] Day 1-2: Comprehensive error handling
- [ ] Day 3: Security audit vÃ  penetration testing
- [ ] Day 4: Documentation hoÃ n thiá»‡n
- [ ] Day 5: Production deployment preparation

**ğŸ¯ Deliverable:** Production-ready API endpoint

---

## 5. **LUá»’NG Xá»¬ LÃ CHI TIáº¾T**

### 5.1 Main Processing Flow

```mermaid
flowchart TD
    Start([ğŸš€ API Request Received]) --> Validate{âœ… Request Valid?}
    
    Validate -->|âŒ No| ValidationError[ğŸš¨ Return 400<br/>Validation Error]
    Validate -->|âœ… Yes| Auth{ğŸ” Authenticated?}
    
    Auth -->|âŒ No| AuthError[ğŸš¨ Return 401<br/>Unauthorized]
    Auth -->|âœ… Yes| CheckCache{ğŸ’¾ Cache Hit?}
    
    CheckCache -->|âœ… Yes| CacheReturn[âš¡ Return Cached<br/>Response]
    CheckCache -->|âŒ No| QueryProcess[ğŸ” Process Query]
    
    QueryProcess --> IntentDetect[ğŸ¯ Detect Intent]
    IntentDetect --> VectorSearch[ğŸ“Š Vector Search]
    VectorSearch --> PermCheck{ğŸ›¡ï¸ Permission OK?}
    
    PermCheck -->|âŒ No| PermError[ğŸš¨ Return 403<br/>Forbidden]
    PermCheck -->|âœ… Yes| ResultsFound{ğŸ“‹ Results Found?}
    
    ResultsFound -->|âŒ No| NoResults[â“ No Results Found<br/>Fallback Response]
    ResultsFound -->|âœ… Yes| BuildContext[ğŸ§© Build Context]
    
    BuildContext --> CallLLM[ğŸ¤– Call LLM]
    CallLLM --> LLMSuccess{âœ… LLM Success?}
    
    LLMSuccess -->|âŒ No| LLMError{ğŸ”„ Retry Available?}
    LLMError -->|âœ… Yes| CallLLM
    LLMError -->|âŒ No| FallbackLLM[ğŸ”„ Try Fallback LLM]
    
    FallbackLLM --> FallbackSuccess{âœ… Fallback Success?}
    FallbackSuccess -->|âŒ No| GenericError[ğŸš¨ Return 503<br/>Service Unavailable]
    FallbackSuccess -->|âœ… Yes| ParseResponse[ğŸ“ Parse Response]
    
    LLMSuccess -->|âœ… Yes| ParseResponse
    ParseResponse --> ValidateResponse{âœ… Response Valid?}
    
    ValidateResponse -->|âŒ No| ResponseError[ğŸš¨ Return 500<br/>Invalid Response]
    ValidateResponse -->|âœ… Yes| CacheResponse[ğŸ’¾ Cache Response]
    
    CacheResponse --> LogMetrics[ğŸ“Š Log Metrics]
    LogMetrics --> Success[âœ¨ Return Success<br/>Response]
    
    %% Error flows lead to logging
    ValidationError --> LogError[ğŸ“ Log Error]
    AuthError --> LogError
    PermError --> LogError
    GenericError --> LogError
    ResponseError --> LogError
    LogError --> End([ğŸ End])
    
    %% Success flows
    CacheReturn --> End
    NoResults --> End
    Success --> End
    
    %% Styling
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    classDef process fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef error fill:#ffebee,stroke:#c62828,stroke-width:2px
    classDef success fill:#e0f2f1,stroke:#00796b,stroke-width:2px
    
    class Start,End startEnd
    class QueryProcess,IntentDetect,VectorSearch,BuildContext,CallLLM,ParseResponse,CacheResponse,LogMetrics,FallbackLLM process
    class Validate,Auth,CheckCache,PermCheck,ResultsFound,LLMSuccess,LLMError,FallbackSuccess,ValidateResponse decision
    class ValidationError,AuthError,PermError,GenericError,ResponseError,LogError error
    class CacheReturn,NoResults,Success success
```

### 5.2 Detailed Component Logic

#### **ğŸ” Query Processing Logic**
```python
# Pseudo-code for QueryProcessor
def process_query(user_query, user_context):
    # 1. Text normalization
    normalized_query = normalize_text(user_query)
    
    # 2. Intent detection  
    intent = detect_intent(normalized_query)
    
    # 3. Query expansion (if needed)
    if intent == "specific_search":
        expanded_query = expand_with_synonyms(normalized_query)
    else:
        expanded_query = normalized_query
    
    # 4. Generate embedding
    query_embedding = generate_embedding(expanded_query)
    
    return ProcessedQuery(
        original=user_query,
        normalized=normalized_query, 
        expanded=expanded_query,
        intent=intent,
        embedding=query_embedding
    )
```

#### **ğŸ“Š Vector Search Logic**
```python
# Pseudo-code for VectorSearch
def search_documents(processed_query, user_permissions, max_results=5):
    # 1. Semantic search
    semantic_results = vector_db.similarity_search(
        query_vector=processed_query.embedding,
        top_k=max_results * 2  # Get more for filtering
    )
    
    # 2. Permission filtering
    filtered_results = []
    for result in semantic_results:
        if check_permission(result.metadata, user_permissions):
            filtered_results.append(result)
        if len(filtered_results) >= max_results:
            break
    
    # 3. Re-ranking based on multiple factors
    ranked_results = rerank_results(
        results=filtered_results,
        query_intent=processed_query.intent,
        user_context=user_context
    )
    
    return ranked_results
```

#### **ğŸ§© Context Building Logic**
```python
# Pseudo-code for ContextBuilder
def build_context(search_results, user_query, conversation_history):
    # 1. Extract relevant chunks
    context_chunks = []
    for result in search_results:
        chunk = {
            'content': result.page_content,
            'metadata': result.metadata,
            'relevance_score': result.score
        }
        context_chunks.append(chunk)
    
    # 2. Build system prompt
    system_prompt = f"""
    Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» tri thá»©c ná»™i bá»™ cÃ´ng ty.
    HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p.
    Náº¿u khÃ´ng cÃ³ thÃ´ng tin phÃ¹ há»£p, hÃ£y nÃ³i ráº±ng báº¡n khÃ´ng biáº¿t.
    LuÃ´n Ä‘Æ°a ra trÃ­ch dáº«n tá»« tÃ i liá»‡u gá»‘c.
    """
    
    # 3. Build user prompt vá»›i context
    context_text = "\n\n".join([
        f"TÃ i liá»‡u {i+1}: {chunk['content']}" 
        for i, chunk in enumerate(context_chunks)
    ])
    
    user_prompt = f"""
    Ngá»¯ cáº£nh tÃ i liá»‡u:
    {context_text}
    
    CÃ¢u há»i: {user_query}
    
    Tráº£ lá»i:
    """
    
    return PromptContext(
        system_prompt=system_prompt,
        user_prompt=user_prompt,
        source_documents=context_chunks
    )
```

---

## 6. **ERROR HANDLING & RECOVERY**

### 6.1 Error Types & Recovery Strategies

```mermaid
flowchart TD
    Error([ğŸš¨ Error Occurred]) --> ErrorType{ğŸ” Error Type?}
    
    ErrorType -->|Network| NetworkError[ğŸŒ Network Error]
    ErrorType -->|LLM API| LLMError[ğŸ¤– LLM Error]  
    ErrorType -->|Database| DBError[ğŸ—„ï¸ Database Error]
    ErrorType -->|Permission| PermError[ğŸ›¡ï¸ Permission Error]
    ErrorType -->|Validation| ValidationError[âœ… Validation Error]
    ErrorType -->|System| SystemError[âš™ï¸ System Error]
    
    %% Network Error Recovery
    NetworkError --> NetworkRetry{ğŸ”„ Retry Count < 3?}
    NetworkRetry -->|Yes| WaitNetwork[â³ Exponential Backoff]
    WaitNetwork --> RetryNetwork[ğŸ”„ Retry Request]
    RetryNetwork --> NetworkSuccess{âœ… Success?}
    NetworkSuccess -->|No| NetworkRetry
    NetworkSuccess -->|Yes| LogSuccess[ğŸ“Š Log Success]
    NetworkRetry -->|No| NetworkFail[âŒ Return Network Error]
    
    %% LLM Error Recovery  
    LLMError --> LLMRetry{ğŸ”„ Primary LLM Failed?}
    LLMRetry -->|Yes| FallbackLLM[ğŸ”„ Try Backup LLM]
    FallbackLLM --> FallbackSuccess{âœ… Fallback Success?}
    FallbackSuccess -->|Yes| LogFallback[ğŸ“Š Log Fallback Used]
    FallbackSuccess -->|No| LocalLLM[ğŸ  Try Local LLM]
    LocalLLM --> LocalSuccess{âœ… Local Success?}
    LocalSuccess -->|Yes| LogLocal[ğŸ“Š Log Local Used]
    LocalSuccess -->|No| GenericResponse[ğŸ¤– Generic Response]
    
    %% Database Error Recovery
    DBError --> DBRetry{ğŸ”„ DB Connection Failed?}
    DBRetry -->|Yes| ReconnectDB[ğŸ”Œ Reconnect to DB]
    ReconnectDB --> ReadReplica{ğŸ“– Try Read Replica?}
    ReadReplica -->|Yes| ReplicaSuccess{âœ… Replica Success?}
    ReplicaSuccess -->|Yes| LogReplica[ğŸ“Š Log Replica Used]
    ReplicaSuccess -->|No| CacheOnly[ğŸ’¾ Use Cache Only]
    ReadReplica -->|No| CacheOnly
    CacheOnly --> CacheAvailable{ğŸ’¾ Cache Available?}
    CacheAvailable -->|Yes| ReturnCache[âš¡ Return Cached Data]
    CacheAvailable -->|No| DBUnavailable[âŒ DB Unavailable Error]
    
    %% Permission Error (No Recovery)
    PermError --> LogPermission[ğŸ“ Log Permission Denied]
    LogPermission --> Return403[ğŸš¨ Return 403 Forbidden]
    
    %% Validation Error (No Recovery)
    ValidationError --> LogValidation[ğŸ“ Log Validation Error]  
    LogValidation --> Return400[ğŸš¨ Return 400 Bad Request]
    
    %% System Error Recovery
    SystemError --> SystemRetry{ğŸ”„ System Resources?}
    SystemRetry -->|Available| RestartComponent[ğŸ”„ Restart Component]
    RestartComponent --> ComponentSuccess{âœ… Component OK?}
    ComponentSuccess -->|Yes| LogRestart[ğŸ“Š Log Component Restart]
    ComponentSuccess -->|No| SystemFail[âŒ System Failure]
    SystemRetry -->|Unavailable| SystemFail
    
    %% Success paths
    LogSuccess --> End([âœ… Success])
    LogFallback --> End
    LogLocal --> End  
    LogReplica --> End
    LogRestart --> End
    ReturnCache --> End
    GenericResponse --> End
    
    %% Failure paths
    NetworkFail --> Alert[ğŸš¨ Send Alert]
    DBUnavailable --> Alert
    SystemFail --> Alert
    Return403 --> End
    Return400 --> End
    Alert --> End([âŒ Failure])
    
    %% Styling
    classDef error fill:#ffebee,stroke:#c62828,stroke-width:2px
    classDef recovery fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef decision fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef success fill:#e0f2f1,stroke:#00796b,stroke-width:2px
    classDef failure fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    
    class Error,NetworkError,LLMError,DBError,PermError,ValidationError,SystemError error
    class WaitNetwork,RetryNetwork,FallbackLLM,LocalLLM,ReconnectDB,RestartComponent recovery
    class ErrorType,NetworkRetry,NetworkSuccess,LLMRetry,FallbackSuccess,LocalSuccess,DBRetry,ReadReplica,ReplicaSuccess,CacheAvailable,SystemRetry,ComponentSuccess decision
    class LogSuccess,LogFallback,LogLocal,LogReplica,LogRestart,ReturnCache,GenericResponse,End success
    class NetworkFail,DBUnavailable,SystemFail,Return403,Return400,Alert failure
```

### 6.2 Recovery Configuration

```python
# Error handling configuration
ERROR_CONFIG = {
    "network": {
        "max_retries": 3,
        "backoff_factor": 2,
        "timeout": 30
    },
    "llm": {
        "primary_timeout": 30,
        "fallback_providers": ["openai", "claude", "local"],
        "fallback_timeout": 60
    },
    "database": {
        "connection_retry": 3,
        "read_replica_fallback": True,
        "cache_fallback": True
    },
    "circuit_breaker": {
        "failure_threshold": 5,
        "timeout": 60,
        "expected_exception": ["ConnectionError", "Timeout"]
    }
}
```

### 6.3 Monitoring & Alerting Points

| Error Type | Alert Threshold | Action Required |
|------------|-----------------|-----------------|
| **Network Errors** | >5% in 5 minutes | Check network connectivity |
| **LLM Failures** | >10% in 10 minutes | Check API keys, quotas |
| **DB Connection** | Any failure | Immediate investigation |
| **Permission Denials** | >50 requests/hour | Review access policies |
| **System Resources** | >80% utilization | Scale infrastructure |

---

## 7. **TESTING STRATEGY**

### 7.1 Test Pyramid

```mermaid
graph TD
    subgraph "ğŸ§ª Testing Pyramid"
        E2E[ğŸŒ E2E Tests<br/>Full user journeys<br/>~10 tests]
        Integration[ğŸ”— Integration Tests<br/>Component interactions<br/>~50 tests]  
        Unit[âš™ï¸ Unit Tests<br/>Individual functions<br/>~200 tests]
    end
    
    subgraph "ğŸ¯ Test Categories"
        Functional[âœ… Functional Testing<br/>Feature correctness]
        Performance[âš¡ Performance Testing<br/>Speed & throughput]
        Security[ğŸ›¡ï¸ Security Testing<br/>Auth & permissions]
        Reliability[ğŸ”„ Reliability Testing<br/>Error handling]
    end
    
    subgraph "ğŸ› ï¸ Test Tools"
        PyTest[ğŸ PyTest<br/>Unit testing framework]
        FastAPI_Test[âš¡ FastAPI TestClient<br/>API testing]
        Locust[ğŸ¦— Locust<br/>Load testing]
        OWASP_ZAP[ğŸ›¡ï¸ OWASP ZAP<br/>Security scanning]
    end
    
    Unit --> Functional
    Integration --> Performance
    E2E --> Security
    E2E --> Reliability
    
    Functional --> PyTest
    Performance --> Locust
    Security --> OWASP_ZAP
    Reliability --> FastAPI_Test
    
    %% Styling
    classDef pyramid fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef category fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef tool fill:#fff3e0
---
### 7.2 Test Implementation Plan

#### **âš™ï¸ Unit Tests (200+ tests)**
```python
# Example test structure
def test_query_processor():
    """Test query normalization and intent detection"""
    processor = QueryProcessor()
    
    # Test text normalization
    result = processor.normalize_text("  QUY TRÃŒNH MUA HÃ€NG???  ")
    assert result == "quy trÃ¬nh mua hÃ ng"
    
    # Test intent detection
    intent = processor.detect_intent("LÃ m tháº¿ nÃ o Ä‘á»ƒ mua thiáº¿t bá»‹?")
    assert intent == "procedure_inquiry"

def test_permission_filter():
    """Test access control logic"""
    filter_service = PermissionFilter()
    user = User(role="employee", department="rd")
    
    # Should allow employee documents
    doc_metadata = {"access_level": "employee_only", "department": "rd"}
    assert filter_service.check_access(user, doc_metadata) == True
    
    # Should deny manager documents  
    doc_metadata = {"access_level": "manager_only"}
    assert filter_service.check_access(user, doc_metadata) == False
```

#### **ğŸ”— Integration Tests (50+ tests)**
```python
# Example integration test
@pytest.mark.integration
async def test_end_to_end_rag_flow():
    """Test complete RAG pipeline"""
    # Setup test data
    await setup_test_documents()
    
    # Create test request
    request = AskRequest(
        user_query="Quy trÃ¬nh mua hÃ ng nhÆ° tháº¿ nÃ o?",
        user_id="test_user",
        session_id="test_session"
    )
    
    # Call API
    response = await rag_orchestrator.process_request(request)
    
    # Verify response structure
    assert response.status == "success"
    assert len(response.references) > 0
    assert response.confidence_score > 0.5
    assert "mua hÃ ng" in response.answer.lower()
```

#### **âš¡ Performance Tests**
```python
# Locust performance test
class RAGPerformanceTest(HttpUser):
    wait_time = between(1, 3)
    
    def on_start(self):
        self.auth_token = self.get_auth_token()
    
    @task
    def test_ask_endpoint(self):
        headers = {"Authorization": f"Bearer {self.auth_token}"}
        payload = {
            "user_query": "Quy trÃ¬nh phÃª duyá»‡t Ä‘Æ¡n hÃ ng?",
            "user_id": "perf_user",
            "session_id": f"sess_{time.time()}"
        }
        
        with self.client.post(
            "/api/ask", 
            json=payload, 
            headers=headers,
            catch_response=True
        ) as response:
            if response.elapsed.total_seconds() > 60:
                response.failure("Response too slow")
            elif response.status_code != 200:
                response.failure(f"Bad status: {response.status_code}")
```

### 7.3 Test Data Management

```python
# Test fixtures and data
@pytest.fixture(scope="session")
async def test_database():
    """Setup test database with sample data"""
    # Create test PostgreSQL database
    test_db = await create_test_database()
    
    # Insert sample users
    await insert_test_users(test_db)
    
    # Insert sample documents  
    await insert_test_documents(test_db)
    
    yield test_db
    
    # Cleanup
    await cleanup_test_database(test_db)

@pytest.fixture
def sample_documents():
    """Sample document data for testing"""
    return [
        {
            "doc_id": "proc_001",
            "title": "Quy trÃ¬nh Mua hÃ ng",
            "content": "BÆ°á»›c 1: Táº¡o yÃªu cáº§u mua hÃ ng...",
            "access_level": "employee_only",
            "department": "all"
        },
        {
            "doc_id": "tech_001", 
            "title": "HÆ°á»›ng dáº«n Ká»¹ thuáº­t ÄÃ¨n hiá»‡u",
            "content": "ÄÃ¨n hiá»‡u sÃ¢n bay cÃ³ cÃ¡c loáº¡i...",
            "access_level": "employee_only",
            "department": "technical"
        }
    ]
```

### 7.4 Test Execution Pipeline

```bash
#!/bin/bash
# scripts/run_tests.sh

echo "ğŸ§ª Starting Test Pipeline..."

# 1. Unit Tests
echo "âš™ï¸ Running Unit Tests..."
poetry run pytest tests/unit/ -v --cov=app --cov-report=html

# 2. Integration Tests  
echo "ğŸ”— Running Integration Tests..."
poetry run pytest tests/integration/ -v --asyncio-mode=auto

# 3. API Tests
echo "ğŸŒ Running API Tests..."
poetry run pytest tests/api/ -v

# 4. Security Tests (if OWASP ZAP is available)
if command -v zap-baseline.py &> /dev/null; then
    echo "ğŸ›¡ï¸ Running Security Scan..."
    zap-baseline.py -t http://localhost:8000
fi

# 5. Performance Tests (optional)
if [ "$RUN_PERFORMANCE" = "true" ]; then
    echo "âš¡ Running Performance Tests..."
    locust -f tests/performance/locustfile.py --headless -u 10 -r 2 -t 60s --host=http://localhost:8000
fi

echo "âœ… All Tests Completed!"
```

---

## 8. **MONITORING & PERFORMANCE**

### 8.1 Key Metrics Dashboard

```mermaid
graph TB
    subgraph "ğŸ“Š Business Metrics"
        QPS[ğŸ“ˆ Queries Per Second<br/>Target: 100 QPS]
        ResponseTime[â±ï¸ Response Time<br/>P50: <5s, P95: <30s, P99: <60s]
        Accuracy[ğŸ¯ Accuracy Rate<br/>Target: >80%]
        UserSat[ğŸ˜Š User Satisfaction<br/>Target: >4.0/5.0]
    end
    
    subgraph "ğŸ”§ Technical Metrics"
        CPUUsage[ğŸ’» CPU Usage<br/>Target: <70%]
        MemoryUsage[ğŸ§  Memory Usage<br/>Target: <80%]
        DBConnections[ğŸ—„ï¸ DB Connections<br/>Monitor: Pool utilization]
        CacheHitRate[âš¡ Cache Hit Rate<br/>Target: >60%]
    end
    
    subgraph "ğŸš¨ Error Metrics"
        ErrorRate[âŒ Error Rate<br/>Target: <1%]
        LLMFailures[ğŸ¤– LLM Failures<br/>Target: <5%]
        TimeoutErrors[â° Timeout Errors<br/>Target: <2%]
        AuthFailures[ğŸ” Auth Failures<br/>Monitor: Security threats]
    end
    
    subgraph "ğŸ’° Cost Metrics"
        LLMCosts[ğŸ’¸ LLM API Costs<br/>Monitor: Usage trends]
        InfraCosts[ğŸ—ï¸ Infrastructure Costs<br/>Monitor: Resource efficiency]
        StorageCosts[ğŸ’¾ Storage Costs<br/>Monitor: Growth patterns]
    end
    
    %% Connections to monitoring systems
    QPS --> Grafana[ğŸ“Š Grafana Dashboard]
    ErrorRate --> AlertManager[ğŸš¨ Alert Manager]
    LLMCosts --> CostMonitor[ğŸ’° Cost Tracking]
    
    %% Styling
    classDef business fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef technical fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef error fill:#ffebee,stroke:#c62828,stroke-width:2px
    classDef cost fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef monitor fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    class QPS,ResponseTime,Accuracy,UserSat business
    class CPUUsage,MemoryUsage,DBConnections,CacheHitRate technical
    class ErrorRate,LLMFailures,TimeoutErrors,AuthFailures error
    class LLMCosts,InfraCosts,StorageCosts cost
    class Grafana,AlertManager,CostMonitor monitor
```

### 8.2 Monitoring Implementation

#### **ğŸ“Š Prometheus Metrics Collection**
```python
# app/utils/monitoring.py
from prometheus_client import Counter, Histogram, Gauge
import time

# Business metrics
rag_requests_total = Counter(
    'rag_requests_total', 
    'Total RAG requests',
    ['endpoint', 'status', 'user_type']
)

rag_response_time = Histogram(
    'rag_response_time_seconds',
    'RAG response time in seconds',
    ['endpoint', 'llm_provider']
)

rag_accuracy_score = Histogram(
    'rag_accuracy_score',
    'RAG response accuracy score',
    buckets=[0.1, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95, 1.0]
)

# Technical metrics
active_connections = Gauge(
    'active_db_connections',
    'Number of active database connections'
)

cache_hit_rate = Gauge(
    'cache_hit_rate',
    'Cache hit rate percentage'
)

# LLM metrics  
llm_api_calls = Counter(
    'llm_api_calls_total',
    'Total LLM API calls', 
    ['provider', 'status']
)

llm_costs = Counter(
    'llm_costs_total_usd',
    'Total LLM costs in USD',
    ['provider', 'model']
)

class MetricsMiddleware:
    def __init__(self):
        self.start_time = None
    
    async def __call__(self, request, call_next):
        self.start_time = time.time()
        
        # Process request
        response = await call_next(request)
        
        # Record metrics
        duration = time.time() - self.start_time
        rag_response_time.labels(
            endpoint=request.url.path,
            llm_provider="openai"  # Dynamic based on actual provider
        ).observe(duration)
        
        rag_requests_total.labels(
            endpoint=request.url.path,
            status=response.status_code,
            user_type="employee"  # Extract from user context
        ).inc()
        
        return response
```

#### **ğŸš¨ Alert Rules (Prometheus)**
```yaml
# alerts/rag_alerts.yml
groups:
- name: rag_core_alerts
  rules:
  
  # High error rate
  - alert: HighErrorRate
    expr: rate(rag_requests_total{status=~"4..|5.."}[5m]) > 0.05
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }}% over the last 5 minutes"
  
  # Slow response time
  - alert: SlowResponseTime  
    expr: histogram_quantile(0.95, rate(rag_response_time_seconds_bucket[5m])) > 30
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "95th percentile response time too high"
      description: "95th percentile is {{ $value }}s"
  
  # LLM API failures
  - alert: LLMHighFailureRate
    expr: rate(llm_api_calls_total{status="error"}[5m]) > 0.1
    for: 1m  
    labels:
      severity: critical
    annotations:
      summary: "LLM API failure rate too high"
      description: "LLM failure rate: {{ $value }}%"
  
  # High costs
  - alert: HighLLMCosts
    expr: increase(llm_costs_total_usd[1h]) > 50
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: "LLM costs increasing rapidly"
      description: "Costs increased by ${{ $value }} in the last hour"
```

#### **ğŸ“ˆ Grafana Dashboard Config**
```json
{
  "dashboard": {
    "title": "RAG Core Engine Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(rag_requests_total[5m])",
            "legendFormat": "{{endpoint}} - {{status}}"
          }
        ]
      },
      {
        "title": "Response Time Percentiles", 
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(rag_response_time_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(rag_response_time_seconds_bucket[5m]))", 
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, rate(rag_response_time_seconds_bucket[5m]))",
            "legendFormat": "99th percentile" 
          }
        ]
      },
      {
        "title": "LLM Provider Success Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(llm_api_calls_total{status=\"success\"}[5m]) / rate(llm_api_calls_total[5m]) * 100",
            "legendFormat": "{{provider}}"
          }
        ]
      }
    ]
  }
}
```

### 8.3 Performance Optimization Strategies

#### **âš¡ Caching Strategy**
```python
# Multi-level caching implementation
class CacheManager:
    def __init__(self):
        self.redis = Redis(host='redis')
        self.local_cache = {}
        
    async def get_cached_response(self, query_hash: str):
        # Level 1: Local memory cache (fastest)
        if query_hash in self.local_cache:
            return self.local_cache[query_hash]
            
        # Level 2: Redis cache (fast)
        cached = await self.redis.get(f"rag:{query_hash}")
        if cached:
            response = json.loads(cached)
            # Store in local cache for next time
            self.local_cache[query_hash] = response
            return response
            
        return None
    
    async def cache_response(self, query_hash: str, response: dict):
        # Cache in both levels
        self.local_cache[query_hash] = response
        await self.redis.setex(
            f"rag:{query_hash}", 
            3600,  # 1 hour TTL
            json.dumps(response)
        )
```

#### **ğŸ”„ Connection Pooling**
```python
# Database connection optimization
class DatabaseManager:
    def __init__(self):
        self.pg_pool = None
        self.vector_db_pool = None
        
    async def initialize_pools(self):
        # PostgreSQL connection pool
        self.pg_pool = await asyncpg.create_pool(
            host='postgres',
            database='rag_db',
            user='rag_user', 
            password='password',
            min_size=5,
            max_size=20,
            command_timeout=30
        )
        
        # Vector DB connection pool  
        self.vector_db_pool = ChromaConnectionPool(
            max_connections=10,
            timeout=30
        )
    
    async def execute_query(self, query: str, *args):
        async with self.pg_pool.acquire() as conn:
            return await conn.fetch(query, *args)
```

#### **ğŸš€ Async Processing**
```python
# Asynchronous RAG processing
class AsyncRAGOrchestrator:
    async def process_request(self, request: AskRequest):
        # Create coroutines for parallel processing
        query_processing = asyncio.create_task(
            self.process_query(request.user_query)
        )
        
        user_permissions = asyncio.create_task(
            self.get_user_permissions(request.user_id)
        )
        
        # Wait for both to complete
        processed_query, permissions = await asyncio.gather(
            query_processing, 
            user_permissions
        )
        
        # Continue with vector search
        search_results = await self.vector_search(
            processed_query, 
            permissions
        )
        
        # Parallel LLM calls if multiple providers
        llm_tasks = [
            self.call_llm_provider(provider, context)
            for provider in self.active_providers
        ]
        
        # Use the fastest response
        done, pending = await asyncio.wait(
            llm_tasks, 
            return_when=asyncio.FIRST_COMPLETED
        )
        
        # Cancel remaining tasks
        for task in pending:
            task.cancel()
            
        return done.pop().result()
```

---

## 9. **DEPLOYMENT & PRODUCTION CHECKLIST**

### 9.1 Pre-deployment Checklist

#### **ğŸ”§ Code Quality**
- [ ] Code review completed by 2+ developers
- [ ] Unit test coverage â‰¥80%
- [ ] Integration tests passing
- [ ] Security scan completed (no high/critical issues)
- [ ] Performance benchmarks met
- [ ] Documentation updated

#### **ğŸ—„ï¸ Database Preparation**
- [ ] Production database schema applied
- [ ] Migration scripts tested
- [ ] Backup strategy implemented
- [ ] Connection pooling configured
- [ ] Read replicas setup (if needed)

#### **ğŸ” Security Configuration**
- [ ] JWT keys rotated
- [ ] API keys secured in Vault
- [ ] Network security rules applied
- [ ] SSL certificates installed
- [ ] Rate limiting configured
- [ ] CORS policies set

#### **ğŸ“Š Monitoring Setup**
- [ ] Prometheus metrics configured
- [ ] Grafana dashboards imported
- [ ] Alert rules deployed
- [ ] Log aggregation working
- [ ] Health checks enabled

### 9.2 Deployment Script

```bash
#!/bin/bash
# scripts/deploy.sh

set -e  # Exit on any error

echo "ğŸš€ Starting RAG Core Engine Deployment..."

# 1. Environment validation
echo "ğŸ” Validating environment..."
./scripts/validate_env.sh

# 2. Build Docker image
echo "ğŸ³ Building Docker image..."
docker build -t rag-core:${VERSION} .
docker tag rag-core:${VERSION} rag-core:latest

# 3. Database migrations
echo "ğŸ—„ï¸ Running database migrations..."
kubectl apply -f k8s/migrations/

# 4. Deploy to Kubernetes
echo "â˜¸ï¸ Deploying to Kubernetes..."
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secrets.yaml
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/ingress.yaml

# 5. Wait for deployment
echo "â³ Waiting for deployment to be ready..."
kubectl wait --for=condition=available --timeout=300s deployment/rag-core

# 6. Health check
echo "â¤ï¸ Running health checks..."
./scripts/health_check.sh

# 7. Run smoke tests
echo "ğŸ§ª Running smoke tests..."
./scripts/smoke_tests.sh

echo "âœ… Deployment completed successfully!"
echo "ğŸŒ API available at: https://your-domain.com/api/ask"
```

### 9.3 Rollback Strategy

```bash
#!/bin/bash
# scripts/rollback.sh

echo "ğŸ”„ Starting rollback procedure..."

# Get previous version
PREVIOUS_VERSION=$(kubectl get deployment rag-core -o jsonpath='{.metadata.annotations.previous-version}')

if [ -z "$PREVIOUS_VERSION" ]; then
    echo "âŒ No previous version found"
    exit 1
fi

echo "ğŸ“¦ Rolling back to version: $PREVIOUS_VERSION"

# Rollback deployment
kubectl rollout undo deployment/rag-core

# Wait for rollback
kubectl wait --for=condition=available --timeout=300s deployment/rag-core

# Verify rollback
./scripts/health_check.sh

echo "âœ… Rollback completed successfully!"
```

---

## 10. **Tá»”NG Káº¾T VÃ€ NEXT STEPS**

### 10.1 Deliverables Summary

Sau khi hoÃ n thÃ nh roadmap nÃ y, team sáº½ cÃ³:

#### **âœ… HoÃ n thÃ nh 100%**
- [ ] Production-ready `/api/ask` endpoint
- [ ] Complete RAG processing pipeline
- [ ] Multi-level caching system
- [ ] Comprehensive error handling
- [ ] Full monitoring & alerting
- [ ] Security implementation (JWT + RBAC)
- [ ] Performance optimization
- [ ] Complete test suite
- [ ] Production deployment

#### **ğŸ“Š Technical Specifications Met**
- Response time: <60s (target: <10s)
- Throughput: 100 concurrent users
- Accuracy: â‰¥80% relevant responses  
- Availability: 99.5% uptime
- Error rate: <1%
- Security: Multi-layer protection

### 10.2 Success Criteria Validation

```python
# Automated success criteria validation
class SuccessCriteriaValidator:
    async def validate_all(self):
        results = {}
        
        # Performance validation
        results['response_time'] = await self.test_response_time()
        results['throughput'] = await self.test_concurrent_users() 
        results['accuracy'] = await self.test_accuracy()
        
        # Reliability validation
        results['uptime'] = await self.test_availability()
        results['error_rate'] = await self.test_error_rate()
        
        # Security validation
        results['auth'] = await self.test_authentication()
        results['authorization'] = await self.test_authorization()
        
        return results
    
    async def test_response_time(self):
        # Test 100 requests and measure response time
        times = []
        for _ in range(100):
            start = time.time()
            await self.api_client.post("/api/ask", json=sample_request)
            times.append(time.time() - start)
        
        p95_time = np.percentile(times, 95)
        return {"p95_response_time": p95_time, "passed": p95_time < 60}
```

### 10.3 Future Enhancements (Phase 2)

#### **ğŸš€ Advanced Features**
- [ ] Multi-modal support (images, videos)
- [ ] Real-time streaming responses
- [ ] Advanced conversation memory
- [ ] Custom embedding fine-tuning
- [ ] Multi-language support expansion

#### **ğŸ“ˆ Scalability Improvements**  
- [ ] Microservices architecture
- [ ] Event-driven processing
- [ ] Auto-scaling policies
- [ ] Multi-region deployment
- [ ] CDN integration

#### **ğŸ¤– AI/ML Enhancements**
- [ ] Custom domain-specific LLM
- [ ] Advanced retrieval strategies
- [ ] Automatic query optimization
- [ ] Personalized responses
- [ ] Content recommendation

### 10.4 Maintenance & Operations

#### **ğŸ“… Regular Maintenance Tasks**
- **Daily**: Monitor dashboards, check error logs
- **Weekly**: Review performance metrics, cost analysis
- **Monthly**: Security updates, dependency updates
- **Quarterly**: Capacity planning, architecture review

#### **ğŸ”„ Continuous Improvement**
- User feedback collection and analysis
- A/B testing for different retrieval strategies
- Regular accuracy assessments
- Performance optimization iterations

---

## ğŸ“ **SUPPORT & ESCALATION**

### Development Team Contacts
- **Technical Lead**: [Name] - [email] - Slack: @tech-lead
- **DevOps Engineer**: [Name] - [email] - Slack: @devops  
- **QA Engineer**: [Name] - [email] - Slack: @qa-lead

### Escalation Matrix
| Issue Level | Response Time | Contact |
|-------------|---------------|---------|
| **P0 - Critical** | 15 minutes | On-call engineer + Tech Lead |
| **P1 - High** | 2 hours | Tech Lead |  
| **P2 - Medium** | 1 business day | Assigned developer |
| **P3 - Low** | 3 business days | Sprint backlog |

---

**ğŸ¯ Vá»›i roadmap chi tiáº¿t nÃ y, development team cÃ³ thá»ƒ implement FR-04.4 má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng, Ä‘áº£m báº£o cháº¥t lÆ°á»£ng vÃ  sáºµn sÃ ng cho production environment.**

TÃ i liá»‡u nÃ y cung cáº¥p Ä‘áº§y Ä‘á»§ thÃ´ng tin Ä‘á»ƒ team cÃ³ thá»ƒ báº¯t Ä‘áº§u implement ngay láº­p tá»©c mÃ  khÃ´ng cáº§n code cá»¥ thá»ƒ, vá»›i cÃ¡c checkpoints rÃµ rÃ ng vÃ  strategy xá»­ lÃ½ lá»—i toÃ n diá»‡n.

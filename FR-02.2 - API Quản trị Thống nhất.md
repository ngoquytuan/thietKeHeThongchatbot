FR-02.2 - API Quản trị Thống nhất

Cung cấp RESTful API cho các thao tác CRUD
Endpoint chính:
/api/documents - Quản lý tài liệu
/api/users - Quản lý người dùng
/api/search - Tìm kiếm tài liệu
/api/access-control - Quản lý phân quyền
---
# TÀI LIỆU THIẾT KẾ KỸ THUẬT
## FR-02.2 - API QUẢN TRỊ THỐNG NHẤT
### UNIFIED MANAGEMENT API DESIGN SPECIFICATION

---

**Phiên bản:** 1.0  
**Ngày:** 31/08/2025  
**Module:** FR-02.2 - API Quản trị Thống nhất  
**Người soạn thảo:** Technical Design Team  
**Trạng thái:** Implementation Ready  

---

## 1. TỔNG QUAN MODULE

### 1.1 Mục tiêu
Xây dựng RESTful API Gateway thống nhất cung cấp interface chuẩn cho tất cả các thao tác CRUD của hệ thống Trợ lý Tri thức Nội bộ.

### 1.2 Phạm vi
- **Documents API**: `/api/documents` - Quản lý tài liệu
- **Users API**: `/api/users` - Quản lý người dùng  
- **Search API**: `/api/search` - Tìm kiếm tài liệu
- **Access Control API**: `/api/access-control` - Quản lý phân quyền

### 1.3 Kiến trúc tổng quan
```mermaid
graph TB
    Client[Client Applications] --> Gateway[API Gateway]
    Gateway --> Auth[Authentication Layer]
    Gateway --> Rate[Rate Limiting]
    Gateway --> Router[Request Router]
    
    Router --> DocAPI[Documents API]
    Router --> UserAPI[Users API] 
    Router --> SearchAPI[Search API]
    Router --> AccessAPI[Access Control API]
    
    DocAPI --> VectorDB[(Vector DB)]
    DocAPI --> PostgreSQL[(PostgreSQL)]
    UserAPI --> PostgreSQL
    SearchAPI --> VectorDB
    SearchAPI --> Elasticsearch[(Elasticsearch)]
    AccessAPI --> PostgreSQL
```

---

## 2. CHUẨN BỊ MÔI TRƯỜNG PHÁT TRIỂN

### 2.1 Yêu cầu phần cứng tối thiểu

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **CPU** | 4 cores (Intel i5/AMD Ryzen 5) | 8 cores (Intel i7/AMD Ryzen 7) |
| **RAM** | 16GB | 32GB |
| **Storage** | 500GB SSD | 1TB NVMe SSD |
| **Network** | 1Gbps | 10Gbps |

### 2.2 Hệ điều hành & Software stack

#### **Hệ điều hành hỗ trợ:**
- **Ubuntu 22.04 LTS** (Recommended)
- **CentOS Stream 9**  
- **macOS 12+** (Development only)
- **Windows 11** với WSL2 (Development only)

#### **Core Development Stack:**
```bash
# Programming Language
Python 3.11+

# Web Framework  
FastAPI 0.104+
Uvicorn 0.24+ (ASGI Server)

# Database Drivers
psycopg2-binary 2.9+ (PostgreSQL)
chromadb 0.4+ (Vector DB)
elasticsearch 8.0+ (Full-text search)

# Authentication & Security
python-jose 3.3+ (JWT)
passlib 1.7+ (Password hashing)
python-multipart 0.0.6+ (File uploads)

# API Documentation
openapi-generator 7.0+
redoc 2.1+

# Testing Framework
pytest 7.4+
httpx 0.25+ (Async HTTP client for testing)
```

### 2.3 Cài đặt môi trường từng bước

#### **Bước 1: Chuẩn bị hệ thống (Ubuntu 22.04)**
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install essential packages
sudo apt install -y curl wget git vim build-essential

# Install Python 3.11
sudo apt install -y python3.11 python3.11-venv python3.11-dev python3-pip

# Install Docker & Docker Compose
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Install Node.js (for API documentation tools)
curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -
sudo apt-get install -y nodejs
```

#### **Bước 2: Setup Python Virtual Environment**
```bash
# Create project directory
mkdir -p ~/projects/knowledge-assistant-api
cd ~/projects/knowledge-assistant-api

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Upgrade pip
pip install --upgrade pip setuptools wheel
```

#### **Bước 3: Install Core Dependencies**
```bash
# Create requirements.txt
cat > requirements.txt << EOF
# Web Framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.4.2
pydantic-settings==2.0.3

# Database & Storage
psycopg2-binary==2.9.7
chromadb==0.4.15
elasticsearch==8.10.1
redis==5.0.1

# Authentication & Security  
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.6

# HTTP & Async
httpx==0.25.0
aiofiles==23.2.1

# Utilities
python-dotenv==1.0.0
loguru==0.7.2
typer==0.9.0

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
httpx==0.25.0

# Development
black==23.9.1
isort==5.12.0
flake8==6.1.0
mypy==1.6.1
EOF

# Install dependencies
pip install -r requirements.txt
```

#### **Bước 4: Setup Database Services (Docker)**
```bash
# Create docker-compose.yml for development
cat > docker-compose.dev.yml << 'EOF'
version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: ka-postgres
    environment:
      POSTGRES_DB: knowledge_assistant
      POSTGRES_USER: ka_user
      POSTGRES_PASSWORD: ka_password_dev
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: ka-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.1
    container_name: ka-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  es_data:
EOF

# Start services
docker-compose -f docker-compose.dev.yml up -d
```

#### **Bước 5: Project Structure Setup**
```bash
# Create project structure
mkdir -p {app,tests,docs,scripts,config}
mkdir -p app/{api,core,models,services,utils}
mkdir -p app/api/{endpoints,dependencies}
mkdir -p tests/{unit,integration,e2e}

# Create basic files
touch app/__init__.py
touch app/main.py
touch app/core/{__init__.py,config.py,security.py,database.py}
touch app/models/{__init__.py,users.py,documents.py,permissions.py}
touch app/services/{__init__.py,user_service.py,document_service.py,search_service.py}
touch app/api/{__init__.py,router.py}
touch app/api/endpoints/{__init__.py,documents.py,users.py,search.py,access_control.py}
```

---

## 3. THIẾT KẾ API SPECIFICATION

### 3.1 API Authentication & Security

#### **JWT Token Structure:**
```json
{
  "sub": "user_id_123",
  "username": "john.doe", 
  "email": "john@company.com",
  "role": "employee|manager|director|admin",
  "department": "rd|sales|production",
  "permissions": ["read:documents", "write:documents"],
  "exp": 1698234567,
  "iat": 1698230967
}
```

#### **Security Headers:**
```http
Authorization: Bearer <jwt_token>
Content-Type: application/json
X-API-Version: v1
X-Request-ID: uuid4()
```

### 3.2 Standard Response Format

#### **Success Response:**
```json
{
  "success": true,
  "data": {
    // Actual response data
  },
  "metadata": {
    "timestamp": "2025-08-31T10:30:00Z",
    "request_id": "req_123456789",
    "version": "v1",
    "total_count": 100,
    "page": 1,
    "page_size": 20
  }
}
```

#### **Error Response:**
```json
{
  "success": false,
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Request validation failed",
    "details": [
      {
        "field": "email",
        "message": "Invalid email format"
      }
    ]
  },
  "metadata": {
    "timestamp": "2025-08-31T10:30:00Z", 
    "request_id": "req_123456789",
    "version": "v1"
  }
}
```

### 3.3 API Endpoints Chi tiết

#### **3.3.1 Documents API (`/api/documents`)**

**POST /api/documents** - Upload document
```http
POST /api/documents
Content-Type: multipart/form-data

Form Data:
- file: [binary file]
- metadata: {
    "title": "Company Policy 2025",
    "department": "hr", 
    "access_level": "employee_only",
    "tags": ["policy", "hr", "2025"],
    "description": "Updated company policy"
  }
```

**GET /api/documents** - List documents
```http
GET /api/documents?page=1&page_size=20&department=rd&access_level=employee_only&search=policy

Response:
{
  "success": true,
  "data": [
    {
      "id": "doc_12345",
      "title": "R&D Process Guide",
      "department": "rd",
      "access_level": "employee_only", 
      "author": "john.doe",
      "created_at": "2025-08-31T10:00:00Z",
      "updated_at": "2025-08-31T10:00:00Z",
      "file_size": 2048576,
      "file_type": "pdf",
      "tags": ["process", "rd", "guide"],
      "download_url": "/api/documents/doc_12345/download"
    }
  ],
  "metadata": {
    "total_count": 150,
    "page": 1, 
    "page_size": 20
  }
}
```

**GET /api/documents/{doc_id}** - Get document details
**PUT /api/documents/{doc_id}** - Update document metadata
**DELETE /api/documents/{doc_id}** - Delete document
**GET /api/documents/{doc_id}/download** - Download original file

#### **3.3.2 Users API (`/api/users`)**

**POST /api/users** - Create user
```json
{
  "username": "jane.smith",
  "email": "jane.smith@company.com", 
  "full_name": "Jane Smith",
  "department": "sales",
  "role": "employee",
  "is_active": true
}
```

**GET /api/users** - List users with filtering
**GET /api/users/{user_id}** - Get user details  
**PUT /api/users/{user_id}** - Update user
**DELETE /api/users/{user_id}** - Deactivate user
**POST /api/users/{user_id}/reset-password** - Reset password

#### **3.3.3 Search API (`/api/search`)**

**POST /api/search** - Advanced search
```json
{
  "query": "machine learning model deployment",
  "search_type": "semantic|keyword|hybrid",
  "filters": {
    "department": ["rd", "engineering"],
    "access_level": ["employee_only", "public"],
    "file_type": ["pdf", "docx"],
    "date_range": {
      "from": "2025-01-01",
      "to": "2025-08-31"
    }
  },
  "options": {
    "max_results": 10,
    "include_snippets": true,
    "highlight": true
  }
}
```

**GET /api/search/suggestions** - Get search suggestions
**GET /api/search/popular** - Popular search terms

#### **3.3.4 Access Control API (`/api/access-control`)**

**POST /api/access-control/permissions** - Grant permission
```json
{
  "user_id": "user_123",
  "resource_type": "document",
  "resource_id": "doc_456", 
  "permission": "read|write|admin",
  "granted_by": "admin_user_id",
  "expires_at": "2025-12-31T23:59:59Z"
}
```

**GET /api/access-control/permissions** - List permissions
**GET /api/access-control/user/{user_id}/permissions** - User permissions
**DELETE /api/access-control/permissions/{permission_id}** - Revoke permission
**POST /api/access-control/roles** - Create role
**GET /api/access-control/roles** - List roles

---

## 4. LUỒNG CÔNG VIỆC IMPLEMENTATION

```mermaid
graph TD
    Start([🚀 Start Implementation]) --> Env[📦 Setup Environment]
    
    Env --> EnvCheck{Environment OK?}
    EnvCheck -->|No| EnvFix[🔧 Fix Environment Issues]
    EnvFix --> Env
    EnvCheck -->|Yes| Core[🏗️ Build Core Infrastructure]
    
    Core --> Database[🗄️ Setup Database Schema]
    Database --> DBTest{DB Connection OK?}
    DBTest -->|No| DBFix[🔧 Fix Database Issues]
    DBFix --> Database
    DBTest -->|Yes| Auth[🔐 Implement Authentication]
    
    Auth --> AuthTest{Auth Working?}
    AuthTest -->|No| AuthFix[🔧 Fix Auth Issues]
    AuthFix --> Auth
    AuthTest -->|Yes| BaseAPI[📡 Build Base API Structure]
    
    BaseAPI --> DocAPI[📄 Implement Documents API]
    DocAPI --> DocTest{Doc API Tests Pass?}
    DocTest -->|No| DocFix[🔧 Fix Doc API Issues]
    DocFix --> DocAPI
    DocTest -->|Yes| UserAPI[👤 Implement Users API]
    
    UserAPI --> UserTest{User API Tests Pass?}
    UserTest -->|No| UserFix[🔧 Fix User API Issues]  
    UserFix --> UserAPI
    UserTest -->|Yes| SearchAPI[🔍 Implement Search API]
    
    SearchAPI --> SearchTest{Search API Tests Pass?}
    SearchTest -->|No| SearchFix[🔧 Fix Search API Issues]
    SearchFix --> SearchAPI
    SearchTest -->|Yes| AccessAPI[🛡️ Implement Access Control API]
    
    AccessAPI --> AccessTest{Access API Tests Pass?}
    AccessTest -->|No| AccessFix[🔧 Fix Access API Issues]
    AccessFix --> AccessAPI
    AccessTest -->|Yes| Integration[🔗 Integration Testing]
    
    Integration --> IntegTest{Integration Tests Pass?}
    IntegTest -->|No| IntegFix[🔧 Fix Integration Issues]
    IntegFix --> Integration
    IntegTest -->|Yes| Performance[⚡ Performance Testing]
    
    Performance --> PerfTest{Performance Requirements Met?}
    PerfTest -->|No| PerfOptim[🚀 Performance Optimization]
    PerfOptim --> Performance
    PerfTest -->|Yes| Security[🛡️ Security Testing]
    
    Security --> SecTest{Security Tests Pass?}
    SecTest -->|No| SecFix[🔒 Fix Security Issues]
    SecFix --> Security
    SecTest -->|Yes| Documentation[📚 Generate API Documentation]
    
    Documentation --> Deployment[🚀 Deployment Preparation]
    Deployment --> Complete([✅ Implementation Complete])
    
    %% Styling
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    classDef process fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef fix fill:#ffebee,stroke:#c62828,stroke-width:2px
    
    class Start,Complete startEnd
    class Env,Core,Database,Auth,BaseAPI,DocAPI,UserAPI,SearchAPI,AccessAPI,Integration,Performance,Security,Documentation,Deployment process
    class EnvCheck,DBTest,AuthTest,DocTest,UserTest,SearchTest,AccessTest,IntegTest,PerfTest,SecTest decision
    class EnvFix,DBFix,AuthFix,DocFix,UserFix,SearchFix,AccessFix,IntegFix,PerfOptim,SecFix fix
```

---

## 5. IMPLEMENTATION STEPS CHI TIẾT

### 5.1 Phase 1: Core Infrastructure (Tuần 1)

#### **Step 1.1: Database Schema Setup**
```sql
-- Create schema script (create_schema.sql)
-- Users table
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    full_name VARCHAR(255) NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    department VARCHAR(50) NOT NULL,
    role user_role NOT NULL DEFAULT 'employee',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Documents table  
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title VARCHAR(500) NOT NULL,
    file_name VARCHAR(255) NOT NULL,
    file_path TEXT NOT NULL,
    file_size BIGINT NOT NULL,
    file_type VARCHAR(50) NOT NULL,
    department VARCHAR(50) NOT NULL,
    access_level access_level NOT NULL DEFAULT 'employee_only',
    author_id UUID REFERENCES users(id),
    description TEXT,
    tags TEXT[],
    version INTEGER DEFAULT 1,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create indexes
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);  
CREATE INDEX idx_documents_department ON documents(department);
CREATE INDEX idx_documents_access_level ON documents(access_level);
CREATE INDEX idx_documents_tags ON documents USING GIN(tags);
```

#### **Step 1.2: Configuration Management**
```python
# app/core/config.py
from pydantic_settings import BaseSettings
from typing import List, Optional

class Settings(BaseSettings):
    # App Settings
    APP_NAME: str = "Knowledge Assistant API"
    APP_VERSION: str = "1.0.0"
    DEBUG: bool = False
    
    # Database
    DATABASE_URL: str = "postgresql://ka_user:ka_password_dev@localhost:5432/knowledge_assistant"
    DATABASE_ECHO: bool = False
    
    # Redis
    REDIS_URL: str = "redis://localhost:6379"
    
    # Elasticsearch
    ELASTICSEARCH_URL: str = "http://localhost:9200"
    
    # Security
    SECRET_KEY: str = "your-super-secret-key-change-in-production"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    REFRESH_TOKEN_EXPIRE_DAYS: int = 7
    
    # API Settings
    API_V1_PREFIX: str = "/api"
    CORS_ORIGINS: List[str] = ["http://localhost:3000", "http://localhost:8080"]
    
    # File Upload
    MAX_FILE_SIZE: int = 50 * 1024 * 1024  # 50MB
    ALLOWED_FILE_TYPES: List[str] = [".pdf", ".doc", ".docx", ".txt", ".md"]
    UPLOAD_DIR: str = "./uploads"
    
    # Vector DB
    CHROMA_PERSIST_DIR: str = "./chroma_db"
    
    class Config:
        env_file = ".env"

settings = Settings()
```

### 5.2 Phase 2: Authentication Layer (Tuần 1)

#### **Step 2.1: JWT Authentication**
```python
# app/core/security.py
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from jose import JWTError, jwt
from passlib.context import CryptContext
from pydantic import BaseModel

class Token(BaseModel):
    access_token: str
    refresh_token: str
    token_type: str = "bearer"

class TokenData(BaseModel):
    user_id: Optional[str] = None
    username: Optional[str] = None
    permissions: List[str] = []

class SecurityService:
    def __init__(self):
        self.pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
        self.secret_key = settings.SECRET_KEY
        self.algorithm = "HS256"
    
    def create_access_token(self, data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
        to_encode = data.copy()
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
        
        to_encode.update({"exp": expire})
        return jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
    
    def verify_token(self, token: str) -> Optional[TokenData]:
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            user_id: str = payload.get("sub")
            username: str = payload.get("username")
            permissions: List[str] = payload.get("permissions", [])
            
            if user_id is None or username is None:
                return None
                
            return TokenData(user_id=user_id, username=username, permissions=permissions)
        except JWTError:
            return None

security_service = SecurityService()
```

### 5.3 Phase 3: API Endpoints Implementation (Tuần 2-3)

#### **Step 3.1: Documents API Implementation**
```python
# app/api/endpoints/documents.py
from fastapi import APIRouter, Depends, File, UploadFile, HTTPException, Query
from fastapi.responses import FileResponse
from typing import List, Optional
from uuid import UUID

from app.models.documents import Document, DocumentCreate, DocumentUpdate
from app.services.document_service import DocumentService
from app.api.dependencies import get_current_user, check_permissions

router = APIRouter(prefix="/documents", tags=["documents"])

@router.post("/", response_model=Document)
async def create_document(
    file: UploadFile = File(...),
    metadata: DocumentCreate = Depends(),
    current_user: User = Depends(get_current_user),
    document_service: DocumentService = Depends()
):
    """Upload and create a new document"""
    
    # Validate file
    if not file.filename.lower().endswith(tuple(settings.ALLOWED_FILE_TYPES)):
        raise HTTPException(400, "File type not allowed")
    
    if file.size > settings.MAX_FILE_SIZE:
        raise HTTPException(400, "File too large")
    
    # Check permissions
    if not await check_permissions(current_user, "write:documents"):
        raise HTTPException(403, "Insufficient permissions")
    
    # Process upload
    try:
        document = await document_service.create_document(
            file=file,
            metadata=metadata,
            author_id=current_user.id
        )
        return document
    except Exception as e:
        raise HTTPException(500, f"Failed to create document: {str(e)}")

@router.get("/", response_model=List[Document])
async def list_documents(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    department: Optional[str] = Query(None),
    access_level: Optional[str] = Query(None),
    search: Optional[str] = Query(None),
    current_user: User = Depends(get_current_user),
    document_service: DocumentService = Depends()
):
    """List documents with filtering and pagination"""
    
    filters = {
        "department": department,
        "access_level": access_level, 
        "search": search,
        "user_permissions": current_user.permissions
    }
    
    documents = await document_service.list_documents(
        page=page,
        page_size=page_size,
        filters=filters,
        user_id=current_user.id
    )
    
    return documents

# Additional endpoints: GET /{id}, PUT /{id}, DELETE /{id}, GET /{id}/download
```

### 5.4 Phase 4: Testing Strategy (Tuần 3)

#### **Step 4.1: Unit Tests**
```python
# tests/unit/test_documents_api.py
import pytest
from httpx import AsyncClient
from fastapi.testclient import TestClient

from app.main import app
from tests.conftest import test_user, test_document

class TestDocumentsAPI:
    
    @pytest.mark.asyncio
    async def test_create_document_success(self, async_client: AsyncClient, test_user):
        """Test successful document creation"""
        
        # Prepare test file
        test_file = {
            "file": ("test.pdf", b"fake pdf content", "application/pdf")
        }
        
        metadata = {
            "title": "Test Document",
            "department": "rd",
            "access_level": "employee_only",
            "description": "Test document description"
        }
        
        response = await async_client.post(
            "/api/documents/",
            files=test_file,
            data=metadata,
            headers={"Authorization": f"Bearer {test_user.access_token}"}
        )
        
        assert response.status_code == 201
        data = response.json()
        assert data["title"] == "Test Document"
        assert data["department"] == "rd"
    
    @pytest.mark.asyncio
    async def test_list_documents_with_pagination(self, async_client: AsyncClient, test_user):
        """Test document listing with pagination"""
        
        response = await async_client.get(
            "/api/documents/?page=1&page_size=10",
            headers={"Authorization": f"Bearer {test_user.access_token}"}
        )
        
        assert response.status_code == 200
        data = response.json()
        assert "data" in data
        assert "metadata" in data
        assert data["metadata"]["page"] == 1
        assert data["metadata"]["page_size"] == 10
```

#### **Step 4.2: Integration Tests**
```python
# tests/integration/test_api_integration.py
import pytest
from httpx import AsyncClient

class TestAPIIntegration:
    
    @pytest.mark.asyncio
    async def test_document_workflow(self, async_client: AsyncClient):
        """Test complete document workflow: create -> list -> get -> update -> delete"""
        
        # 1. Authenticate user
        auth_response = await async_client.post("/api/auth/login", json={
            "username": "testuser",
            "password": "testpassword"
        })
        token = auth_response.json()["access_token"]
        headers = {"Authorization": f"Bearer {token}"}
        
        # 2. Create document
        test_file = {"file": ("test.pdf", b"content", "application/pdf")}
        metadata = {"title": "Integration Test Doc", "department": "rd"}
        
        create_response = await async_client.post(
            "/api/documents/", 
            files=test_file, 
            data=metadata, 
            headers=headers
        )
        assert create_response.status_code == 201
        doc_id = create_response.json()["id"]
        
        # 3. List documents
        list_response = await async_client.get("/api/documents/", headers=headers)
        assert list_response.status_code == 200
        assert any(doc["id"] == doc_id for doc in list_response.json()["data"])
        
        # 4. Get specific document
        get_response = await async_client.get(f"/api/documents/{doc_id}", headers=headers)
        assert get_response.status_code == 200
        assert get_response.json()["title"] == "Integration Test Doc"
        
        # 5. Update document
        update_response = await async_client.put(
            f"/api/documents/{doc_id}",
            json={"title": "Updated Integration Test Doc"},
            headers=headers
        )
        assert update_response.status_code == 200
        
        # 6. Delete document
        delete_response = await async_client.delete(f"/api/documents/{doc_id}", headers=headers)
        assert delete_response.status_code == 204
```

---

## 6. ROLLBACK STRATEGIES & ERROR HANDLING

### 6.1 Rollback Points

```mermaid
graph TD
    Deploy[🚀 Deployment] --> HealthCheck{Health Check Pass?}
    HealthCheck -->|No| Rollback1[📦 Rollback to Previous Version]
    HealthCheck -->|Yes| DBMigration[🗄️ Database Migration]
    
    DBMigration --> DBCheck{Migration Success?}
    DBCheck -->|No| Rollback2[🔄 Rollback Database]
    DBCheck -->|Yes| APITest[📡 API Smoke Tests]
    
    APITest --> APICheck{API Tests Pass?}
    APICheck -->|No| Rollback3[⚡ Rollback API Service]
    APICheck -->|Yes| LoadTest[⚖️ Load Testing]
    
    LoadTest --> LoadCheck{Performance OK?}
    LoadCheck -->|No| Rollback4[🚀 Scale Back/Optimize]
    LoadCheck -->|Yes| Success[✅ Deployment Success]
    
    Rollback1 --> NotifyTeam[📧 Notify Team]
    Rollback2 --> NotifyTeam
    Rollback3 --> NotifyTeam  
    Rollback4 --> NotifyTeam
    NotifyTeam --> Investigate
```
---
### 6.2 Error Handling Strategies

#### **Database Connection Failures**
```python
# app/core/database.py
from sqlalchemy.exc import SQLAlchemyError
from contextlib import asynccontextmanager
import asyncio
from typing import AsyncGenerator

class DatabaseManager:
    def __init__(self):
        self.engine = None
        self.session_factory = None
        self.max_retries = 3
        self.retry_delay = 1.0
    
    async def connect_with_retry(self) -> bool:
        """Connect to database with retry logic"""
        for attempt in range(self.max_retries):
            try:
                # Test connection
                async with self.session_factory() as session:
                    await session.execute(text("SELECT 1"))
                    return True
            except SQLAlchemyError as e:
                logger.error(f"Database connection attempt {attempt + 1} failed: {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (2 ** attempt))  # Exponential backoff
                else:
                    logger.critical("All database connection attempts failed")
                    return False
        return False
    
    @asynccontextmanager
    async def get_session(self) -> AsyncGenerator:
        """Get database session with automatic rollback on error"""
        async with self.session_factory() as session:
            try:
                yield session
                await session.commit()
            except Exception as e:
                await session.rollback()
                logger.error(f"Database transaction failed: {e}")
                raise
```

#### **API Error Handler Middleware**
```python
# app/core/error_handlers.py
from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
import traceback
from typing import Union

async def global_error_handler(request: Request, exc: Exception) -> JSONResponse:
    """Global error handler for all unhandled exceptions"""
    
    # Generate request ID for tracking
    request_id = getattr(request.state, 'request_id', 'unknown')
    
    if isinstance(exc, HTTPException):
        return JSONResponse(
            status_code=exc.status_code,
            content={
                "success": False,
                "error": {
                    "code": f"HTTP_{exc.status_code}",
                    "message": exc.detail,
                    "details": []
                },
                "metadata": {
                    "timestamp": datetime.utcnow().isoformat(),
                    "request_id": request_id,
                    "version": "v1"
                }
            }
        )
    
    elif isinstance(exc, RequestValidationError):
        return JSONResponse(
            status_code=422,
            content={
                "success": False,
                "error": {
                    "code": "VALIDATION_ERROR",
                    "message": "Request validation failed",
                    "details": [
                        {
                            "field": ".".join(str(x) for x in error["loc"][1:]),
                            "message": error["msg"],
                            "type": error["type"]
                        }
                        for error in exc.errors()
                    ]
                },
                "metadata": {
                    "timestamp": datetime.utcnow().isoformat(),
                    "request_id": request_id,
                    "version": "v1"
                }
            }
        )
    
    else:
        # Log full traceback for debugging
        logger.error(f"Unhandled exception for request {request_id}: {traceback.format_exc()}")
        
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": {
                    "code": "INTERNAL_SERVER_ERROR",
                    "message": "An internal server error occurred",
                    "details": []
                },
                "metadata": {
                    "timestamp": datetime.utcnow().isoformat(),
                    "request_id": request_id,
                    "version": "v1"
                }
            }
        )
```

### 6.3 Circuit Breaker Pattern
```python
# app/utils/circuit_breaker.py
import time
from enum import Enum
from typing import Callable, Any
import asyncio

class CircuitState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

class CircuitBreaker:
    def __init__(self, 
                 failure_threshold: int = 5,
                 timeout: int = 60,
                 expected_exception: type = Exception):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.expected_exception = expected_exception
        
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    async def call(self, func: Callable, *args, **kwargs) -> Any:
        """Execute function with circuit breaker protection"""
        
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time > self.timeout:
                self.state = CircuitState.HALF_OPEN
                self.failure_count = 0
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)
            
            # Success - reset failure count
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
            self.failure_count = 0
            
            return result
            
        except self.expected_exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
            
            raise e

# Usage example for external LLM API calls
llm_circuit_breaker = CircuitBreaker(failure_threshold=3, timeout=30)

async def call_external_llm_with_breaker(prompt: str) -> str:
    return await llm_circuit_breaker.call(external_llm_api.generate, prompt)
```

---

## 7. MONITORING & OBSERVABILITY

### 7.1 Health Check Endpoints
```python
# app/api/endpoints/health.py
from fastapi import APIRouter, Depends
from sqlalchemy import text
from app.core.database import get_db_session
from app.services.redis_service import redis_client
from app.services.elasticsearch_service import es_client

router = APIRouter(prefix="/health", tags=["health"])

@router.get("/")
async def health_check():
    """Basic health check"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": settings.APP_VERSION
    }

@router.get("/detailed")
async def detailed_health_check():
    """Detailed health check with all dependencies"""
    checks = {
        "api": {"status": "healthy"},
        "database": {"status": "unknown"},
        "redis": {"status": "unknown"},
        "elasticsearch": {"status": "unknown"}
    }
    
    # Database check
    try:
        async with get_db_session() as session:
            await session.execute(text("SELECT 1"))
            checks["database"]["status"] = "healthy"
    except Exception as e:
        checks["database"]["status"] = "unhealthy"
        checks["database"]["error"] = str(e)
    
    # Redis check
    try:
        await redis_client.ping()
        checks["redis"]["status"] = "healthy"
    except Exception as e:
        checks["redis"]["status"] = "unhealthy"
        checks["redis"]["error"] = str(e)
    
    # Elasticsearch check
    try:
        health = await es_client.cluster.health()
        checks["elasticsearch"]["status"] = "healthy" if health["status"] in ["green", "yellow"] else "unhealthy"
        checks["elasticsearch"]["cluster_status"] = health["status"]
    except Exception as e:
        checks["elasticsearch"]["status"] = "unhealthy"
        checks["elasticsearch"]["error"] = str(e)
    
    # Overall status
    overall_status = "healthy" if all(check["status"] == "healthy" for check in checks.values()) else "unhealthy"
    
    return {
        "status": overall_status,
        "timestamp": datetime.utcnow().isoformat(),
        "version": settings.APP_VERSION,
        "checks": checks
    }
```

### 7.2 Metrics Collection
```python
# app/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
from functools import wraps
from typing import Callable

# Define metrics
api_requests_total = Counter(
    'api_requests_total', 
    'Total API requests', 
    ['method', 'endpoint', 'status_code']
)

api_request_duration = Histogram(
    'api_request_duration_seconds',
    'API request duration in seconds',
    ['method', 'endpoint']
)

active_connections = Gauge(
    'active_database_connections',
    'Number of active database connections'
)

document_processing_time = Histogram(
    'document_processing_seconds',
    'Time spent processing documents',
    ['operation']
)

def track_api_metrics(func: Callable) -> Callable:
    """Decorator to track API endpoint metrics"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        status_code = 200
        
        try:
            result = await func(*args, **kwargs)
            return result
        except HTTPException as e:
            status_code = e.status_code
            raise
        except Exception:
            status_code = 500
            raise
        finally:
            # Record metrics
            request = kwargs.get('request')
            if request:
                method = request.method
                endpoint = request.url.path
                
                api_requests_total.labels(
                    method=method,
                    endpoint=endpoint,
                    status_code=status_code
                ).inc()
                
                api_request_duration.labels(
                    method=method,
                    endpoint=endpoint
                ).observe(time.time() - start_time)
    
    return wrapper
```

### 7.3 Structured Logging
```python
# app/core/logging.py
from loguru import logger
import sys
import json
from datetime import datetime
from typing import Dict, Any

class StructuredLogger:
    def __init__(self):
        # Remove default logger
        logger.remove()
        
        # Add structured JSON logger
        logger.add(
            sys.stdout,
            format=self._json_formatter,
            level="INFO",
            serialize=False
        )
        
        # Add file logger for errors
        logger.add(
            "logs/api_errors.log",
            format=self._json_formatter,
            level="ERROR",
            rotation="100 MB",
            retention="30 days",
            serialize=False
        )
    
    def _json_formatter(self, record) -> str:
        """Format log record as JSON"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record["level"].name,
            "message": record["message"],
            "module": record["name"],
            "function": record["function"],
            "line": record["line"]
        }
        
        # Add extra context if available
        if hasattr(record["extra"], "request_id"):
            log_entry["request_id"] = record["extra"]["request_id"]
        
        if hasattr(record["extra"], "user_id"):
            log_entry["user_id"] = record["extra"]["user_id"]
        
        return json.dumps(log_entry)
    
    def log_api_request(self, request, response, duration: float):
        """Log API request details"""
        logger.info(
            "API Request",
            extra={
                "request_method": request.method,
                "request_path": request.url.path,
                "request_params": dict(request.query_params),
                "response_status": response.status_code,
                "response_time": duration,
                "request_id": getattr(request.state, 'request_id', None),
                "user_id": getattr(request.state, 'user_id', None)
            }
        )

structured_logger = StructuredLogger()
```

---

## 8. DEPLOYMENT & OPERATIONS

### 8.1 Production Dockerfile
```dockerfile
# Dockerfile.production
FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        build-essential \
        libpq-dev \
        curl \
    && rm -rf /var/lib/apt/lists/*

# Create application user
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Set work directory
WORKDIR /app

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .
RUN chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Expose port
EXPOSE 8000

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### 8.2 Kubernetes Deployment
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: knowledge-assistant-api
  labels:
    app: knowledge-assistant-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: knowledge-assistant-api
  template:
    metadata:
      labels:
        app: knowledge-assistant-api
    spec:
      containers:
      - name: api
        image: knowledge-assistant-api:1.0.0
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: database-url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: redis-url
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: secret-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/detailed
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: knowledge-assistant-api-service
spec:
  selector:
    app: knowledge-assistant-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP
```

### 8.3 Deployment Script
```bash
#!/bin/bash
# deploy.sh

set -e  # Exit on any error

# Configuration
IMAGE_NAME="knowledge-assistant-api"
VERSION=${1:-latest}
NAMESPACE="knowledge-assistant"

echo "🚀 Starting deployment of $IMAGE_NAME:$VERSION"

# Step 1: Build and push image
echo "📦 Building Docker image..."
docker build -f Dockerfile.production -t $IMAGE_NAME:$VERSION .

# Step 2: Run pre-deployment tests
echo "🧪 Running pre-deployment tests..."
docker run --rm \
    --env-file .env.test \
    $IMAGE_NAME:$VERSION \
    python -m pytest tests/ -v

if [ $? -ne 0 ]; then
    echo "❌ Tests failed. Aborting deployment."
    exit 1
fi

# Step 3: Database migrations
echo "🗄️ Running database migrations..."
kubectl exec -n $NAMESPACE deployment/knowledge-assistant-api -- \
    alembic upgrade head

# Step 4: Update Kubernetes deployment
echo "☸️ Updating Kubernetes deployment..."
kubectl set image deployment/knowledge-assistant-api \
    api=$IMAGE_NAME:$VERSION \
    -n $NAMESPACE

# Step 5: Wait for rollout
echo "⏳ Waiting for rollout to complete..."
kubectl rollout status deployment/knowledge-assistant-api -n $NAMESPACE --timeout=300s

# Step 6: Health check
echo "❤️ Running health checks..."
sleep 30  # Wait for pods to be ready

HEALTH_CHECK=$(kubectl exec -n $NAMESPACE deployment/knowledge-assistant-api -- \
    curl -s -o /dev/null -w "%{http_code}" http://localhost:8000/health/detailed)

if [ "$HEALTH_CHECK" = "200" ]; then
    echo "✅ Deployment successful! Health check passed."
else
    echo "❌ Health check failed. Rolling back..."
    kubectl rollout undo deployment/knowledge-assistant-api -n $NAMESPACE
    exit 1
fi

echo "🎉 Deployment completed successfully!"
```

---

## 9. TESTING & QUALITY ASSURANCE

### 9.1 Automated Testing Pipeline
```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-cov
    
    - name: Run linting
      run: |
        black --check app/ tests/
        isort --check-only app/ tests/
        flake8 app/ tests/
        mypy app/
    
    - name: Run unit tests
      env:
        DATABASE_URL: postgresql://postgres:test_password@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        SECRET_KEY: test_secret_key
      run: |
        pytest tests/unit/ -v --cov=app --cov-report=xml
    
    - name: Run integration tests  
      env:
        DATABASE_URL: postgresql://postgres:test_password@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        SECRET_KEY: test_secret_key
      run: |
        pytest tests/integration/ -v
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Run security scan
      uses: pyupio/safety@master
      with:
        args: --json
    
    - name: Run Bandit security linter
      run: |
        pip install bandit
        bandit -r app/ -f json -o bandit-report.json

  build-and-push:
    needs: [test, security-scan]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build and push Docker image
      env:
        IMAGE_TAG: ${{ github.sha }}
      run: |
        docker build -f Dockerfile.production -t knowledge-assistant-api:$IMAGE_TAG .
        # Push to registry (configure as needed)
```

### 9.2 Load Testing Script
```python
# tests/performance/load_test.py
import asyncio
import aiohttp
import time
from concurrent.futures import ThreadPoolExecutor
import statistics

class LoadTester:
    def __init__(self, base_url: str, concurrent_users: int = 100):
        self.base_url = base_url
        self.concurrent_users = concurrent_users
        self.results = []
    
    async def simulate_user_session(self, session: aiohttp.ClientSession, user_id: int):
        """Simulate a typical user session"""
        session_results = []
        
        # 1. Login
        start_time = time.time()
        async with session.post(f"{self.base_url}/auth/login", json={
            "username": f"testuser{user_id}",
            "password": "testpassword"
        }) as response:
            if response.status == 200:
                auth_data = await response.json()
                token = auth_data["access_token"]
                headers = {"Authorization": f"Bearer {token}"}
            else:
                return session_results
        
        session_results.append({
            "operation": "login",
            "duration": time.time() - start_time,
            "status": response.status
        })
        
        # 2. Search documents (3 queries)
        search_queries = [
            "machine learning deployment",
            "company policy remote work", 
            "technical documentation API"
        ]
        
        for query in search_queries:
            start_time = time.time()
            async with session.post(f"{self.base_url}/search", 
                                   json={"query": query, "max_results": 5},
                                   headers=headers) as response:
                session_results.append({
                    "operation": "search",
                    "duration": time.time() - start_time,
                    "status": response.status,
                    "query": query
                })
        
        # 3. List documents
        start_time = time.time()
        async with session.get(f"{self.base_url}/documents?page=1&page_size=20",
                              headers=headers) as response:
            session_results.append({
                "operation": "list_documents",
                "duration": time.time() - start_time,
                "status": response.status
            })
        
        return session_results
    
    async def run_load_test(self, duration_seconds: int = 300):
        """Run load test for specified duration"""
        print(f"Starting load test with {self.concurrent_users} concurrent users for {duration_seconds}s")
        
        connector = aiohttp.TCPConnector(limit=self.concurrent_users * 2)
        timeout = aiohttp.ClientTimeout(total=60)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            # Create semaphore to limit concurrent requests
            semaphore = asyncio.Semaphore(self.concurrent_users)
            
            async def limited_user_session(user_id: int):
                async with semaphore:
                    return await self.simulate_user_session(session, user_id)
            
            # Run for specified duration
            start_time = time.time()
            user_counter = 0
            
            while time.time() - start_time < duration_seconds:
                # Start batch of concurrent users
                tasks = [
                    limited_user_session(user_counter + i) 
                    for i in range(min(50, self.concurrent_users))
                ]
                
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for result in batch_results:
                    if isinstance(result, list):
                        self.results.extend(result)
                
                user_counter += len(tasks)
                
                # Brief pause between batches
                await asyncio.sleep(1)
        
        self.analyze_results()
    
    def analyze_results(self):
        """Analyze load test results"""
        if not self.results:
            print("No results to analyze")
            return
        
        operations = {}
        for result in self.results:
            op = result["operation"]
            if op not in operations:
                operations[op] = {"durations": [], "success_count": 0, "error_count": 0}
            
            operations[op]["durations"].append(result["duration"])
            if result["status"] < 400:
                operations[op]["success_count"] += 1
            else:
                operations[op]["error_count"] += 1
        
        print("\n" + "="*50)
        print("LOAD TEST RESULTS")
        print("="*50)
        
        for op, data in operations.items():
            durations = data["durations"]
            total_requests = len(durations)
            success_rate = (data["success_count"] / total_requests) * 100
            
            print(f"\nOperation: {op.upper()}")
            print(f"Total Requests: {total_requests}")
            print(f"Success Rate: {success_rate:.1f}%")
            print(f"Average Response Time: {statistics.mean(durations):.3f}s")
            print(f"95th Percentile: {statistics.quantiles(durations, n=20)[18]:.3f}s")
            print(f"Max Response Time: {max(durations):.3f}s")
            print(f"Min Response Time: {min(durations):.3f}s")

# Usage
async def main():
    tester = LoadTester("http://localhost:8000/api", concurrent_users=50)
    await tester.run_load_test(duration_seconds=180)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## 10. CHECKLIST & VERIFICATION

### 10.1 Implementation Checklist

#### **Phase 1: Environment Setup** ✅
- [ ] Development environment configured
- [ ] All required packages installed
- [ ] Docker services running (PostgreSQL, Redis, Elasticsearch)
- [ ] Database schema created and migrated
- [ ] Virtual environment activated and dependencies installed

#### **Phase 2: Core Infrastructure** ✅
- [ ] Configuration management implemented
- [ ] Database connection with retry logic
- [ ] JWT authentication system
- [ ] Error handling middleware
- [ ] Request/Response models defined
- [ ] Base API structure created

#### **Phase 3: API Endpoints** ✅
- [ ] Documents API (`/api/documents`) fully implemented
- [ ] Users API (`/api/users`) fully implemented  
- [ ] Search API (`/api/search`) fully implemented
- [ ] Access Control API (`/api/access-control`) fully implemented
- [ ] All CRUD operations working
- [ ] Proper permission checks implemented

#### **Phase 4: Testing** ✅
- [ ] Unit tests written and passing (>80% coverage)
- [ ] Integration tests implemented and passing
- [ ] API endpoint tests comprehensive
- [ ] Performance tests meeting requirements (<60s response time)
- [ ] Security tests completed
- [ ] Load testing with 100 concurrent users

#### **Phase 5: Production Ready** ✅
- [ ] Error handling and circuit breakers implemented
- [ ] Monitoring and metrics collection setup
- [ ] Structured logging implemented
- [ ] Health check endpoints working
- [ ] Docker image built and tested
- [ ] Kubernetes manifests prepared
- [ ] Deployment scripts tested

### 10.2 Final Verification Commands

#### **API Functionality Tests**
```bash
# Test all endpoints are responding
curl -X GET http://localhost:8000/health/detailed
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"testuser","password":"testpassword"}'

# Test document operations (with auth token)
TOKEN="your_jwt_token_here"
curl -X GET http://localhost:8000/api/documents \
  -H "Authorization: Bearer $TOKEN"

curl -X POST http://localhost:8000/api/search \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"query":"test search","search_type":"semantic"}'
```

#### **Performance Verification**
```bash
# Run load test
python tests/performance/load_test.py

# Check response times are under 60 seconds
ab -n 1000 -c 10 http://localhost:8000/api/documents
```

#### **Security Verification**
```bash
# Security scan
bandit -r app/
safety check

# Test unauthorized access
curl -X GET http://localhost:8000/api/documents  # Should return 401
```

---

## 🎯 **KÍCH HOẠT IMPLEMENTATION**

Team kỹ thuật có thể bắt đầu implement FR-02.2 bằng cách:

1. **Clone repository template** (nếu có) hoặc tạo project structure theo hướng dẫn
2. **Chạy setup script**:
   ```bash
   chmod +x setup.sh
   ./setup.sh
   ```
3. **Follow step-by-step guide** từ Phase 1 đến Phase 5
4. **Sử dụng checkpoint system** để verify từng bước
5. **Deploy theo production checklist**

Tài liệu này cung cấp đầy đủ roadmap để implement một API Gateway hoàn chỉnh, production-ready cho hệ thống Knowledge Assistant! 🚀

CÃ¢u há»i nÃ y ráº¥t HAY vÃ  cháº¡m Ä‘Ãºng vÃ o **nghiá»‡p vá»¥ khÃ³ nháº¥t cá»§a RAG**! ğŸ¯

ÄÃ¢y lÃ  case **khÃ¡c hoÃ n toÃ n** vá»›i viá»‡c tÃ¬m cÄƒn cá»© phÃ¡p lÃ½. Äá»ƒ tÃ´i phÃ¢n tÃ­ch chi tiáº¿t:

---

## **ğŸ“‹ PhÃ¢n loáº¡i 2 nghiá»‡p vá»¥ khÃ¡c nhau**

| Äáº·c Ä‘iá»ƒm | **TÃ¬m cÄƒn cá»© phÃ¡p lÃ½** | **TÃ¬m tiÃªu chuáº©n/cÃ¡ch lÃ m** |
|----------|------------------------|----------------------------|
| **User biáº¿t gÃ¬?** | âœ… Biáº¿t vÄƒn báº£n nÃ o (document_id) | â“ KHÃ”NG biáº¿t á»Ÿ vÄƒn báº£n nÃ o |
| **User biáº¿t tá»« khÃ³a?** | âœ… "CÄƒn cá»©", "Quyáº¿t Ä‘á»‹nh" | âŒ KhÃ´ng biáº¿t tá»« khÃ³a chÃ­nh xÃ¡c |
| **Vá»‹ trÃ­ info** | âœ… Äáº§u vÄƒn báº£n (predictable) | âŒ Báº¥t ká»³ Ä‘Ã¢u trong corpus |
| **Cáº¥u trÃºc** | âœ… Format chuáº©n | âŒ Nhiá»u cÃ¡ch diá»…n Ä‘áº¡t khÃ¡c nhau |
| **Scope** | ğŸ¯ 1 document | ğŸŒ ToÃ n bá»™ corpus |
| **Äá»™ khÃ³** | â­â­ Trung bÃ¬nh | â­â­â­â­â­ Ráº¥t khÃ³ |

---

## **ğŸ” VÃ­ dá»¥ thá»±c táº¿ vá» "TÃ¬m tiÃªu chuáº©n"**

### **User query:**
> "Má»©c sÃ¡ng bao nhiÃªu lÃ  Ä‘áº¡t chuáº©n?"

### **ThÃ¡ch thá»©c:**
1. âŒ KhÃ´ng biáº¿t tá»« khÃ³a: "Ä‘á»™ sÃ¡ng"? "cÆ°á»ng Ä‘á»™ Ã¡nh sÃ¡ng"? "lux"? "luminance"?
2. âŒ KhÃ´ng biáº¿t vÄƒn báº£n nÃ o: TiÃªu chuáº©n xÃ¢y dá»±ng? ISO? TCVN? Ná»™i bá»™ cÃ´ng ty?
3. âŒ KhÃ´ng biáº¿t format: "dÆ°á»›i 20%"? "< 200 lux"? "khÃ´ng Ä‘á»§ sÃ¡ng"?
4. âŒ ThÃ´ng tin cÃ³ thá»ƒ ráº£i rÃ¡c nhiá»u Ä‘oáº¡n

---

## **ğŸ¯ CÃ¡c Approach phÃ¹ há»£p**

### **âŒ Approach KHÃ”NG phÃ¹ há»£p**

```python
# âŒ SAI: Filter theo document_id
semantic_search(
    query="má»©c sÃ¡ng",
    document_id="xxx"  # â† User khÃ´ng biáº¿t document nÃ o!
)

# âŒ SAI: Keyword search
keyword_search("má»©c sÃ¡ng")  # â† VÄƒn báº£n cÃ³ thá»ƒ dÃ¹ng "Ä‘á»™ sÃ¡ng", "Ã¡nh sÃ¡ng"

# âŒ SAI: BM25 
bm25_search("20%")  # â† KhÃ´ng biáº¿t chÃ­nh xÃ¡c sá»‘ liá»‡u
```

### **âœ… Approach 1: Semantic Search ToÃ n Corpus + LLM** (Recommended)

```python
# BÆ°á»›c 1: Semantic search KHÃ”NG filter document_id
results = semantic_search(
    query="tiÃªu chuáº©n Ä‘á»™ sÃ¡ng yÃªu cáº§u tá»‘i thiá»ƒu",
    top_k=30,  # Láº¥y nhiá»u Ä‘á»ƒ Ä‘áº£m báº£o coverage
    # âœ… KHÃ”NG cÃ³ document_id filter
)

# BÆ°á»›c 2: LLM reasoning
llm_prompt = f"""
Dá»±a trÃªn cÃ¡c Ä‘oáº¡n vÄƒn báº£n sau:

{results}

CÃ¢u há»i: {user_query}

Nhiá»‡m vá»¥:
1. TÃ¬m cÃ¡c tiÃªu chuáº©n vá» má»©c sÃ¡ng
2. TrÃ­ch dáº«n CHÃNH XÃC sá»‘ liá»‡u vÃ  nguá»“n
3. Náº¿u cÃ³ nhiá»u tiÃªu chuáº©n khÃ¡c nhau, liá»‡t kÃª táº¥t cáº£
4. Náº¿u KHÃ”NG tÃ¬m tháº¥y, tráº£ lá»i "KhÃ´ng tÃ¬m tháº¥y trong tÃ i liá»‡u"
"""
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… KhÃ´ng cáº§n biáº¿t document_id
- âœ… KhÃ´ng cáº§n biáº¿t tá»« khÃ³a chÃ­nh xÃ¡c
- âœ… LLM cÃ³ thá»ƒ reasoning tá»« nhiá»u chunks
- âœ… CÃ³ thá»ƒ tÃ¬m tháº¥y info dÃ¹ diá»…n Ä‘áº¡t khÃ¡c

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ CÃ³ thá»ƒ miss náº¿u diá»…n Ä‘áº¡t quÃ¡ khÃ¡c (vÃ­ dá»¥: "illumination" thay vÃ¬ "Ã¡nh sÃ¡ng")
- âš ï¸ Tá»‘n token náº¿u top_k lá»›n

---

### **âœ… Approach 2: Multi-Query Expansion**

VÃ¬ user khÃ´ng biáº¿t tá»« khÃ³a chÃ­nh xÃ¡c, ta má»Ÿ rá»™ng query:

```python
# BÆ°á»›c 1: LLM expand query
expanded_queries = llm_expand_query(
    original_query="má»©c sÃ¡ng bao nhiÃªu lÃ  Ä‘áº¡t chuáº©n?"
)
# Output:
# - "tiÃªu chuáº©n Ä‘á»™ sÃ¡ng tá»‘i thiá»ƒu"
# - "cÆ°á»ng Ä‘á»™ Ã¡nh sÃ¡ng yÃªu cáº§u"
# - "má»©c lux quy Ä‘á»‹nh"
# - "Ä‘á»™ rá»i tiÃªu chuáº©n"

# BÆ°á»›c 2: Search vá»›i má»—i query
all_results = []
for query in expanded_queries:
    results = semantic_search(query, top_k=10)
    all_results.extend(results)

# BÆ°á»›c 3: Deduplicate vÃ  rank
final_results = deduplicate_and_rerank(all_results)

# BÆ°á»›c 4: LLM tá»•ng há»£p
answer = llm_synthesize(final_results, original_query)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… âœ… Coverage tá»‘t hÆ¡n (nhiá»u cÃ¡ch diá»…n Ä‘áº¡t)
- âœ… TÃ¬m Ä‘Æ°á»£c dÃ¹ tá»« khÃ³a khÃ¡c hoÃ n toÃ n

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ Nhiá»u API calls hÆ¡n
- âš ï¸ Tá»‘n token nhiá»u

---

### **âœ… Approach 3: Metadata-Guided Search**

Náº¿u metadata cÃ³ tags tá»‘t:

```python
# BÆ°á»›c 1: Filter theo metadata category
results = semantic_search(
    query="má»©c sÃ¡ng",
    top_k=20,
    metadata_filters={
        "category": ["TiÃªu chuáº©n ká»¹ thuáº­t", "Quy chuáº©n"],
        "domain": ["XÃ¢y dá»±ng", "Äiá»‡n", "An toÃ n lao Ä‘á»™ng"]
    }
)

# BÆ°á»›c 2: LLM extract
answer = llm_extract_standards(results)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Giáº£m noise (chá»‰ search trong tiÃªu chuáº©n)
- âœ… Nhanh hÆ¡n

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ Cáº§n metadata tá»‘t (FR03.3 chá»‰ cÃ³ 5% metadata)

---

### **âœ… Approach 4: Hybrid vá»›i Substring cho sá»‘ liá»‡u**

Náº¿u user há»i vá» sá»‘ cá»¥ thá»ƒ:

```python
# User query: "TÃ´i cÃ³ káº¿t quáº£ Ä‘o 18%, Ä‘áº¡t chuáº©n khÃ´ng?"

# BÆ°á»›c 1: Semantic search
semantic_results = semantic_search("tiÃªu chuáº©n má»©c sÃ¡ng", top_k=20)

# BÆ°á»›c 2: Substring search cho pattern sá»‘
pattern_results = substring_search(
    patterns=["20%", "< 20", "dÆ°á»›i 20", "trÃªn 20"],
    filters={"category": "TiÃªu chuáº©n"}
)

# BÆ°á»›c 3: Merge
combined = merge_results(semantic_results, pattern_results)

# BÆ°á»›c 4: LLM reasoning
answer = llm_compare_with_standard(
    user_value=18,
    standard_chunks=combined
)
```

---

### **âœ… Approach 5: Graph RAG (NÃ¢ng cao)**

Náº¿u tiÃªu chuáº©n cÃ³ hierarchy:

```
TCVN 123:2020 (TiÃªu chuáº©n tá»•ng)
    â”œâ”€ ChÆ°Æ¡ng 3: Ãnh sÃ¡ng
    â”‚   â”œâ”€ Äiá»u 3.1: NÆ¡i lÃ m viá»‡c (> 300 lux)
    â”‚   â”œâ”€ Äiá»u 3.2: HÃ nh lang (> 150 lux)
    â””â”€ ChÆ°Æ¡ng 4: Nhiá»‡t Ä‘á»™
```

```python
# Query graph
graph_results = graph_search(
    query="tiÃªu chuáº©n Ã¡nh sÃ¡ng",
    relation_types=["contains", "specifies"]
)

# LLM synthesize tá»« graph context
answer = llm_with_graph_context(graph_results)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… âœ… Hiá»ƒu cáº¥u trÃºc phÃ¢n cáº¥p
- âœ… CÃ³ thá»ƒ tráº£ lá»i "Ãp dá»¥ng cho trÆ°á»ng há»£p nÃ o?"

---

## **ğŸ¯ Äá» xuáº¥t cho FR03.3**

Dá»±a trÃªn hiá»‡n tráº¡ng FR03.3, tÃ´i Ä‘á» xuáº¥t **Approach 1 + 2 (Semantic + Multi-Query)**:

```python
async def find_technical_standard(
    user_query: str,
    specific_value: Optional[float] = None
) -> Dict[str, Any]:
    """
    TÃ¬m tiÃªu chuáº©n ká»¹ thuáº­t trong corpus
    
    Args:
        user_query: "Má»©c sÃ¡ng bao nhiÃªu lÃ  Ä‘áº¡t?"
        specific_value: 18.5 (náº¿u user cÃ³ giÃ¡ trá»‹ cá»¥ thá»ƒ)
    """
    
    # Step 1: Expand query vá»›i LLM
    expanded_queries = await llm_expand_query(user_query)
    logger.info(f"Expanded to {len(expanded_queries)} queries")
    
    # Step 2: Search vá»›i má»—i query variant
    all_chunks = []
    for query in expanded_queries:
        chunks = await semantic_search(
            query=query,
            top_k=15,
            # âœ… KHÃ”NG filter document_id
        )
        all_chunks.extend(chunks)
    
    # Step 3: Deduplicate
    unique_chunks = deduplicate_by_chunk_id(all_chunks)
    
    # Step 4: Rerank theo relevance
    reranked = rerank_chunks(unique_chunks, user_query)
    top_chunks = reranked[:20]  # Láº¥y top 20 relevant nháº¥t
    
    # Step 5: LLM extract vÃ  reasoning
    llm_prompt = f"""
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch tiÃªu chuáº©n ká»¹ thuáº­t.

CÃ¡c Ä‘oáº¡n vÄƒn báº£n tÃ¬m Ä‘Æ°á»£c:
{format_chunks(top_chunks)}

CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: "{user_query}"
{"GiÃ¡ trá»‹ cáº§n kiá»ƒm tra: " + str(specific_value) if specific_value else ""}

Nhiá»‡m vá»¥:
1. TÃ¬m Táº¤T Cáº¢ cÃ¡c tiÃªu chuáº©n liÃªn quan
2. TrÃ­ch dáº«n CHÃNH XÃC:
   - Sá»‘ hiá»‡u tiÃªu chuáº©n (vÃ­ dá»¥: TCVN 123:2020)
   - GiÃ¡ trá»‹ cá»¥ thá»ƒ (vÃ­ dá»¥: > 300 lux, < 20%)
   - Äiá»u khoáº£n (vÃ­ dá»¥: Äiá»u 3.1)
3. Náº¿u user cÃ³ giÃ¡ trá»‹ cá»¥ thá»ƒ, so sÃ¡nh vÃ  káº¿t luáº­n Ä‘áº¡t/khÃ´ng Ä‘áº¡t
4. Náº¿u cÃ³ nhiá»u tiÃªu chuáº©n Ã¡p dá»¥ng cho ngá»¯ cáº£nh khÃ¡c nhau, giáº£i thÃ­ch rÃµ
5. Náº¿u KHÃ”NG tÃ¬m tháº¥y, tráº£ lá»i: "KhÃ´ng tÃ¬m tháº¥y tiÃªu chuáº©n vá» [X] trong cÆ¡ sá»Ÿ dá»¯ liá»‡u"

Format output:
## TiÃªu chuáº©n tÃ¬m Ä‘Æ°á»£c:
1. [TÃªn tiÃªu chuáº©n] - [Sá»‘ hiá»‡u]
   - YÃªu cáº§u: [GiÃ¡ trá»‹ cá»¥ thá»ƒ]
   - Nguá»“n: [Document title], [Chunk position]

## Káº¿t luáº­n:
[So sÃ¡nh vá»›i giÃ¡ trá»‹ user náº¿u cÃ³]
"""
    
    answer = await llm_call(llm_prompt)
    
    return {
        "query": user_query,
        "expanded_queries": expanded_queries,
        "chunks_found": len(top_chunks),
        "answer": answer,
        "sources": [format_source(c) for c in top_chunks]
    }
```

---

## **ğŸ“Š So sÃ¡nh approaches cho "TÃ¬m tiÃªu chuáº©n"**

| Approach | Coverage | Accuracy | Speed | Cost | Best for |
|----------|----------|----------|-------|------|----------|
| **Semantic only** | â­â­â­ | â­â­â­ | âš¡âš¡ | ğŸ’° | Query rÃµ rÃ ng |
| **Multi-Query** | â­â­â­â­â­ | â­â­â­â­ | âš¡ | ğŸ’°ğŸ’° | Query mÆ¡ há»“ |
| **Metadata-Guided** | â­â­â­â­ | â­â­â­â­ | âš¡âš¡âš¡ | ğŸ’° | CÃ³ metadata tá»‘t |
| **Hybrid** | â­â­â­â­ | â­â­â­â­â­ | âš¡âš¡ | ğŸ’°ğŸ’° | CÃ³ sá»‘ liá»‡u cá»¥ thá»ƒ |
| **Graph RAG** | â­â­â­â­â­ | â­â­â­â­â­ | âš¡ | ğŸ’°ğŸ’°ğŸ’° | Cáº¥u trÃºc phá»©c táº¡p |

---

## **ğŸ’¡ Test cases thá»±c táº¿**

```python
# Test 1: Query mÆ¡ há»“
query = "Má»©c sÃ¡ng bao nhiÃªu lÃ  Ä‘áº¡t?"
# â†’ Multi-Query approach

# Test 2: Query vá»›i sá»‘ cá»¥ thá»ƒ
query = "18% cÃ³ Ä‘áº¡t chuáº©n khÃ´ng?"
# â†’ Hybrid (semantic + substring "18%", "< 20", "> 20")

# Test 3: Query vá» context cá»¥ thá»ƒ
query = "Má»©c sÃ¡ng trong phÃ²ng lÃ m viá»‡c"
# â†’ Semantic + Metadata filter (category="TiÃªu chuáº©n xÃ¢y dá»±ng")

# Test 4: KhÃ´ng biáº¿t cÃ³ hay khÃ´ng
query = "CÃ³ quy Ä‘á»‹nh vá» nhiá»‡t Ä‘á»™ khÃ´ng?"
# â†’ Semantic search toÃ n corpus â†’ LLM tráº£ lá»i "CÃ³/KhÃ´ng"
```

---

## **ğŸ¯ Káº¿t luáº­n**

Vá»›i nghiá»‡p vá»¥ **"TÃ¬m tiÃªu chuáº©n/cÃ¡ch lÃ m"**, approach khÃ¡c hoÃ n toÃ n:

| Äáº·c Ä‘iá»ƒm | TÃ¬m cÄƒn cá»© phÃ¡p lÃ½ | TÃ¬m tiÃªu chuáº©n |
|----------|-------------------|----------------|
| **Scope** | 1 document (cÃ³ document_id) | ToÃ n corpus |
| **Query expansion** | KhÃ´ng cáº§n | âœ… Ráº¤T Cáº¦N |
| **Top_k** | 10-20 Ä‘á»§ | 30-50 Ä‘á»ƒ coverage |
| **LLM role** | Extract & format | Reasoning & compare |
| **Metadata filter** | KhÃ´ng cáº§n | Há»¯u Ã­ch náº¿u cÃ³ |
| **Reranking** | KhÃ´ng cáº§n | âœ… Cáº¦N Ä‘á»ƒ lá»c noise |

**Äá» xuáº¥t cho FR03.3:**
1. âœ… Implement Multi-Query Expansion
2. âœ… Increase top_k to 30-50
3. âœ… Add reranking layer
4. âœ… Improve LLM prompt cho reasoning
5. ğŸ”® Consider Graph RAG náº¿u cÃ³ budget

Báº¡n muá»‘n tÃ´i code luÃ´n workflow nÃ y khÃ´ng? ğŸš€

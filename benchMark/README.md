## ğŸ“– README.md


# Vietnamese Qwen3 Embedding Benchmark ğŸ‡»ğŸ‡³

CÃ´ng cá»¥ benchmark chuyÃªn dá»¥ng cho model **Qwen/Qwen3-Embedding-0.6B** trÃªn dá»¯ liá»‡u tiáº¿ng Viá»‡t vá»›i tá»‘i Æ°u GPU.

## âœ¨ TÃ­nh nÄƒng

- **ğŸ¯ ChuyÃªn dá»¥ng cho Qwen3**: Tá»‘i Æ°u cho model Qwen/Qwen3-Embedding-0.6B
- **ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t**: Há»— trá»£ Ä‘áº§y Ä‘á»§ xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t (pyvi, underthesea)
- **âš¡ GPU Acceleration**: Tá»± Ä‘á»™ng detect vÃ  sá»­ dá»¥ng GPU/CUDA
- **ğŸ“Š Metrics Ä‘áº§y Ä‘á»§**: MRR, Hit Rate@K, MAP, NDCG, Precision, Recall
- **ğŸ“ˆ Visualizations**: Interactive charts vá»›i Plotly
- **ğŸ“‹ HTML Reports**: BÃ¡o cÃ¡o HTML chi tiáº¿t vÃ  professional

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone project
```bash
git clone <your-repo>
cd vietnamese_qwen3_benchmark
```

### 2. Táº¡o virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows
```

### 3. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 4. CÃ i Ä‘áº·t GPU support (náº¿u cÃ³)
```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1  
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

## ğŸ“Š CÃ¡ch sá»­ dá»¥ng

### Cháº¡y benchmark Ä‘Æ¡n giáº£n
```bash
python benchmark.py
```

### Vá»›i custom config
```bash
python benchmark.py --config configs/model_config.json --verbose
```

### Cáº¥u trÃºc sau khi cháº¡y
```
vietnamese_qwen3_benchmark/
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ benchmark_report.html          # BÃ¡o cÃ¡o HTML chÃ­nh
â”‚   â”œâ”€â”€ benchmark_results_20241201_143022.json
â”‚   â”œâ”€â”€ chunks_info.json               # Debug info cho chunks
â”‚   â””â”€â”€ charts/
â”‚       â”œâ”€â”€ metrics_overview.html      # Interactive charts
â”‚       â”œâ”€â”€ detailed_analysis.html
â”‚       â”œâ”€â”€ performance_radar.html
â”‚       â””â”€â”€ category_performance.html
â””â”€â”€ model_cache/                       # Cached models
```

## âš™ï¸ Configuration

### TÃ¹y chá»‰nh model trong `configs/model_config.json`:
```json
{
  "model": {
    "name": "Qwen/Qwen3-Embedding-0.6B",  // â† Thay Ä‘á»•i model á»Ÿ Ä‘Ã¢y
    "device": "auto",
    "batch_size": 32,
    "max_seq_length": 512,
    "normalize_embeddings": true
  }
}
```

### Thay Ä‘á»•i dá»¯ liá»‡u test:
- **Content**: Chá»‰nh sá»­a `data/content.md`
- **Questions**: Cáº­p nháº­t `data/test_suite.json`

## ğŸ“ˆ Metrics Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡

| Metric | MÃ´ táº£ | Má»¥c tiÃªu |
|--------|-------|----------|
| **MRR** | Mean Reciprocal Rank | > 0.65 |
| **Hit Rate@1** | Top-1 accuracy | > 50% |
| **Hit Rate@5** | Top-5 accuracy | > 75% |
| **Precision@5** | Precision at 5 | > 0.6 |
| **NDCG@5** | Ranking quality | > 0.6 |
| **MAP@5** | Mean Average Precision | > 0.5 |

## ğŸ¯ Káº¿t quáº£ máº«u

```
ğŸ‰ BENCHMARK COMPLETED SUCCESSFULLY!
============================================================
â±ï¸  Total time: 45.23s
ğŸ¯ Overall MRR: 0.724
ğŸ“Š Hit Rate@5: 81.2%
ğŸ’¾ Reports saved in: /path/to/reports
```

## ğŸ”§ Troubleshooting

### CUDA Out of Memory
```bash
# Giáº£m batch size trong config
"batch_size": 16  # hoáº·c 8
```

### Model khÃ´ng táº£i Ä‘Æ°á»£c
```bash
# XÃ³a cache vÃ  thá»­ láº¡i
rm -rf model_cache/
python benchmark.py
```

### Lá»—i Vietnamese NLP
```bash
pip uninstall underthesea pyvi
pip install underthesea pyvi
```

## ğŸ“Š Hiá»ƒu káº¿t quáº£

### Performance Levels:
- **Excellent** (MRR â‰¥ 0.7): Sáºµn sÃ ng production
- **Good** (MRR â‰¥ 0.5): CÃ³ thá»ƒ sá»­ dá»¥ng vá»›i optimizations
- **Average** (MRR â‰¥ 0.3): Cáº§n fine-tuning
- **Poor** (MRR < 0.3): Cáº§n Ä‘á»•i model hoáº·c cáº£i thiá»‡n data

### PhÃ¢n tÃ­ch Category:
- Kiá»ƒm tra category nÃ o cÃ³ hiá»‡u suáº¥t tháº¥p nháº¥t
- Xem cÃ¢u há»i nÃ o khÃ³ nháº¥t (khÃ´ng tÃ¬m tháº¥y trong top-5)
- PhÃ¢n tÃ­ch score gap giá»¯a top-1 vÃ  correct answer

## ğŸ”„ Workflow tÃ¹y chá»‰nh

### Thay Ä‘á»•i model
```bash
# Chá»‰nh sá»­a configs/model_config.json
{
  "model": {
    "name": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  }
}
```

### ThÃªm dá»¯ liá»‡u má»›i
```bash
# 1. Cáº­p nháº­t data/content.md vá»›i ná»™i dung má»›i
# 2. Táº¡o cÃ¢u há»i tÆ°Æ¡ng á»©ng trong data/test_suite.json
# 3. Cháº¡y benchmark
python benchmark.py
```

### Batch processing nhiá»u models
```bash
# Táº¡o script Ä‘á»ƒ test nhiá»u models
for model in "Qwen/Qwen3-Embedding-0.6B" "sentence-transformers/LaBSE"
do
    echo "Testing $model"
    # Update config and run
    python benchmark.py --config configs/${model//\//_}.json
done
```

## ğŸ›ï¸ Advanced Usage

### Memory optimization
```python
# Trong embedding_manager.py, tÃ¹y chá»‰nh:
def _get_optimal_batch_size(self, requested_batch_size: int) -> int:
    if self.device == "cuda":
        available_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        if available_memory < 4:
            return 8    # Giáº£m cho GPU nhá»
        elif available_memory >= 16:
            return 128  # TÄƒng cho GPU lá»›n
```

### Custom metrics
```python
# Trong src/metrics.py, thÃªm metric má»›i:
def calculate_custom_metric(self, search_results, ground_truth):
    # Custom logic here
    return custom_score
```

## ğŸ“ Logs vÃ  Debug

### Enable verbose logging
```bash
python benchmark.py --verbose
```

### Debug chunks
```bash
# Xem chunks_info.json Ä‘á»ƒ hiá»ƒu cÃ¡ch text Ä‘Æ°á»£c chia
cat reports/chunks_info.json | jq '.chunks[0]'
```

### Memory monitoring
```bash
# Theo dÃµi GPU memory trong quÃ¡ trÃ¬nh cháº¡y
watch -n 1 nvidia-smi
```

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o feature branch: `git checkout -b feature/new-feature`
3. Test vá»›i Vietnamese data
4. Commit: `git commit -m 'Add Vietnamese feature'`
5. Push: `git push origin feature/new-feature`
6. Táº¡o Pull Request

## ğŸ“„ License

MIT License - xem LICENSE file.

## ğŸ™ Credits

- [Qwen Team](https://github.com/QwenLM/Qwen) - Qwen3-Embedding model
- [Sentence Transformers](https://www.sbert.net/) - Embedding framework
- [underthesea](https://github.com/undertheseanlp/underthesea) - Vietnamese NLP
- [pyvi](https://github.com/trungtv/pyvi) - Vietnamese tokenization

---

**Happy Benchmarking! ğŸš€**

Náº¿u gáº·p váº¥n Ä‘á», táº¡o issue trong repository hoáº·c liÃªn há»‡ qua email.
```

## ğŸ¯ HÆ°á»›ng dáº«n cháº¡y nhanh:

### 1. CÃ i Ä‘áº·t cÆ¡ báº£n:
```bash
# Clone vÃ  setup
git clone <repo>
cd vietnamese_qwen3_benchmark

# Virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Cháº¡y benchmark:
```bash
python benchmark.py
```

### 3. Xem káº¿t quáº£:
- Má»Ÿ `reports/benchmark_report.html` trong browser
- Xem cÃ¡c charts interactive trong `reports/charts/`
- Kiá»ƒm tra JSON results cho detailed data

## ğŸ”§ Äiá»u chá»‰nh model:

Äá»ƒ thay Ä‘á»•i model, chá»‰nh sá»­a `configs/model_config.json`:
```json
{
  "model": {
    "name": "your-model-name-here",  // â† Thay Ä‘á»•i táº¡i Ä‘Ã¢y
    "device": "auto",
    "batch_size": 32
  }
}
```

## ğŸ“Š Output Structure:

Sau khi cháº¡y xong, báº¡n sáº½ cÃ³:

1. **HTML Report**: `reports/benchmark_report.html` - BÃ¡o cÃ¡o tá»•ng quan
2. **Interactive Charts**: `reports/charts/` - CÃ¡c biá»ƒu Ä‘á»“ interactive
3. **JSON Results**: `reports/benchmark_results_*.json` - Dá»¯ liá»‡u chi tiáº¿t
4. **Debug Info**: `reports/chunks_info.json` - ThÃ´ng tin chunks

## ğŸ¯ Expected Performance:

Vá»›i Qwen3-Embedding-0.6B trÃªn Vietnamese data:
- **MRR**: 0.65-0.75 (good range)  
- **Hit Rate@5**: 75-85%
- **Processing Speed**: 50-100 texts/second (GPU)
- **Memory Usage**: ~2-4GB GPU RAM

Project nÃ y Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘áº·c biá»‡t cho Vietnamese text processing vÃ  Qwen3 model, vá»›i GPU acceleration vÃ  comprehensive metrics Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ performance má»™t cÃ¡ch chÃ­nh xÃ¡c nháº¥t.

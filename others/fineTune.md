Dá»±a trÃªn project knowledge, tÃ´i tháº¥y **cÃ³ nÃªn cÃ³ tÃ i liá»‡u máº«u** trÆ°á»›c khi thiáº¿t káº¿ database. 

**Sá»‘ lÆ°á»£ng tÃ i liá»‡u máº«u khuyáº¿n nghá»‹:**
- **Tá»‘i thiá»ƒu 20-30 tÃ i liá»‡u** Ä‘áº¡i diá»‡n cho cÃ¡c loáº¡i chÃ­nh:
  - Policy (5-7 tÃ i liá»‡u)
  - Procedure (5-7 tÃ i liá»‡u) 
  - Technical Guide (5-7 tÃ i liá»‡u)
  - Report (5-7 tÃ i liá»‡u)

**LÃ½ do cáº§n tÃ i liá»‡u máº«u:**
1. **XÃ¡c Ä‘á»‹nh metadata structure** - Hiá»ƒu rÃµ trÆ°á»ng nÃ o thá»±c sá»± cáº§n thiáº¿t
2. **Test access levels** - Äáº£m báº£o phÃ¢n quyá»n 4 cáº¥p hoáº¡t Ä‘á»™ng Ä‘Ãºng
3. **Validate chunking strategy** - Tá»‘i Æ°u size 500-1000 tokens
4. **Design tagging system** - PhÃ¡t triá»ƒn taxonomy phÃ¹ há»£p

Project Ä‘Ã£ cÃ³ schema chi tiáº¿t nhÆ°ng cáº§n tÃ i liá»‡u thá»±c táº¿ Ä‘á»ƒ validate vÃ  fine-tune trÆ°á»›c khi implement chÃ­nh thá»©c.
---
CÃ³ 2 lÃ½ do chÃ­nh cáº§n **fine-tuning** embedding model dá»±a trÃªn project knowledge:

## **LÃ½ do 1: Tá»‘i Æ°u cho dá»¯ liá»‡u ná»™i bá»™**

Há»‡ thá»‘ng pháº£i há»— trá»£ fine-tuning model trÃªn dá»¯ liá»‡u ná»™i bá»™ vÃ¬:

- **Domain-specific vocabulary**: TÃ i liá»‡u cÃ´ng ty cÃ³ thuáº­t ngá»¯ chuyÃªn ngÃ nh, tá»« viáº¿t táº¯t riÃªng
- **Ngá»¯ cáº£nh Ä‘áº·c thÃ¹**: CÃ¡ch diá»…n Ä‘áº¡t, phong cÃ¡ch viáº¿t cá»§a tá»• chá»©c
- **Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c**: Model AITeamVN/Vietnamese_Embedding Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c vÆ°á»£t trá»™i vá»›i 11 trÃªn 16 cÃ¢u há»i Ä‘Ãºng á»Ÿ vá»‹ trÃ­ top 1

## **LÃ½ do 2: Xá»­ lÃ½ Ä‘iá»ƒm yáº¿u cá»§a model**

Háº§u háº¿t cÃ¡c model hÃ ng Ä‘áº§u Ä‘á»u tháº¥t báº¡i á»Ÿ 2 cÃ¢u há»i giá»‘ng nhau vá» nhá»¯ng thÃ¡ch thá»©c chÃ­nh cá»§a AI vÃ  tÆ°Æ¡ng lai AI táº¡i Viá»‡t Nam. Fine-tuning giÃºp:

- Cáº£i thiá»‡n kháº£ nÄƒng xá»­ lÃ½ **cÃ¢u há»i trá»«u tÆ°á»£ng**
- Tá»‘i Æ°u cho **ngá»¯ cáº£nh tiáº¿ng Viá»‡t** cá»¥ thá»ƒ cá»§a cÃ´ng ty
- Giáº£m **false negatives** cho cÃ¡c truy váº¥n quan trá»ng

**Káº¿t luáº­n**: Fine-tuning khÃ´ng báº¯t buá»™c ban Ä‘áº§u, nhÆ°ng cáº§n thiáº¿t Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t cho dá»¯ liá»‡u ná»™i bá»™ sau khi há»‡ thá»‘ng Ä‘Ã£ hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.
---
Dá»±a trÃªn project knowledge, Ä‘Ã¢y lÃ  **thá»±c tráº¡ng vá» fine-tuning embedding models**:

## **ğŸ¯ THá»°C HIá»†N FINE-TUNING**

### **CÃ¡ch thá»±c hiá»‡n:**

**BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u**
- Tá»‘i thiá»ƒu **1000-5000 cáº·p (query, document)** tá»« dá»¯ liá»‡u ná»™i bá»™  
- Format: Question-Answer pairs tá»« tÃ i liá»‡u thá»±c táº¿
- Label positive/negative samples

**BÆ°á»›c 2: Chá»n base model phÃ¹ há»£p**
- AITeamVN/Vietnamese_Embedding cÃ³ Ä‘á»™ chÃ­nh xÃ¡c vÆ°á»£t trá»™i vá»›i 11 trÃªn 16 cÃ¢u há»i Ä‘Ãºng á»Ÿ vá»‹ trÃ­ top 1
- paraphrase-multilingual-MiniLM-L12-v2 cÃ¢n báº±ng tá»‘t vá»›i dimension chá»‰ 384

**BÆ°á»›c 3: Training process**
```python
# Sá»­ dá»¥ng sentence-transformers framework
from sentence_transformers import SentenceTransformer, losses
model.fit(train_objectives=[(train_dataloader, losses.MultipleNegativesRankingLoss())])
```

## **ğŸ” HIá»†U QUáº¢ THá»°C Táº¾**

### **âœ… Lá»£i Ã­ch Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh:**
- **Cáº£i thiá»‡n domain-specific terms**: Hiá»ƒu thuáº­t ngá»¯ chuyÃªn ngÃ nh tá»‘t hÆ¡n
- **Giáº£m false negatives**: Táº¥t cáº£ model Ä‘á»u tháº¥t báº¡i á»Ÿ cÃ¢u há»i trá»«u tÆ°á»£ng nhÆ° "Nhá»¯ng thÃ¡ch thá»©c chÃ­nh cá»§a AI hiá»‡n nay lÃ  gÃ¬?"
- **TÄƒng precision**: Äáº·c biá»‡t vá»›i cÃ¢u há»i cÃ³ ngá»¯ cáº£nh Ä‘áº·c thÃ¹

### **âŒ Háº¡n cháº¿ thá»±c táº¿:**
- **Chi phÃ­ cao**: Cáº§n GPU, thá»i gian training 1-3 ngÃ y
- **Risk overfitting**: Model cÃ³ thá»ƒ "há»c thuá»™c lÃ²ng" training data
- **KhÃ´ng Ä‘áº£m báº£o**: CÃ¡c model chuyÃªn biá»‡t cho Tiáº¿ng Viá»‡t khÃ´ng pháº£i lÃºc nÃ o cÅ©ng tá»‘t hÆ¡n model Ä‘a ngÃ´n ngá»¯

## **ğŸ’¡ KHUYáº¾N NGHá»Š THá»°C Táº¾**

**Giai Ä‘oáº¡n 1**: Sá»­ dá»¥ng model sáºµn cÃ³ 6-12 thÃ¡ng Ä‘áº§u
**Giai Ä‘oáº¡n 2**: Thu tháº­p dá»¯ liá»‡u feedback tá»« users thá»±c táº¿  
**Giai Ä‘oáº¡n 3**: Fine-tune náº¿u cÃ³ Ä‘á»§ data quality vÃ  tháº¥y rÃµ bottleneck

**ROI Æ°á»›c tÃ­nh**: 5-15% cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c, nhÆ°ng cáº§n Ä‘áº§u tÆ° 2-4 weeks engineering effort.
---
Sau khi fine-tuning, báº¡n sáº½ cÃ³ **MODEL Má»šI hoÃ n chá»‰nh**, khÃ´ng pháº£i chá»‰ lÃ  fine-tune data.

## **ğŸ¯ OUTPUT Cá»¦A FINE-TUNING**

### **Báº¡n nháº­n Ä‘Æ°á»£c:**
```
ğŸ“¦ Fine-tuned Model Package:
â”œâ”€â”€ ğŸ“ model_files/
â”‚   â”œâ”€â”€ pytorch_model.bin       # Model weights má»›i
â”‚   â”œâ”€â”€ config.json            # Cáº¥u hÃ¬nh model
â”‚   â”œâ”€â”€ tokenizer.json         # Tokenizer (náº¿u cÃ³ thay Ä‘á»•i)
â”‚   â””â”€â”€ training_args.json     # ThÃ´ng sá»‘ training
â”œâ”€â”€ ğŸ“ evaluation_results/
â”‚   â”œâ”€â”€ performance_metrics.json
â”‚   â””â”€â”€ comparison_report.pdf
â””â”€â”€ ğŸ“„ deployment_guide.md
```

### **Model má»›i nÃ y:**
- âœ… **HoÃ n toÃ n Ä‘á»™c láº­p** - khÃ´ng cáº§n base model gá»‘c
- âœ… **Drop-in replacement** - thay tháº¿ trá»±c tiáº¿p model cÅ©  
- âœ… **Giá»¯ nguyÃªn API** - khÃ´ng cáº§n thay Ä‘á»•i code production
- âœ… **CÃ¹ng dimension** - vector embedding size khÃ´ng Ä‘á»•i

## **ğŸ”„ DEPLOYMENT PROCESS**

### **Triá»ƒn khai Ä‘Æ¡n giáº£n:**
```python
# TrÆ°á»›c fine-tuning
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# Sau fine-tuning  
model = SentenceTransformer('./path/to/your-finetuned-model')

# API hoÃ n toÃ n giá»‘ng nhau
embeddings = model.encode(texts)
```

### **Zero downtime deployment:**
1. **Stage 1**: Load model má»›i song song vá»›i model cÅ©
2. **Stage 2**: A/B test vá»›i 10% traffic
3. **Stage 3**: Chuyá»ƒn hoÃ n toÃ n sang model má»›i

## **ğŸ“Š VÃ Dá»¤ THá»°C Táº¾**

Vá»›i model **AITeamVN/Vietnamese_Embedding** cÃ³ Ä‘á»™ chÃ­nh xÃ¡c vÆ°á»£t trá»™i (11/16 cÃ¢u Ä‘Ãºng á»Ÿ top 1), sau fine-tuning cÃ³ thá»ƒ cáº£i thiá»‡n lÃªn **13-14/16 cÃ¢u** Ä‘áº·c biá»‡t cho nhá»¯ng cÃ¢u há»i trá»«u tÆ°á»£ng mÃ  táº¥t cáº£ model Ä‘á»u tháº¥t báº¡i.

**Káº¿t luáº­n**: Báº¡n Ä‘Æ°á»£c 1 model má»›i hoÃ n chá»‰nh, khÃ´ng cáº§n giá»¯ láº¡i fine-tune data riÃªng biá»‡t.
---
Dá»±a trÃªn project knowledge, tÃ´i khuyáº¿n nghá»‹ chá»n **`paraphrase-multilingual-MiniLM-L12-v2`** Ä‘á»ƒ fine-tuning vÃ¬ nhá»¯ng lÃ½ do sau:

## **ğŸ¯ KHUYáº¾N NGHá»Š: MiniLM-L12-v2**

### **LÃ½ do chá»n MiniLM thay vÃ¬ AITeamVN:**

**1. Fine-tuning Potential cao hÆ¡n**
- Model nÃ y cÃ³ dimension chá»‰ 384 thay vÃ¬ 1024, nháº¹ hÆ¡n Ä‘Ã¡ng ká»ƒ vÃ  dá»… fine-tune hÆ¡n
- Nhanh hÆ¡n gáº§n 4 láº§n (16.6s vs 64.5s) nÃªn training time ngáº¯n hÆ¡n
- Architecture Ä‘Æ¡n giáº£n hÆ¡n, Ã­t overfitting hÆ¡n vá»›i dá»¯ liá»‡u ná»™i bá»™

**2. Baseline performance tá»‘t**
- MRR 0.7188 - chá»‰ kÃ©m AITeamVN má»™t chÃºt (0.7812)
- Hit Rate@1: 62.5% so vá»›i 68.75%
- CÃ³ "room for improvement" rÃµ rÃ ng qua fine-tuning

**3. Production-ready advantages**
- Chá»‰ cáº§n 0.48 GB VRAM thay vÃ¬ 2.28 GB
- Chi phÃ­ infrastructure tháº¥p hÆ¡n
- Dá»… scale vÃ  deploy

## **ğŸ“Š Dá»° ÄOÃN HIá»†U QUáº¢ FINE-TUNING**

### **MiniLM-L12-v2 (Recommended):**
- **TrÆ°á»›c fine-tune**: MRR 0.7188, Hit@1: 62.5%
- **Sau fine-tune**: MRR 0.80-0.85, Hit@1: 75-80%
- **Improvement**: +15-20% accuracy

### **AITeamVN/Vietnamese_Embedding:**
- **TrÆ°á»›c fine-tune**: MRR 0.7812, Hit@1: 68.75% 
- **Sau fine-tune**: MRR 0.82-0.87, Hit@1: 75-85%
- **Improvement**: +5-10% accuracy

## **ğŸ’° COST-BENEFIT ANALYSIS**

| Metrics | MiniLM-L12-v2 | AITeamVN |
|---------|---------------|----------|
| **Training Time** | 1-2 ngÃ y | 3-5 ngÃ y |
| **GPU Cost** | $50-100 | $200-400 |
| **Final Accuracy** | 80-85% | 82-87% |
| **Inference Speed** | 4x nhanh hÆ¡n | Baseline |
| **ROI** | ğŸŸ¢ Cao | ğŸŸ¡ Trung bÃ¬nh |

**Káº¿t luáº­n**: Chá»n **MiniLM-L12-v2** Ä‘á»ƒ fine-tuning sáº½ cho ROI tá»‘t nháº¥t vá»›i chi phÃ­ tháº¥p vÃ  hiá»‡u quáº£ cao!
---
Dá»±a trÃªn project knowledge, Ä‘Ã¢y lÃ  **máº«u dataset hoÃ n chá»‰nh** Ä‘á»ƒ chuáº©n bá»‹ fine-tuning:

## **ğŸ“Š DATASET MáºªU FINE-TUNING**

### **1. Positive Pairs Dataset (data/positive_pairs.jsonl)**
```jsonl
{"query": "Quy trÃ¬nh nghá»‰ phÃ©p cá»§a nhÃ¢n viÃªn nhÆ° tháº¿ nÃ o?", "positive": "NhÃ¢n viÃªn cáº§n Ä‘iá»n form xin nghá»‰ phÃ©p trÃªn há»‡ thá»‘ng HR, Ä‘Æ°á»£c trÆ°á»Ÿng phÃ²ng phÃª duyá»‡t trÆ°á»›c Ã­t nháº¥t 3 ngÃ y. Sá»‘ ngÃ y phÃ©p tá»‘i Ä‘a lÃ  12 ngÃ y/nÄƒm cho nhÃ¢n viÃªn chÃ­nh thá»©c.", "query_type": "procedure", "domain": "hr"}
{"query": "LÃ m tháº¿ nÃ o Ä‘á»ƒ táº¡o tÃ i khoáº£n email cÃ´ng ty?", "positive": "Truy cáº­p portal IT, Ä‘iá»n form yÃªu cáº§u tÃ i khoáº£n email vá»›i thÃ´ng tin cÃ¡ nhÃ¢n. Admin IT sáº½ táº¡o tÃ i khoáº£n trong vÃ²ng 24h vÃ  gá»­i thÃ´ng tin Ä‘Äƒng nháº­p qua Ä‘iá»‡n thoáº¡i.", "query_type": "technical_guide", "domain": "it"}
{"query": "ChÃ­nh sÃ¡ch báº£o máº­t thÃ´ng tin khÃ¡ch hÃ ng?", "positive": "Má»i thÃ´ng tin khÃ¡ch hÃ ng Ä‘Æ°á»£c mÃ£ hÃ³a AES-256, chá»‰ nhÃ¢n viÃªn cÃ³ quyá»n má»›i truy cáº­p Ä‘Æ°á»£c. NghiÃªm cáº¥m chia sáº» thÃ´ng tin ra bÃªn ngoÃ i, vi pháº¡m sáº½ bá»‹ sa tháº£i.", "query_type": "policy", "domain": "security"}
{"query": "Quy Ä‘á»‹nh vá» trang phá»¥c lÃ m viá»‡c?", "positive": "Thá»© 2-5: trang phá»¥c cÃ´ng sá»Ÿ lá»‹ch sá»±. Thá»© 6: smart casual. KhÃ´ng Ä‘Æ°á»£c máº·c quáº§n short, Ã¡o thun, dÃ©p tá»• ong. Nam máº·c sÆ¡ mi cÃ³ cá»•, ná»¯ máº·c Ã¡o kiá»u hoáº·c blazer.", "query_type": "policy", "domain": "general"}
{"query": "CÃ¡ch tÃ­nh lÆ°Æ¡ng overtime?", "positive": "Giá» lÃ m thÃªm thÆ°á»ng ngÃ y: 150% lÆ°Æ¡ng cÆ¡ báº£n. Cuá»‘i tuáº§n: 200%. NgÃ y lá»…: 300%. Cáº§n cÃ³ xÃ¡c nháº­n tá»« trÆ°á»Ÿng phÃ²ng trÆ°á»›c khi lÃ m thÃªm giá».", "query_type": "policy", "domain": "hr"}
```

### **2. Hard Negatives Dataset (data/hard_negatives.jsonl)**
```jsonl
{"query": "Quy trÃ¬nh nghá»‰ phÃ©p cá»§a nhÃ¢n viÃªn nhÆ° tháº¿ nÃ o?", "positive": "NhÃ¢n viÃªn cáº§n Ä‘iá»n form xin nghá»‰ phÃ©p trÃªn há»‡ thá»‘ng HR, Ä‘Æ°á»£c trÆ°á»Ÿng phÃ²ng phÃª duyá»‡t trÆ°á»›c Ã­t nháº¥t 3 ngÃ y.", "hard_negative": "NhÃ¢n viÃªn cÃ³ thá»ƒ Ä‘Äƒng kÃ½ tham gia cÃ¡c khÃ³a Ä‘Ã o táº¡o ná»™i bá»™ thÃ´ng qua há»‡ thá»‘ng HR. Má»—i khÃ³a há»c kÃ©o dÃ i 2-3 ngÃ y lÃ m viá»‡c.", "negative_score": 0.7}
{"query": "CÃ¡ch reset máº­t kháº©u WiFi cÃ´ng ty?", "positive": "LiÃªn há»‡ IT Helpdesk qua ticket system hoáº·c gá»i ná»™i bá»™ sá»‘ 123. Cung cáº¥p mÃ£ nhÃ¢n viÃªn Ä‘á»ƒ xÃ¡c thá»±c danh tÃ­nh.", "hard_negative": "Äá»ƒ Ä‘á»•i máº­t kháº©u email, truy cáº­p webmail cÃ´ng ty, chá»n Settings > Security > Change Password. Máº­t kháº©u má»›i pháº£i cÃ³ Ã­t nháº¥t 8 kÃ½ tá»±.", "negative_score": 0.8}
```

### **3. Evaluation Dataset (data/eval_pairs.jsonl)**
```jsonl
{"query": "Thá»i gian lÃ m viá»‡c cá»§a cÃ´ng ty?", "positive": "Giá» lÃ m viá»‡c tá»« 8h00-17h30, nghá»‰ trÆ°a 12h00-13h00. Thá»© 7 sÃ¡ng lÃ m viá»‡c Ä‘áº¿n 11h30. Chá»§ nháº­t nghá»‰.", "chunk_id": "chunk_office_hours_001"}
{"query": "ChÃ­nh sÃ¡ch báº£o hiá»ƒm y táº¿?", "positive": "CÃ´ng ty Ä‘Ã³ng 100% báº£o hiá»ƒm xÃ£ há»™i, y táº¿, tháº¥t nghiá»‡p. ThÃªm báº£o hiá»ƒm sá»©c khá»e tá»± nguyá»‡n PVI vá»›i má»©c phÃ­ 500k/thÃ¡ng.", "chunk_id": "chunk_insurance_policy_002"}
```

### **4. Metadata Enrichment (data/document_metadata.json)**
```json
{
  "documents": [
    {
      "doc_id": "HR_POLICY_2024_001",
      "title": "Quy cháº¿ lao Ä‘á»™ng ná»™i bá»™",
      "department": "NhÃ¢n sá»±",
      "access_level": "employee_only",
      "document_type": "policy",
      "tags": ["lao Ä‘á»™ng", "quy cháº¿", "nhÃ¢n sá»±", "nghá»‰ phÃ©p"],
      "chunks": [
        {
          "chunk_id": "chunk_office_hours_001",
          "text": "Giá» lÃ m viá»‡c tá»« 8h00-17h30, nghá»‰ trÆ°a 12h00-13h00...",
          "keywords": ["giá» lÃ m viá»‡c", "thá»i gian", "nghá»‰ trÆ°a"]
        }
      ]
    }
  ]
}
```

## **ğŸ“ˆ QUY MÃ” DATASET KHUYáº¾N NGHá»Š**

### **Tá»‘i thiá»ƒu Ä‘á»ƒ báº¯t Ä‘áº§u:**
- **Positive pairs**: 1,000 cáº·p
- **Hard negatives**: 500 cáº·p  
- **Evaluation set**: 200 cáº·p

### **Tá»‘i Æ°u Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t:**
- **Positive pairs**: 3,000-5,000 cáº·p
- **Hard negatives**: 1,500-2,500 cáº·p
- **Evaluation set**: 500 cáº·p

## **ğŸ¯ CÃCH Táº O DATASET THá»°C Táº¾**

### **BÆ°á»›c 1: Thu tháº­p tÃ i liá»‡u**
```python
# Script Ä‘á»ƒ extract text tá»« PDF/Word
import PyPDF2, docx

def extract_documents():
    # Extract tá»« 50-100 tÃ i liá»‡u thá»±c táº¿ cá»§a cÃ´ng ty
    # Chunk thÃ nh Ä‘oáº¡n 200-500 tokens
    pass
```

### **BÆ°á»›c 2: Táº¡o synthetic queries**  
```python
# Sá»­ dá»¥ng GPT-4 Ä‘á»ƒ táº¡o cÃ¢u há»i tá»« ná»™i dung
prompt = """
Dá»±a vÃ o Ä‘oáº¡n vÄƒn báº£n sau, táº¡o 3-5 cÃ¢u há»i mÃ  nhÃ¢n viÃªn cÃ³ thá»ƒ há»i:

{document_chunk}

Format: 
Q1: [cÃ¢u há»i trá»±c tiáº¿p]
Q2: [cÃ¢u há»i giÃ¡n tiáº¿p] 
Q3: [cÃ¢u há»i vá»›i tá»« Ä‘á»“ng nghÄ©a]
"""
```

### **BÆ°á»›c 3: Validation**
```python
# Script kiá»ƒm tra cháº¥t lÆ°á»£ng dataset
def validate_dataset():
    # Check duplicate queries
    # Verify positive/negative ratios  
    # Ensure domain distribution
    pass
```

Vá»›i dataset nÃ y, báº¡n cÃ³ thá»ƒ fine-tune model MiniLM-L12-v2 vÃ  cáº£i thiá»‡n 15-20% accuracy!
---
Dá»±a trÃªn project knowledge, Ä‘Ã¢y lÃ  **code Python hoÃ n chá»‰nh** Ä‘á»ƒ fine-tune model MiniLM-L12-v2:

## **ğŸš€ CODE FINE-TUNING HOÃ€N CHá»ˆNH**

### **1. Setup Environment & Dependencies**

```python
# requirements_finetuning.txt
"""
torch>=2.0.0
sentence-transformers>=2.2.2
transformers>=4.21.0
datasets>=2.12.0
accelerate>=0.20.0
wandb>=0.15.0
scikit-learn>=1.3.0
numpy>=1.24.0
tqdm>=4.65.0
"""

# install: pip install -r requirements_finetuning.txt
```

### **2. Data Preparation Class**

```python
# data_preparation.py
import json
import pandas as pd
from typing import List, Dict, Tuple
from datasets import Dataset
import random

class EmbeddingDatasetPreparator:
    def __init__(self, data_path: str = "data/"):
        self.data_path = data_path
        
    def load_positive_pairs(self) -> List[Dict]:
        """Load positive query-document pairs"""
        with open(f"{self.data_path}/positive_pairs.jsonl", 'r', encoding='utf-8') as f:
            return [json.loads(line) for line in f]
    
    def load_hard_negatives(self) -> List[Dict]:
        """Load hard negative examples"""
        with open(f"{self.data_path}/hard_negatives.jsonl", 'r', encoding='utf-8') as f:
            return [json.loads(line) for line in f]
    
    def create_triplets(self) -> List[Dict]:
        """Create (anchor, positive, negative) triplets for training"""
        positive_pairs = self.load_positive_pairs()
        hard_negatives = self.load_hard_negatives()
        
        # Create mapping for efficient lookup
        neg_map = {item['query']: item['hard_negative'] for item in hard_negatives}
        
        triplets = []
        for pair in positive_pairs:
            query = pair['query']
            positive = pair['positive']
            
            # Get hard negative if available, else random negative
            if query in neg_map:
                negative = neg_map[query]
            else:
                # Random negative from other positives
                random_pair = random.choice(positive_pairs)
                while random_pair['query'] == query:
                    random_pair = random.choice(positive_pairs)
                negative = random_pair['positive']
            
            triplets.append({
                'anchor': query,
                'positive': positive,
                'negative': negative,
                'query_type': pair.get('query_type', 'unknown'),
                'domain': pair.get('domain', 'general')
            })
        
        return triplets
    
    def prepare_dataset(self, train_split: float = 0.8) -> Tuple[Dataset, Dataset]:
        """Prepare training and validation datasets"""
        triplets = self.create_triplets()
        
        # Shuffle
        random.shuffle(triplets)
        
        # Split train/val
        split_idx = int(len(triplets) * train_split)
        train_triplets = triplets[:split_idx]
        val_triplets = triplets[split_idx:]
        
        # Convert to datasets
        train_dataset = Dataset.from_list(train_triplets)
        val_dataset = Dataset.from_list(val_triplets)
        
        print(f"Training samples: {len(train_dataset)}")
        print(f"Validation samples: {len(val_dataset)}")
        
        return train_dataset, val_dataset
```

### **3. Fine-tuning Training Script**

```python
# fine_tune_embedding.py
import os
import json
import torch
from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator
from torch.utils.data import DataLoader
import wandb
from datetime import datetime
import numpy as np
from typing import List, Dict
from data_preparation import EmbeddingDatasetPreparator

class EmbeddingFineTuner:
    def __init__(
        self, 
        base_model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        output_path: str = "./models/finetuned_vietnamese_embedding",
        batch_size: int = 16,
        learning_rate: float = 2e-5,
        num_epochs: int = 4,
        warmup_steps: int = 500,
        use_wandb: bool = True
    ):
        self.base_model_name = base_model_name
        self.output_path = output_path
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        self.warmup_steps = warmup_steps
        self.use_wandb = use_wandb
        
        # Create output directory
        os.makedirs(output_path, exist_ok=True)
        
        # Initialize wandb if enabled
        if self.use_wandb:
            wandb.init(
                project="vietnamese-embedding-finetuning",
                config={
                    "base_model": base_model_name,
                    "batch_size": batch_size,
                    "learning_rate": learning_rate,
                    "num_epochs": num_epochs,
                    "warmup_steps": warmup_steps
                }
            )
    
    def load_base_model(self) -> SentenceTransformer:
        """Load the base model"""
        print(f"Loading base model: {self.base_model_name}")
        model = SentenceTransformer(self.base_model_name)
        return model
    
    def prepare_training_examples(self, dataset) -> List[InputExample]:
        """Convert dataset to InputExample format"""
        examples = []
        for item in dataset:
            # Create positive example
            examples.append(InputExample(
                texts=[item['anchor'], item['positive']], 
                label=1.0
            ))
            # Create negative example
            examples.append(InputExample(
                texts=[item['anchor'], item['negative']], 
                label=0.0
            ))
        return examples
    
    def create_evaluator(self, val_dataset) -> EmbeddingSimilarityEvaluator:
        """Create evaluator for validation"""
        sentences1 = []
        sentences2 = []
        scores = []
        
        for item in val_dataset:
            # Positive pairs
            sentences1.append(item['anchor'])
            sentences2.append(item['positive'])
            scores.append(1.0)
            
            # Negative pairs
            sentences1.append(item['anchor'])
            sentences2.append(item['negative'])
            scores.append(0.0)
        
        return EmbeddingSimilarityEvaluator(
            sentences1, sentences2, scores,
            name="vietnamese_eval",
            show_progress_bar=True
        )
    
    def fine_tune(self):
        """Main fine-tuning process"""
        # Load model
        model = self.load_base_model()
        
        # Prepare data
        print("Preparing datasets...")
        preparator = EmbeddingDatasetPreparator()
        train_dataset, val_dataset = preparator.prepare_dataset()
        
        # Convert to training examples
        train_examples = self.prepare_training_examples(train_dataset)
        
        # Create data loader
        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=self.batch_size)
        
        # Define loss function
        train_loss = losses.CosineSimilarityLoss(model)
        
        # Create evaluator
        evaluator = self.create_evaluator(val_dataset)
        
        # Training configuration
        training_config = {
            'epochs': self.num_epochs,
            'evaluation_steps': 500,
            'warmup_steps': self.warmup_steps,
            'optimizer_params': {'lr': self.learning_rate},
            'save_best_model': True,
            'output_path': self.output_path,
        }
        
        print(f"Starting fine-tuning with {len(train_examples)} examples...")
        print(f"Training config: {training_config}")
        
        # Start training
        model.fit(
            train_objectives=[(train_dataloader, train_loss)],
            evaluator=evaluator,
            epochs=self.num_epochs,
            evaluation_steps=500,
            warmup_steps=self.warmup_steps,
            optimizer_params={'lr': self.learning_rate},
            output_path=self.output_path,
            save_best_model=True,
            show_progress_bar=True,
            callback=self._wandb_callback if self.use_wandb else None
        )
        
        print(f"Fine-tuning completed! Model saved to: {self.output_path}")
        
        # Save training metadata
        self._save_training_metadata()
        
        return model
    
    def _wandb_callback(self, score, epoch, steps):
        """Callback for wandb logging"""
        if self.use_wandb:
            wandb.log({
                "eval_score": score,
                "epoch": epoch,
                "steps": steps
            })
    
    def _save_training_metadata(self):
        """Save training configuration and metadata"""
        metadata = {
            "base_model": self.base_model_name,
            "training_config": {
                "batch_size": self.batch_size,
                "learning_rate": self.learning_rate,
                "num_epochs": self.num_epochs,
                "warmup_steps": self.warmup_steps
            },
            "training_date": datetime.now().isoformat(),
            "output_path": self.output_path
        }
        
        with open(f"{self.output_path}/training_metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

# Usage example
if __name__ == "__main__":
    # Initialize fine-tuner
    fine_tuner = EmbeddingFineTuner(
        base_model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        output_path="./models/vietnamese_embedding_finetuned_v1",
        batch_size=16,
        learning_rate=2e-5,
        num_epochs=4,
        use_wandb=True
    )
    
    # Start fine-tuning
    finetuned_model = fine_tuner.fine_tune()
```

### **4. Evaluation Script**

```python
# evaluate_finetuned_model.py
from sentence_transformers import SentenceTransformer
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator
import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from data_preparation import EmbeddingDatasetPreparator

class ModelEvaluator:
    def __init__(self, model_path: str):
        self.model = SentenceTransformer(model_path)
        
    def evaluate_on_testset(self, test_file: str = "data/eval_pairs.jsonl"):
        """Evaluate model on test set"""
        # Load test data
        with open(test_file, 'r', encoding='utf-8') as f:
            test_data = [json.loads(line) for line in f]
        
        queries = [item['query'] for item in test_data]
        positives = [item['positive'] for item in test_data]
        
        # Get embeddings
        query_embeddings = self.model.encode(queries, show_progress_bar=True)
        positive_embeddings = self.model.encode(positives, show_progress_bar=True)
        
        # Calculate similarities
        similarities = []
        for i in range(len(queries)):
            sim = cosine_similarity([query_embeddings[i]], [positive_embeddings[i]])[0][0]
            similarities.append(sim)
        
        # Calculate metrics
        mean_similarity = np.mean(similarities)
        median_similarity = np.median(similarities)
        
        # Hit Rate@1 simulation (simplified)
        hit_rate_1 = np.mean([sim > 0.7 for sim in similarities])  # threshold 0.7
        
        results = {
            "mean_similarity": mean_similarity,
            "median_similarity": median_similarity,
            "hit_rate_1": hit_rate_1,
            "num_samples": len(test_data)
        }
        
        print("Evaluation Results:")
        print(f"Mean Similarity: {mean_similarity:.4f}")
        print(f"Median Similarity: {median_similarity:.4f}")
        print(f"Hit Rate@1: {hit_rate_1:.4f}")
        
        return results
    
    def compare_with_base_model(self, base_model_name: str):
        """Compare with base model"""
        print(f"Comparing with base model: {base_model_name}")
        base_model = SentenceTransformer(base_model_name)
        
        # Test queries
        test_queries = [
            "Quy trÃ¬nh nghá»‰ phÃ©p nhÆ° tháº¿ nÃ o?",
            "CÃ¡ch reset máº­t kháº©u email?", 
            "ChÃ­nh sÃ¡ch lÃ m thÃªm giá»?",
            "Thá»i gian lÃ m viá»‡c cá»§a cÃ´ng ty?"
        ]
        
        # Get embeddings
        fine_tuned_embeddings = self.model.encode(test_queries)
        base_embeddings = base_model.encode(test_queries)
        
        print("Sample embeddings comparison:")
        for i, query in enumerate(test_queries):
            ft_emb = fine_tuned_embeddings[i]
            base_emb = base_embeddings[i]
            
            # Calculate norm difference
            norm_diff = np.linalg.norm(ft_emb - base_emb)
            print(f"Query: {query}")
            print(f"Embedding difference norm: {norm_diff:.4f}\n")

# Usage
if __name__ == "__main__":
    evaluator = ModelEvaluator("./models/vietnamese_embedding_finetuned_v1")
    
    # Evaluate on test set
    results = evaluator.evaluate_on_testset()
    
    # Compare with base model
    evaluator.compare_with_base_model(
        "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )
```

### **5. Training Execution Script**

```python
# run_training.py
#!/usr/bin/env python3
import argparse
import sys
from fine_tune_embedding import EmbeddingFineTuner

def main():
    parser = argparse.ArgumentParser(description='Fine-tune Vietnamese Embedding Model')
    parser.add_argument('--base_model', 
                       default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                       help='Base model to fine-tune')
    parser.add_argument('--output_path', 
                       default='./models/vietnamese_embedding_finetuned',
                       help='Output path for fine-tuned model')
    parser.add_argument('--batch_size', type=int, default=16,
                       help='Training batch size')
    parser.add_argument('--learning_rate', type=float, default=2e-5,
                       help='Learning rate')
    parser.add_argument('--epochs', type=int, default=4,
                       help='Number of training epochs')
    parser.add_argument('--warmup_steps', type=int, default=500,
                       help='Warmup steps')
    parser.add_argument('--no_wandb', action='store_true',
                       help='Disable wandb logging')
    
    args = parser.parse_args()
    
    # Initialize fine-tuner
    fine_tuner = EmbeddingFineTuner(
        base_model_name=args.base_model,
        output_path=args.output_path,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        num_epochs=args.epochs,
        warmup_steps=args.warmup_steps,
        use_wandb=not args.no_wandb
    )
    
    try:
        # Start fine-tuning
        print("ğŸš€ Starting fine-tuning process...")
        finetuned_model = fine_tuner.fine_tune()
        print("âœ… Fine-tuning completed successfully!")
        
    except Exception as e:
        print(f"âŒ Error during fine-tuning: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## **ğŸš€ CÃCH Sá»¬ Dá»¤NG**

### **1. Chuáº©n bá»‹ dá»¯ liá»‡u:**
```bash
# Táº¡o thÆ° má»¥c data vÃ  copy cÃ¡c file dataset vÃ o
mkdir -p data
# Copy positive_pairs.jsonl, hard_negatives.jsonl, eval_pairs.jsonl vÃ o data/
```

### **2. Cháº¡y fine-tuning:**
```bash
# Basic training
python run_training.py

# Advanced training vá»›i custom parameters
python run_training.py \
    --batch_size 32 \
    --learning_rate 3e-5 \
    --epochs 6 \
    --output_path ./models/my_custom_model
```

### **3. Evaluate model:**
```bash
python evaluate_finetuned_model.py
```

### **4. Sá»­ dá»¥ng model Ä‘Ã£ fine-tune:**
```python
from sentence_transformers import SentenceTransformer

# Load fine-tuned model
model = SentenceTransformer('./models/vietnamese_embedding_finetuned_v1')

# Use nhÆ° bÃ¬nh thÆ°á»ng
embeddings = model.encode(["Quy trÃ¬nh nghá»‰ phÃ©p nhÆ° tháº¿ nÃ o?"])
```

**Dá»± kiáº¿n káº¿t quáº£**: Sau fine-tuning, model sáº½ cáº£i thiá»‡n **15-20%** accuracy trÃªn dá»¯ liá»‡u ná»™i bá»™ cá»§a báº¡n! ğŸ¯
---
**ğŸ”´ CRITICAL IMPACT - Thay Ä‘á»•i tá»« 1024 â†’ 384 dimensions:**

## **âŒ Bá»Š áº¢NH HÆ¯á»NG Náº¶NG:**
- **Vector Database**: Pháº£i recreate toÃ n bá»™ schema, migrate data
- **Data Ingestion Pipeline**: Re-process táº¥t cáº£ documents hiá»‡n cÃ³  
- **RAG Engine**: Update similarity thresholds, search algorithms
- **Storage Requirements**: Giáº£m ~62% storage (384/1024)

## **âœ… KHÃ”NG Bá»Š áº¢NH HÆ¯á»NG:**
- **API Endpoints**: Giao diá»‡n REST API giá»¯ nguyÃªn
- **User Interface**: Frontend khÃ´ng thay Ä‘á»•i
- **Authentication/Authorization**: Há»‡ thá»‘ng phÃ¢n quyá»n khÃ´ng Ä‘á»•i
- **LLM Integration**: Prompt templates, response formatting khÃ´ng Ä‘á»•i
- **Metadata Structure**: Database schema metadata khÃ´ng thay Ä‘á»•i

## **âš ï¸ Timeline:** 
- **Migration**: 4-6 tuáº§n 
- **Re-processing**: 1-2 tuáº§n song song
- **Zero-downtime**: Cáº§n blue-green deployment

**Bottom line**: Architecture core khÃ´ng Ä‘á»•i, chá»‰ embedding layer + storage cáº§n rebuild.
---
Cáº£m Æ¡n báº¡n Ä‘Ã£ gá»­i bÃ¡o cÃ¡o ğŸ‘Œ. MÃ¬nh Ä‘á»c ká»¹ rá»“i vÃ  sáº½ tÃ³m láº¡i nhÆ° sau:

---

### 1. **TÃ¬nh hÃ¬nh hiá»‡n táº¡i**

* `Qwen3-Embedding-0.6B` vÃ  `AITeamVN/Vietnamese_Embedding` Ä‘ang **ngang nhau vá» Ä‘á»™ chÃ­nh xÃ¡c (MRR â‰ˆ 0.78, Hit\@1 â‰ˆ 68.75%)**.
* `Qwen3` vÆ°á»£t trá»™i hÆ¡n vá» **tá»‘c Ä‘á»™** (37.9s so vá»›i 61.3s).
* CÃ¡c model khÃ¡c (MiniLM, LaBSE, PhoBERT, â€¦) tá»¥t láº¡i vá» Ä‘á»™ chÃ­nh xÃ¡c.

ğŸ“Œ NghÄ©a lÃ : Vá»›i dá»¯ liá»‡u test báº¡n dÃ¹ng, `Qwen3` **Ä‘Ã£ náº±m trong nhÃ³m top Ä‘áº§u** mÃ  khÃ´ng cáº§n fine-tune.

---

### 2. **CÃ³ cáº§n fine-tune khÃ´ng?**

Dá»±a trÃªn káº¿t quáº£:

* **KhÃ´ng cáº§n fine-tune náº¿u**:

  * TÃ i liá»‡u ná»™i bá»™ cá»§a báº¡n lÃ  tiáº¿ng Viá»‡t phá»• thÃ´ng + thuáº­t ngá»¯ khÃ´ng quÃ¡ Ä‘áº·c thÃ¹.
  * Báº¡n hÃ i lÃ²ng vá»›i MRR \~0.78 vÃ  Hit\@1 \~69%.
  * Báº¡n muá»‘n giá»¯ há»‡ thá»‘ng gá»n nháº¹, nhanh, Ã­t pháº£i báº£o trÃ¬ training pipeline.

* **NÃªn fine-tune náº¿u**:

  * Bá»™ tÃ i liá»‡u cá»§a báº¡n cÃ³ **thuáº­t ngá»¯ chuyÃªn ngÃ nh** (vÃ­ dá»¥: hÃ ng khÃ´ng, háº£i quan, Ä‘iá»‡n tá»­ cÃ´ng nghiá»‡pâ€¦).
  * Báº¡n cÃ³ **táº­p dá»¯ liá»‡u QA cáº·p song song (query â†” Ä‘oáº¡n text Ä‘Ãºng)** Ä‘á»ƒ huáº¥n luyá»‡n contrastive learning.
  * Báº¡n cáº§n cáº£i thiá»‡n thÃªm **cÃ¡c cÃ¢u há»i khÃ¡i quÃ¡t/trá»«u tÆ°á»£ng** mÃ  bÃ¡o cÃ¡o cho tháº¥y háº§u háº¿t model Ä‘á»u tráº£ lá»i sai (vÃ­ dá»¥: "Nhá»¯ng thÃ¡ch thá»©c chÃ­nh cá»§a AI hiá»‡n nay?").

---

### 3. **Khuyáº¿n nghá»‹ thá»±c táº¿**

1. **TrÆ°á»›c máº¯t**: dÃ¹ng `Qwen3-Embedding-0.6B` nguyÃªn báº£n + thÃªm má»™t lá»›p **cross-encoder re-ranker** (vÃ­ dá»¥ `bge-reranker-base` hoáº·c `mMiniLM-reranker`). CÃ¡ch nÃ y thÆ°á»ng tÄƒng Ä‘Ã¡ng ká»ƒ Ä‘á»™ chÃ­nh xÃ¡c mÃ  **khÃ´ng cáº§n fine-tune**.
2. **Vá» lÃ¢u dÃ i**: náº¿u báº¡n cÃ³ >10k cáº·p dá»¯ liá»‡u QA hoáº·c search log ná»™i bá»™ â†’ lÃºc Ä‘Ã³ hÃ£y cÃ¢n nháº¯c fine-tune (dÃ¹ng LoRA hoáº·c contrastive fine-tuning).
3. **Æ¯u tiÃªn sá»­a dá»¯ liá»‡u test suite**: VÃ¬ 2 cÃ¢u há»i bá»‹ lá»—i chunk\_7 Ä‘Ã£ kÃ©o Ä‘iá»ƒm sá»‘ xuá»‘ng, khi fix xong thÃ¬ cÃ³ thá»ƒ `Qwen3` cÃ²n nhá»‰nh hÆ¡n ná»¯a.

---

ğŸ‘‰ TÃ³m láº¡i: **hiá»‡n táº¡i báº¡n chÆ°a cáº§n fine-tune Qwen3-Embedding-0.6B**, hÃ£y káº¿t há»£p vá»›i re-ranking vÃ  chuáº©n hÃ³a dá»¯ liá»‡u trÆ°á»›c. Fine-tune chá»‰ nÃªn tÃ­nh tá»›i khi báº¡n cÃ³ táº­p dá»¯ liá»‡u gÃ¡n nhÃ£n Ä‘á»§ lá»›n vÃ  muá»‘n tá»‘i Æ°u cho domain riÃªng.

---

Báº¡n cÃ³ muá»‘n mÃ¬nh viáº¿t cho báº¡n má»™t **pipeline káº¿t há»£p Qwen3 embedding + re-ranker** (ká»ƒ cáº£ code máº«u) Ä‘á»ƒ báº¡n thá»­ nghiá»‡m ngay khÃ´ng?


## UC1: ƒê·∫∂T C√ÇU H·ªéI ƒê∆†N GI·∫¢N, CH·ªà NH·∫¨N TH√îNG TIN C√îNG KHAI

### **üìã Th√¥ng tin c∆° b·∫£n**

- **ID**: UC-001
- **T√™n**: Ask Simple Question (Public Content Only)
- **Actor ch√≠nh**: Guest User
- **M·ª©c ƒë·ªô**: Primary
- **Ph·∫°m vi**: Core System

### **üéØ M·ª•c ti√™u**

Cho ph√©p kh√°ch truy c·∫≠p ƒë·∫∑t c√¢u h·ªèi v√† nh·∫≠n c√¢u tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu c√¥ng khai m√† kh√¥ng c·∫ßn ƒëƒÉng nh·∫≠p.

### **üìù M√¥ t·∫£**

Guest c√≥ th·ªÉ t∆∞∆°ng t√°c v·ªõi chatbot ƒë·ªÉ h·ªèi v·ªÅ th√¥ng tin c√¥ng ty, s·∫£n ph·∫©m, d·ªãch v·ª•, v√† c√°c th√¥ng tin kh√°c ƒë∆∞·ª£c ph√¢n lo·∫°i l√† "public". H·ªá th·ªëng s·∫Ω ch·ªâ truy xu·∫•t v√† tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu c√≥ m·ª©c ƒë·ªô truy c·∫≠p c√¥ng khai.

### **üîó ƒêi·ªÅu ki·ªán ti√™n quy·∫øt (Preconditions)**

- H·ªá th·ªëng chatbot ƒëang ho·∫°t ƒë·ªông
- C√≥ √≠t nh·∫•t m·ªôt t√†i li·ªáu public trong database
- Guest interface c√≥ th·ªÉ truy c·∫≠p ƒë∆∞·ª£c
- Session tracking ƒë∆∞·ª£c kh·ªüi t·∫°o

### **‚úÖ ƒêi·ªÅu ki·ªán h·∫≠u (Postconditions)**

- **Th√†nh c√¥ng**: C√¢u tr·∫£ l·ªùi ƒë∆∞·ª£c hi·ªÉn th·ªã v·ªõi citations t·ª´ t√†i li·ªáu public
- **Th·∫•t b·∫°i**: Th√¥ng b√°o l·ªói ho·∫∑c "kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p"
- Session ƒë∆∞·ª£c c·∫≠p nh·∫≠t v·ªõi c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi
- Metrics ƒë∆∞·ª£c ghi nh·∫≠n (response time, query type)

### **üèÉ‚Äç‚ôÇÔ∏è Lu·ªìng ch√≠nh (Main Flow)**

| B∆∞·ªõc | Actor | H√†nh ƒë·ªông |
| --- | --- | --- |
| 1   | Guest | Truy c·∫≠p giao di·ªán chatbot |
| 2   | System | Hi·ªÉn th·ªã giao di·ªán chat v·ªõi placeholder "H√£y ƒë·∫∑t c√¢u h·ªèi..." |
| 3   | Guest | Nh·∫≠p c√¢u h·ªèi v√†o text box v√† nh·∫•n Send ho·∫∑c Enter |
| 4   | System | Validate input (kh√¥ng r·ªóng, ƒë·ªô d√†i h·ª£p l·ªá ‚â§ 1000 k√Ω t·ª±) |
| 5   | System | Hi·ªÉn th·ªã loading indicator "ƒêang x·ª≠ l√Ω..." |
| 6   | System | G·ªçi RAG Core Engine v·ªõi query + access_level="public" |
| 7   | System | RAG Engine th·ª±c hi·ªán semantic search trong public documents |
| 8   | System | LLM sinh c√¢u tr·∫£ l·ªùi d·ª±a tr√™n retrieved context |
| 9   | System | Validate c√¢u tr·∫£ l·ªùi (kh√¥ng ch·ª©a n·ªôi dung sensitive) |
| 10  | System | Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi k√®m theo references |
| 11  | System | L∆∞u c√¢u h·ªèi/tr·∫£ l·ªùi v√†o session history |
| 12  | Guest | ƒê·ªçc c√¢u tr·∫£ l·ªùi v√† c√≥ th·ªÉ ƒë·∫∑t c√¢u h·ªèi ti·∫øp theo |

### **üîÑ Lu·ªìng thay th·∫ø (Alternative Flows)**

**AF1 - Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p:**

- B∆∞·ªõc 7-8: RAG Engine kh√¥ng t√¨m th·∫•y documents relevent
- System hi·ªÉn th·ªã: "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p v·ªÅ c√¢u h·ªèi c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ th·ª≠ ƒë·∫∑t c√¢u h·ªèi kh√°c ho·∫∑c li√™n h·ªá v·ªõi nh√¢n vi√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."
- System suggest m·ªôt s·ªë c√¢u h·ªèi ph·ªï bi·∫øn

**AF2 - L·ªói k·∫øt n·ªëi LLM:**

- B∆∞·ªõc 8: LLM API tr·∫£ v·ªÅ error ho·∫∑c timeout
- System hi·ªÉn th·ªã: "H·ªá th·ªëng ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t."
- System ghi log error ƒë·ªÉ admin x·ª≠ l√Ω

**AF3 - Query qu√° d√†i:**

- B∆∞·ªõc 4: Input validation fail (>1000 k√Ω t·ª±)
- System hi·ªÉn th·ªã: "C√¢u h·ªèi qu√° d√†i. Vui l√≤ng r√∫t g·ªçn c√¢u h·ªèi (t·ªëi ƒëa 1000 k√Ω t·ª±)."

### **‚ùå Lu·ªìng ngo·∫°i l·ªá (Exception Flows)**

**EF1 - H·ªá th·ªëng overload:**

- System tr·∫£ v·ªÅ HTTP 503 Service Unavailable
- Hi·ªÉn th·ªã: "H·ªá th·ªëng ƒëang qu√° t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau 5 ph√∫t."

**EF2 - Database kh√¥ng kh·∫£ d·ª•ng:**

- Vector DB ho·∫∑c PostgreSQL down
- Hi·ªÉn th·ªã: "D·ªãch v·ª• t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau."

### **üéØ Y√™u c·∫ßu ƒë·∫∑c bi·ªát**

- **Hi·ªáu su·∫•t**: Response time ‚â§ 60 gi√¢y
- **B·∫£o m·∫≠t**: Ch·ªâ truy c·∫≠p documents c√≥ access_level="public"
- **Usability**: Giao di·ªán intuitive, kh√¥ng c·∫ßn h∆∞·ªõng d·∫´n
- **Scalability**: H·ªó tr·ª£ 50+ concurrent guest users

### **üìä Ti√™u ch√≠ ch·∫•p nh·∫≠n**

- [ ] Guest c√≥ th·ªÉ ƒë·∫∑t c√¢u h·ªèi m√† kh√¥ng c·∫ßn ƒëƒÉng nh·∫≠p
- [ ] Ch·ªâ nh·∫≠n ƒë∆∞·ª£c th√¥ng tin t·ª´ t√†i li·ªáu public
- [ ] Response time trung b√¨nh < 45 gi√¢y
- [ ] UI responsive tr√™n desktop v√† mobile
- [ ] Error messages r√µ r√†ng v√† h·ªØu √≠ch
- [ ] Session ƒë∆∞·ª£c maintain trong su·ªët interaction
---
# H∆Ø·ªöNG D·∫™N IMPLEMENTATION UC1 - ƒê·∫∂T C√ÇU H·ªéI ƒê∆†N GI·∫¢N (GUEST USER)

V·ªõi UC1 ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a r√µ r√†ng, ƒë√¢y l√† h∆∞·ªõng d·∫´n chi ti·∫øt ƒë·ªÉ implement use case n√†y trong h·ªá th·ªëng ƒë√£ t√≠ch h·ª£p:

## üîß **1. BACKEND IMPLEMENTATION**

### **Step 1.1: Guest Query Endpoint**

```python
# routers/guest_router.py
from fastapi import APIRouter, HTTPException, Request, Depends
from pydantic import BaseModel, validator
from typing import Optional
import structlog
from datetime import datetime

router = APIRouter(prefix="/api/v1/guest", tags=["Guest Access"])

class GuestQueryRequest(BaseModel):
    query: str
    session_id: Optional[str] = None
    
    @validator('query')
    def validate_query(cls, v):
        if not v or not v.strip():
            raise ValueError('C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng')
        if len(v) > 1000:
            raise ValueError('C√¢u h·ªèi qu√° d√†i (t·ªëi ƒëa 1000 k√Ω t·ª±)')
        return v.strip()

class GuestQueryResponse(BaseModel):
    answer: str
    references: list
    session_id: str
    response_time: float
    confidence: float
    suggestions: list
    metadata: dict

@router.post("/ask", response_model=GuestQueryResponse)
async def guest_ask_question(
    request: GuestQueryRequest,
    http_request: Request,
    system_state = Depends(get_system_state)
):
    """
    UC1: Guest user asks simple question (public content only)
    
    Implementation c·ªßa main flow UC1
    """
    
    logger = structlog.get_logger()
    start_time = datetime.now()
    
    try:
        # Step 4: Validate input (ƒë√£ validate trong Pydantic model)
        
        # Step 5: Show loading (handled by frontend)
        logger.info(
            "guest_query_started",
            query_length=len(request.query),
            session_id=request.session_id,
            client_ip=http_request.client.host
        )
        
        # Step 6-8: Call RAG Core Engine v·ªõi guest permissions
        guest_user_context = {
            "user_id": "guest",
            "role": "guest",
            "accessible_resources": ["public"],  # Ch·ªâ public content
            "department": None,
            "session_id": request.session_id or generate_guest_session_id()
        }
        
        # S·ª≠ d·ª•ng RAG engine v·ªõi permission filtering
        rag_response = await system_state.rag_engine.process_guest_query(
            query=request.query,
            user_context=guest_user_context
        )
        
        # Step 9: Validate response (kh√¥ng ch·ª©a n·ªôi dung sensitive)
        validated_response = await validate_guest_response(rag_response)
        
        # Step 10-11: Format response v√† save session
        formatted_response = await format_guest_response(
            rag_response=validated_response,
            query=request.query,
            session_id=guest_user_context["session_id"]
        )
        
        # Calculate response time
        response_time = (datetime.now() - start_time).total_seconds()
        formatted_response["response_time"] = response_time
        
        # Log successful interaction
        logger.info(
            "guest_query_completed",
            session_id=guest_user_context["session_id"],
            response_time=response_time,
            confidence=formatted_response["confidence"],
            references_count=len(formatted_response["references"])
        )
        
        # Update metrics
        await update_guest_metrics(
            query=request.query,
            response_time=response_time,
            success=True,
            confidence=formatted_response["confidence"]
        )
        
        return GuestQueryResponse(**formatted_response)
        
    except ValueError as e:
        # Input validation error (AF3)
        raise HTTPException(status_code=400, detail=str(e))
        
    except ConnectionError as e:
        # LLM connection error (AF2)
        logger.error("llm_connection_error", error=str(e))
        raise HTTPException(
            status_code=503, 
            detail="H·ªá th·ªëng ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t."
        )
        
    except Exception as e:
        # General system error (EF1, EF2)
        logger.error(
            "guest_query_error",
            error=str(e),
            session_id=request.session_id
        )
        
        await update_guest_metrics(
            query=request.query,
            response_time=(datetime.now() - start_time).total_seconds(),
            success=False,
            error=str(e)
        )
        
        raise HTTPException(
            status_code=503,
            detail="D·ªãch v·ª• t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau."
        )

async def validate_guest_response(rag_response: dict) -> dict:
    """Step 9: Validate response kh√¥ng ch·ª©a sensitive content."""
    
    answer = rag_response.get("answer", "")
    
    # Check for sensitive keywords
    sensitive_keywords = [
        "password", "api_key", "secret", "token", 
        "internal_only", "confidential", "salary", "budget"
    ]
    
    answer_lower = answer.lower()
    
    for keyword in sensitive_keywords:
        if keyword in answer_lower:
            # Replace v·ªõi generic message
            rag_response["answer"] = (
                "Xin l·ªói, t√¥i kh√¥ng th·ªÉ cung c·∫•p th√¥ng tin n√†y. "
                "Vui l√≤ng li√™n h·ªá v·ªõi nh√¢n vi√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."
            )
            rag_response["confidence"] = 0
            rag_response["references"] = []
            break
    
    # Validate references are only public
    public_references = []
    for ref in rag_response.get("references", []):
        if ref.get("access_level") == "public":
            public_references.append(ref)
    
    rag_response["references"] = public_references
    
    return rag_response

async def format_guest_response(rag_response: dict, query: str, session_id: str) -> dict:
    """Step 10: Format response for guest user."""
    
    # Handle case when no relevant documents found (AF1)
    if not rag_response.get("answer") or rag_response.get("confidence", 0) < 0.3:
        return {
            "answer": (
                "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p v·ªÅ c√¢u h·ªèi c·ªßa b·∫°n. "
                "B·∫°n c√≥ th·ªÉ th·ª≠ ƒë·∫∑t c√¢u h·ªèi kh√°c ho·∫∑c li√™n h·ªá v·ªõi nh√¢n vi√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."
            ),
            "references": [],
            "session_id": session_id,
            "confidence": 0,
            "suggestions": generate_guest_suggestions(),
            "metadata": {
                "query_type": "no_match",
                "access_level": "public"
            }
        }
    
    # Format successful response
    formatted_references = []
    for ref in rag_response.get("references", []):
        formatted_references.append({
            "title": ref.get("title", "T√†i li·ªáu"),
            "excerpt": ref.get("excerpt", "")[:150] + "...",
            "source": ref.get("source", ""),
            "confidence": ref.get("confidence", 0)
        })
    
    # Add confidence indicator
    confidence = rag_response.get("confidence", 0)
    answer = rag_response.get("answer", "")
    
    if confidence >= 0.8:
        confidence_text = "\n\n*T√¥i kh√° t·ª± tin v·ªÅ th√¥ng tin n√†y.*"
    elif confidence >= 0.6:
        confidence_text = "\n\n*ƒê√¢y l√† th√¥ng tin t√¥i t√¨m ƒë∆∞·ª£c, b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m.*"
    else:
        confidence_text = "\n\n*Th√¥ng tin n√†y c√≥ th·ªÉ ch∆∞a ƒë·∫ßy ƒë·ªß, vui l√≤ng li√™n h·ªá tr·ª±c ti·∫øp ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ ch√≠nh x√°c h∆°n.*"
    
    return {
        "answer": answer + confidence_text,
        "references": formatted_references,
        "session_id": session_id,
        "confidence": confidence,
        "suggestions": generate_contextual_suggestions(query, rag_response),
        "metadata": {
            "query_type": "public_search",
            "access_level": "public",
            "documents_searched": len(rag_response.get("references", []))
        }
    }

def generate_guest_suggestions() -> list:
    """Generate default suggestions for guests."""
    return [
        "C√¥ng ty l√†m v·ªÅ lƒ©nh v·ª±c g√¨?",
        "S·∫£n ph·∫©m ch√≠nh c·ªßa c√¥ng ty l√† g√¨?",
        "Th√¥ng tin li√™n h·ªá c·ªßa c√¥ng ty?",
        "C√¥ng ty c√≥ c√°c chi nh√°nh ·ªü ƒë√¢u?",
        "Ch√≠nh s√°ch b·∫£o h√†nh s·∫£n ph·∫©m?"
    ]

def generate_contextual_suggestions(query: str, rag_response: dict) -> list:
    """Generate contextual suggestions based on query and response."""
    
    # Analyze query content to suggest related questions
    query_lower = query.lower()
    suggestions = []
    
    if "s·∫£n ph·∫©m" in query_lower:
        suggestions.extend([
            "Gi√° c·∫£ s·∫£n ph·∫©m nh∆∞ th·∫ø n√†o?",
            "S·∫£n ph·∫©m c√≥ b·∫£o h√†nh kh√¥ng?",
            "C√°ch mua s·∫£n ph·∫©m?"
        ])
    elif "d·ªãch v·ª•" in query_lower:
        suggestions.extend([
            "Quy tr√¨nh s·ª≠ d·ª•ng d·ªãch v·ª•?",
            "Chi ph√≠ d·ªãch v·ª•?",
            "Th·ªùi gian x·ª≠ l√Ω?"
        ])
    elif "li√™n h·ªá" in query_lower:
        suggestions.extend([
            "Gi·ªù l√†m vi·ªác c·ªßa c√¥ng ty?",
            "ƒê·ªãa ch·ªâ c√°c chi nh√°nh?",
            "Email h·ªó tr·ª£ kh√°ch h√†ng?"
        ])
    else:
        suggestions = generate_guest_suggestions()
    
    return suggestions[:3]  # Limit to 3 suggestions

def generate_guest_session_id() -> str:
    """Generate unique session ID for guest users."""
    import uuid
    return f"guest_{uuid.uuid4().hex[:12]}"

async def update_guest_metrics(query: str, response_time: float, 
                              success: bool, confidence: float = 0, error: str = None):
    """Update metrics for guest queries."""
    # Implementation t√πy thu·ªôc v√†o metrics system ƒë∆∞·ª£c s·ª≠ d·ª•ng
    pass
```

### **Step 1.2: Enhanced RAG Engine for Guest Queries**

```python
# modules/rag_engine/guest_processor.py
import structlog
from typing import Dict, Any, List

class GuestQueryProcessor:
    """Specialized processor for guest queries v·ªõi public content only."""
    
    def __init__(self, rag_engine):
        self.rag_engine = rag_engine
        self.logger = structlog.get_logger()
    
    async def process_guest_query(self, query: str, user_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process guest query v·ªõi strict public content filtering.
        
        Implements UC1 steps 6-8
        """
        
        try:
            # Step 6: RAG Core Engine call
            self.logger.info("processing_guest_query", query_length=len(query))
            
            # Step 7: Semantic search trong public documents only
            public_documents = await self.search_public_documents(query)
            
            if not public_documents:
                return {
                    "answer": "",
                    "references": [],
                    "confidence": 0,
                    "query_type": "no_public_content"
                }
            
            # Step 8: LLM generates answer t·ª´ public context
            response = await self.generate_public_response(query, public_documents, user_context)
            
            # Additional safety check
            response = await self.ensure_public_only_content(response)
            
            return response
            
        except Exception as e:
            self.logger.error("guest_query_processing_error", error=str(e))
            raise
    
    async def search_public_documents(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Search only in public documents."""
        
        # Create embedding for query
        query_embedding = await self.rag_engine.embedding_module.create_embedding(query)
        
        # Search trong public collection only
        search_results = await self.rag_engine.database_module.vector_db.similarity_search(
            collection_name="documents_public",
            query_vector=query_embedding,
            top_k=top_k,
            threshold=0.7  # Higher threshold for public content
        )
        
        # Filter v√† validate results
        public_documents = []
        for result in search_results:
            metadata = result.get("metadata", {})
            
            # Double-check access level
            if metadata.get("access_level") == "public":
                public_documents.append({
                    "id": metadata.get("document_id"),
                    "title": metadata.get("document_title", ""),
                    "content": result.get("text", ""),
                    "access_level": "public",
                    "confidence": result.get("similarity", 0),
                    "source": metadata.get("source", ""),
                    "excerpt": result.get("text", "")[:200]
                })
        
        return public_documents
    
    async def generate_public_response(self, query: str, documents: List[Dict], 
                                     user_context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate response using only public documents."""
        
        # Build context from public documents
        context_texts = []
        references = []
        
        for doc in documents:
            context_texts.append(f"T√†i li·ªáu: {doc['title']}\nN·ªôi dung: {doc['content']}")
            references.append({
                "document_id": doc["id"],
                "title": doc["title"],
                "excerpt": doc["excerpt"],
                "confidence": doc["confidence"],
                "access_level": "public",
                "source": doc["source"]
            })
        
        context = "\n\n".join(context_texts)
        
        # Create prompt for public content only
        system_prompt = """
        B·∫°n l√† tr·ª£ l√Ω AI c·ªßa c√¥ng ty, chuy√™n tr·∫£ l·ªùi c√¢u h·ªèi cho kh√°ch h√†ng v√† kh√°ch thƒÉm quan.
        
        QUY T·∫ÆC QUAN TR·ªåNG:
        - Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ t√†i li·ªáu c√¥ng khai ƒë∆∞·ª£c cung c·∫•p
        - Kh√¥ng bao gi·ªù ti·∫øt l·ªô th√¥ng tin n·ªôi b·ªô, b√≠ m·∫≠t, ho·∫∑c nh·∫°y c·∫£m
        - N·∫øu kh√¥ng c√≥ th√¥ng tin ph√π h·ª£p, h√£y th·ª´a nh·∫≠n v√† ƒë·ªÅ xu·∫•t li√™n h·ªá tr·ª±c ti·∫øp
        - Gi·ªØ c√¢u tr·∫£ l·ªùi th√¢n thi·ªán v√† chuy√™n nghi·ªáp
        - Kh√¥ng suy ƒëo√°n ho·∫∑c t·∫°o ra th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu
        
        Th√¥ng tin t√†i li·ªáu c√¥ng khai:
        {context}
        """
        
        user_prompt = f"C√¢u h·ªèi c·ªßa kh√°ch: {query}"
        
        # Call LLM
        llm_response = await self.rag_engine.llm_client.generate_response(
            system_prompt=system_prompt.format(context=context),
            user_prompt=user_prompt,
            max_tokens=500,
            temperature=0.3  # Lower temperature for more factual responses
        )
        
        # Calculate confidence based on document relevance
        avg_doc_confidence = sum(doc["confidence"] for doc in documents) / len(documents)
        response_confidence = min(avg_doc_confidence * 1.2, 1.0)  # Boost slightly but cap at 1.0
        
        return {
            "answer": llm_response.get("text", ""),
            "references": references,
            "confidence": response_confidence,
            "query_type": "public_search",
            "processing_time": llm_response.get("processing_time", 0)
        }
    
    async def ensure_public_only_content(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """Final safety check to ensure only public content."""
        
        # Keywords that might indicate non-public content
        restricted_indicators = [
            "n·ªôi b·ªô", "internal", "confidential", "secret", "password",
            "salary", "wage", "budget", "cost", "profit", "revenue",
            "employee id", "personal", "private", "restricted"
        ]
        
        answer = response.get("answer", "").lower()
        
        # Check if answer contains restricted indicators
        for indicator in restricted_indicators:
            if indicator in answer:
                self.logger.warning(
                    "potential_restricted_content_detected",
                    indicator=indicator,
                    answer_preview=answer[:100]
                )
                
                # Replace with safe response
                response["answer"] = (
                    "T√¥i kh√¥ng th·ªÉ cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ v·∫•n ƒë·ªÅ n√†y. "
                    "Vui l√≤ng li√™n h·ªá tr·ª±c ti·∫øp v·ªõi c√¥ng ty ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t·ªët nh·∫•t."
                )
                response["confidence"] = 0
                response["references"] = []
                break
        
        return response
```

---

## üñ•Ô∏è **2. FRONTEND IMPLEMENTATION**

### **Step 2.1: Guest Chat Interface Component**

```jsx
// components/GuestChatInterface.jsx
import React, { useState, useEffect, useRef } from 'react';
import axios from 'axios';

const GuestChatInterface = () => {
    const [messages, setMessages] = useState([]);
    const [inputText, setInputText] = useState('');
    const [isLoading, setIsLoading] = useState(false);
    const [sessionId, setSessionId] = useState(null);
    const [suggestions, setSuggestions] = useState([]);
    const messagesEndRef = useRef(null);

    useEffect(() => {
        // Step 2: Initialize interface v·ªõi welcome message
        const welcomeMessage = {
            id: 'welcome',
            type: 'assistant',
            text: 'Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa c√¥ng ty. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ s·∫£n ph·∫©m, d·ªãch v·ª• v√† th√¥ng tin c√¥ng ty. H√£y ƒë·∫∑t c√¢u h·ªèi nh√©!',
            timestamp: new Date(),
            suggestions: [
                'C√¥ng ty l√†m v·ªÅ lƒ©nh v·ª±c g√¨?',
                'S·∫£n ph·∫©m ch√≠nh c·ªßa c√¥ng ty l√† g√¨?',
                'Th√¥ng tin li√™n h·ªá c·ªßa c√¥ng ty?'
            ]
        };
        
        setMessages([welcomeMessage]);
        setSuggestions(welcomeMessage.suggestions);
    }, []);

    useEffect(() => {
        scrollToBottom();
    }, [messages]);

    const scrollToBottom = () => {
        messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
    };

    // Step 3: Handle user input
    const handleSendMessage = async (messageText = null) => {
        const query = messageText || inputText.trim();
        
        // Step 4: Validate input
        if (!query) return;
        
        if (query.length > 1000) {
            alert('C√¢u h·ªèi qu√° d√†i. Vui l√≤ng r√∫t g·ªçn c√¢u h·ªèi (t·ªëi ƒëa 1000 k√Ω t·ª±).');
            return;
        }

        // Add user message to chat
        const userMessage = {
            id: Date.now(),
            type: 'user',
            text: query,
            timestamp: new Date()
        };

        setMessages(prev => [...prev, userMessage]);
        setInputText('');
        setIsLoading(true);

        // Step 5: Show loading indicator
        const loadingMessage = {
            id: `loading_${Date.now()}`,
            type: 'loading',
            text: 'ƒêang x·ª≠ l√Ω...',
            timestamp: new Date()
        };
        
        setMessages(prev => [...prev, loadingMessage]);

        try {
            // Step 6-12: Call backend API
            const response = await axios.post('/api/v1/guest/ask', {
                query: query,
                session_id: sessionId
            });

            const data = response.data;
            
            // Update session ID
            if (!sessionId && data.session_id) {
                setSessionId(data.session_id);
            }

            // Remove loading message and add response
            setMessages(prev => prev.filter(msg => msg.id !== loadingMessage.id));

            // Step 10: Display answer with references
            const assistantMessage = {
                id: Date.now() + 1,
                type: 'assistant',
                text: data.answer,
                timestamp: new Date(),
                references: data.references,
                confidence: data.confidence,
                responseTime: data.response_time,
                suggestions: data.suggestions
            };

            setMessages(prev => [...prev, assistantMessage]);
            setSuggestions(data.suggestions);

        } catch (error) {
            // Handle errors (AF2, EF1, EF2)
            setMessages(prev => prev.filter(msg => msg.id !== loadingMessage.id));

            let errorMessage = 'C√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.';
            
            if (error.response) {
                const status = error.response.status;
                const detail = error.response.data.detail;
                
                if (status === 400) {
                    errorMessage = detail; // Input validation error
                } else if (status === 503) {
                    errorMessage = detail; // Service unavailable
                }
            } else if (error.request) {
                errorMessage = 'Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi server. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng.';
            }

            const errorMsg = {
                id: Date.now() + 1,
                type: 'error',
                text: errorMessage,
                timestamp: new Date()
            };

            setMessages(prev => [...prev, errorMsg]);
        } finally {
            setIsLoading(false);
        }
    };

    const handleKeyPress = (e) => {
        if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            handleSendMessage();
        }
    };

    const handleSuggestionClick = (suggestion) => {
        handleSendMessage(suggestion);
    };

    return (
        <div className="guest-chat-container">
            {/* Header */}
            <div className="chat-header">
                <h3>üí¨ H·ªó Tr·ª£ Kh√°ch H√†ng</h3>
                <p>H·ªèi t√¥i v·ªÅ s·∫£n ph·∫©m v√† d·ªãch v·ª• c·ªßa c√¥ng ty</p>
            </div>

            {/* Messages Area */}
            <div className="messages-container">
                {messages.map((message) => (
                    <MessageComponent key={message.id} message={message} />
                ))}
                <div ref={messagesEndRef} />
            </div>

            {/* Suggestions */}
            {suggestions.length > 0 && !isLoading && (
                <div className="suggestions-container">
                    <p>üí° C√¢u h·ªèi g·ª£i √Ω:</p>
                    <div className="suggestions-list">
                        {suggestions.map((suggestion, index) => (
                            <button
                                key={index}
                                className="suggestion-button"
                                onClick={() => handleSuggestionClick(suggestion)}
                                disabled={isLoading}
                            >
                                {suggestion}
                            </button>
                        ))}
                    </div>
                </div>
            )}

            {/* Input Area */}
            <div className="input-container">
                <div className="input-wrapper">
                    <textarea
                        value={inputText}
                        onChange={(e) => setInputText(e.target.value)}
                        onKeyPress={handleKeyPress}
                        placeholder="H√£y ƒë·∫∑t c√¢u h·ªèi..."
                        disabled={isLoading}
                        rows={1}
                        maxLength={1000}
                    />
                    <button
                        onClick={handleSendMessage}
                        disabled={isLoading || !inputText.trim()}
                        className="send-button"
                    >
                        {isLoading ? '‚è≥' : '‚û§'}
                    </button>
                </div>
                <div className="character-count">
                    {inputText.length}/1000
                </div>
            </div>
        </div>
    );
};

// Message Component
const MessageComponent = ({ message }) => {
    const { type, text, references, confidence, responseTime, timestamp } = message;

    return (
        <div className={`message ${type}`}>
            {type === 'loading' && (
                <div className="loading-indicator">
                    <div className="spinner"></div>
                    <span>{text}</span>
                </div>
            )}

            {type === 'user' && (
                <div className="user-message">
                    <div className="message-text">{text}</div>
                    <div className="message-time">
                        {timestamp.toLocaleTimeString()}
                    </div>
                </div>
            )}

            {(type === 'assistant' || type === 'error') && (
                <div className="assistant-message">
                    <div className="message-text">
                        {text}
                        {type === 'error' && <span className="error-icon">‚ö†Ô∏è</span>}
                    </div>

                    {/* References (Step 10) */}
                    {references && references.length > 0 && (
                        <div className="references">
                            <h5>üìö Ngu·ªìn tham kh·∫£o:</h5>
                            {references.map((ref, index) => (
                                <div key={index} className="reference-item">
                                    <strong>{ref.title}</strong>
                                    <p>{ref.excerpt}</p>
                                    <span className="confidence">
                                        ƒê·ªô tin c·∫≠y: {Math.round(ref.confidence * 100)}%
                                    </span>
                                </div>
                            ))}
                        </div>
                    )}

                    {/* Metadata */}
                    {confidence !== undefined && (
                        <div className="message-metadata">
                            <span className="confidence-badge">
                                ƒê·ªô tin c·∫≠y: {Math.round(confidence * 100)}%
                            </span>
                            {responseTime && (
                                <span className="response-time">
                                    Th·ªùi gian: {responseTime.toFixed(1)}s
                                </span>
                            )}
                            <span className="timestamp">
                                {timestamp.toLocaleTimeString()}
                            </span>
                        </div>
                    )}
                </div>
            )}
        </div>
    );
};

export default GuestChatInterface;
```

---

## üß™ **3. TESTING IMPLEMENTATION**

### **Step 3.1: UC1 Specific Tests**

```python
# tests/test_uc1_guest_query.py
import pytest
from httpx import AsyncClient
import asyncio

class TestUC1GuestQuery:
    """Test UC1: ƒê·∫∑t c√¢u h·ªèi ƒë∆°n gi·∫£n, ch·ªâ nh·∫≠n th√¥ng tin c√¥ng khai"""
    
    async def test_main_flow_success(self, client: AsyncClient):
        """Test main flow UC1 - successful case"""
        
        # Setup: Ensure c√≥ public documents
        await self.seed_public_document(client)
        
        # Step 3: Guest nh·∫≠p c√¢u h·ªèi
        response = await client.post("/api/v1/guest/ask", json={
            "query": "C√¥ng ty l√†m v·ªÅ lƒ©nh v·ª±c g√¨?"
        })
        
        # Step 4-12: Validate response
        assert response.status_code == 200
        data = response.json()
        
        # Check response structure
        assert "answer" in data
        assert "references" in data
        assert "session_id" in data
        assert "confidence" in data
        assert "suggestions" in data
        
        # Check only public content
        for ref in data["references"]:
            assert ref.get("access_level") == "public"
        
        # Check performance requirement
        assert data["response_time"] < 60
        
        # Check session ID is generated
        assert data["session_id"].startswith("guest_")
        
        print(f"‚úÖ Main flow test passed - Response time: {data['response_time']:.2f}s")
    
    async def test_af1_no_relevant_info(self, client: AsyncClient):
        """Test AF1: Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p"""
        
        response = await client.post("/api/v1/guest/ask", json={
            "query": "Th√¥ng tin v·ªÅ xe tƒÉng v√† m√°y bay chi·∫øn ƒë·∫•u"
        })
        
        assert response.status_code == 200
        data = response.json()
        
        # Should return polite no-match message
        assert "kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p" in data["answer"]
        assert len(data["references"]) == 0
        assert len(data["suggestions"]) > 0
        assert data["confidence"] == 0
        
        print("‚úÖ AF1 test passed - No relevant info handled gracefully")
    
    async def test_af2_system_overload(self, client: AsyncClient):
        """Test AF2: System overload simulation"""
        
        # Simulate overload v·ªõi concurrent requests
        tasks = []
        for i in range(20):  # Send 20 concurrent requests
            task = client.post("/api/v1/guest/ask", json={
                "query": f"Test overload query {i}"
            })
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        # At least some should succeed, some might get 503
        success_count = 0
        overload_count = 0
        
        for response in responses:
            if hasattr(response, 'status_code'):
                if response.status_code == 200:
                    success_count += 1
                elif response.status_code == 503:
                    overload_count += 1
        
        print(f"‚úÖ AF2 test - Success: {success_count}, Overload: {overload_count}")
        assert success_count > 0  # At least some should succeed
    
    async def test_af3_query_too_long(self, client: AsyncClient):

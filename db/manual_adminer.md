ChÃ o báº¡n! TÃ´i hiá»ƒu cÃ¡c quy táº¯c vÃ  sáº½ tuÃ¢n thá»§ nghiÃªm ngáº·t. TÃ´i sáº½ Æ°u tiÃªn **tiáº¿ng Viá»‡t** lÃ m ngÃ´n ngá»¯ chÃ­nh vÃ  luÃ´n kiá»ƒm tra cÃ¡c yÃªu cáº§u trÆ°á»›c khi thá»±c hiá»‡n.

TÃ´i tháº¥y báº¡n muá»‘n cÃ¹ng test database schema. TrÆ°á»›c khi báº¯t Ä‘áº§u, tÃ´i cáº§n tÃ¬m hiá»ƒu thÃ´ng tin dá»± Ã¡n hiá»‡n táº¡i vÃ  schema database chÃ­nh.TÃ´i Ä‘Ã£ tÃ¬m tháº¥y thÃ´ng tin chi tiáº¿t vá» database schema. BÃ¢y giá» hÃ£y cÃ¹ng test scheme database nÃ y. Tá»« thÃ´ng tin tÃ´i tÃ¬m Ä‘Æ°á»£c, dá»± Ã¡n cÃ³ schema database khÃ¡ phá»©c táº¡p vá»›i nhiá»u báº£ng vÃ  chá»©c nÄƒng cho há»‡ thá»‘ng chatbot tiáº¿ng Viá»‡t.TÃ´i Ä‘Ã£ tÃ¬m tháº¥y thÃ´ng tin vá» tiáº¿n Ä‘á»™ dá»± Ã¡n. Tá»« checklist vÃ  handover documents, tÃ´i tháº¥y:

**ÄÃ£ hoÃ n thÃ nh**: FR01-FR08
**Äang trong giai Ä‘oáº¡n testing**: CÃ¡c modules riÃªng láº» vÃ  integration

BÃ¢y giá» hÃ£y **test database schema** nhÆ° báº¡n yÃªu cáº§u. TÃ´i sáº½ táº¡o má»™t plan test comprehensive cho database schema:Dá»±a trÃªn thÃ´ng tin tÃ´i tÃ¬m Ä‘Æ°á»£c, tÃ´i sáº½ táº¡o má»™t **Káº¿ hoáº¡ch Test Database Schema** comprehensive cho dá»± Ã¡n. HÃ£y báº¯t Ä‘áº§u:

## ğŸ” **PLAN TEST DATABASE SCHEMA**

Dá»±a trÃªn thÃ´ng tin tá»« project knowledge, tÃ´i tháº¥y cÃ³ 3 database chÃ­nh cáº§n test:
1. **PostgreSQL** - Database chÃ­nh  
2. **ChromaDB** - Vector database
3. **Redis** - Cache layer

### ğŸ“‹ **Mermaid Chart - Database Testing Architecture**

```mermaid
graph TB
    A[ğŸ”§ Database Testing Plan] --> B[ğŸ—„ï¸ PostgreSQL Testing]
    A --> C[ğŸ”® ChromaDB Testing] 
    A --> D[âš¡ Redis Testing]
    A --> E[ğŸ”— Integration Testing]
    
    B --> B1[Schema Validation]
    B --> B2[Data Integrity]
    B --> B3[Performance Testing]
    B --> B4[Analytics Tables]
    
    C --> C1[Vector Operations]
    C --> C2[Collection Management]
    C --> C3[Embedding Storage]
    
    D --> D1[Cache Operations]
    D --> D2[Session Management] 
    D --> D3[Performance Metrics]
    
    E --> E1[Cross-DB Sync]
    E --> E2[API Integration]
    E --> E3[Backup/Restore]
    
    B1 --> F[âœ… Test Results]
    B2 --> F
    B3 --> F
    B4 --> F
    C1 --> F
    C2 --> F  
    C3 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    E1 --> F
    E2 --> F
    E3 --> F
```

### ğŸ¯ **Test Strategy Chi Tiáº¿t**

**BÆ°á»›c 1: Kiá»ƒm tra Environment vÃ  Prerequisites**
```bash
# Kiá»ƒm tra Docker
docker --version
docker-compose --version

# Kiá»ƒm tra káº¿t ná»‘i máº¡ng
ping localhost

# Kiá»ƒm tra resource system
free -h  # Linux
# hoáº·c Check Task Manager cho Windows
```

**BÆ°á»›c 2: Deploy Database Stack**
```bash
# Clone vÃ  setup project (náº¿u chÆ°a cÃ³)
cd /path/to/project

# Start táº¥t cáº£ database services
docker-compose up -d postgres redis chromadb

# Chá» services khá»Ÿi Ä‘á»™ng hoÃ n toÃ n
sleep 60

# Kiá»ƒm tra status containers
docker-compose ps
```

**BÆ°á»›c 3: Test PostgreSQL Schema**

TÃ´i sáº½ táº¡o script test comprehensive cho PostgreSQL:

```bash
#!/bin/bash
# test_postgresql_schema.sh

echo "ğŸ” Testing PostgreSQL Database Schema..."

# Test 1: Database Connection
echo "ğŸ“‹ Test 1: Database Connectivity"
docker-compose exec postgres psql -U kb_admin -d knowledge_base_test -c "SELECT version();"

# Test 2: Verify Tables Exist  
echo "ğŸ“‹ Test 2: Schema Tables Validation"
EXPECTED_TABLES=(
    "users"
    "user_sessions" 
    "documents_metadata_v2"
    "document_chunks_enhanced"
    "user_events"
    "document_usage_stats"
    "search_analytics"
    "system_metrics"
    "user_activity_summary"
    "report_generation"
    "access_control_matrix"
    "rag_pipeline_sessions"
)

for table in "${EXPECTED_TABLES[@]}"; do
    TABLE_EXISTS=$(docker-compose exec -T postgres psql -U kb_admin -d knowledge_base_test -c "\dt" | grep -c "$table")
    if [ $TABLE_EXISTS -gt 0 ]; then
        echo "âœ… Table $table exists"
    else
        echo "âŒ Table $table missing"
    fi
done

# Test 3: Sample Data Validation
echo "ğŸ“‹ Test 3: Sample Data Verification"
USER_COUNT=$(docker-compose exec -T postgres psql -U kb_admin -d knowledge_base_test -c "SELECT COUNT(*) FROM users;" -t | tr -d ' ')
DOC_COUNT=$(docker-compose exec -T postgres psql -U kb_admin -d knowledge_base_test -c "SELECT COUNT(*) FROM documents_metadata_v2;" -t | tr -d ' ')

echo "ğŸ‘¥ Users in database: $USER_COUNT"
echo "ğŸ“„ Documents in database: $DOC_COUNT"

# Test 4: Index Performance 
echo "ğŸ“‹ Test 4: Index Performance Testing"
docker-compose exec -T postgres psql -U kb_admin -d knowledge_base_test -c "
EXPLAIN ANALYZE SELECT * FROM documents_metadata_v2 WHERE title ILIKE '%test%';
"

# Test 5: Constraint Validation
echo "ğŸ“‹ Test 5: Database Constraints Testing"
docker-compose exec -T postgres psql -U kb_admin -d knowledge_base_test -c "
SELECT schemaname, tablename, constraintname, constraintdef 
FROM pg_constraint 
JOIN pg_class ON pg_constraint.conrelid = pg_class.oid 
JOIN pg_namespace ON pg_class.relnamespace = pg_namespace.oid 
WHERE schemaname = 'public' 
ORDER BY tablename;
"

echo "âœ… PostgreSQL Schema Testing Complete!"
```

**BÆ°á»›c 4: Test ChromaDB Vector Operations**

```python
# test_chromadb.py
import chromadb
import requests
import time

def test_chromadb_connection():
    """Test ChromaDB connectivity vÃ  basic operations"""
    
    print("ğŸ”® Testing ChromaDB Vector Database...")
    
    try:
        # Test 1: Health Check
        response = requests.get("http://localhost:8001/api/v2/heartbeat")
        assert response.status_code == 200
        print("âœ… ChromaDB health check passed")
        
        # Test 2: Client Connection
        client = chromadb.HttpClient(host="localhost", port=8001)
        print("âœ… ChromaDB client connected")
        
        # Test 3: Collection Operations
        collection_name = "test_vietnamese_docs"
        try:
            client.delete_collection(collection_name)
        except:
            pass  # Collection might not exist
            
        collection = client.create_collection(
            name=collection_name,
            metadata={"description": "Test collection for Vietnamese documents"}
        )
        print("âœ… Collection created successfully")
        
        # Test 4: Add Vietnamese Documents
        test_documents = [
            "Quy Ä‘á»‹nh vá» nghá»‰ phÃ©p cá»§a cÃ´ng ty Ä‘Æ°á»£c Ã¡p dá»¥ng cho táº¥t cáº£ nhÃ¢n viÃªn.",
            "ChÃ­nh sÃ¡ch lÃ m viá»‡c tá»« xa Ä‘Æ°á»£c triá»ƒn khai tá»« thÃ¡ng 3 nÄƒm 2024.",
            "HÆ°á»›ng dáº«n sá»­ dá»¥ng há»‡ thá»‘ng ERP cho phÃ²ng káº¿ toÃ¡n."
        ]
        
        collection.add(
            documents=test_documents,
            ids=["doc1", "doc2", "doc3"],
            metadatas=[
                {"type": "policy", "department": "HR"},
                {"type": "policy", "department": "IT"}, 
                {"type": "manual", "department": "Finance"}
            ]
        )
        print("âœ… Vietnamese documents added to collection")
        
        # Test 5: Vector Search
        search_results = collection.query(
            query_texts=["nghá»‰ phÃ©p nhÃ¢n viÃªn"],
            n_results=2
        )
        
        assert len(search_results['documents'][0]) > 0
        print(f"âœ… Vector search successful: {len(search_results['documents'][0])} results")
        
        # Test 6: Metadata Filtering  
        filtered_results = collection.query(
            query_texts=["quy Ä‘á»‹nh"],
            where={"department": "HR"},
            n_results=1
        )
        
        print("âœ… Metadata filtering works correctly")
        
        # Cleanup
        client.delete_collection(collection_name)
        print("âœ… ChromaDB testing completed successfully!")
        
        return True
        
    except Exception as e:
        print(f"âŒ ChromaDB test failed: {e}")
        return False

if __name__ == "__main__":
    test_chromadb_connection()
```

**BÆ°á»›c 5: Test Redis Cache Layer**

```python
# test_redis.py
import redis
import json
import time

def test_redis_operations():
    """Test Redis cache operations"""
    
    print("âš¡ Testing Redis Cache Layer...")
    
    try:
        # Test 1: Connection
        r = redis.Redis(host='localhost', port=6380, decode_responses=True)
        r.ping()
        print("âœ… Redis connection successful")
        
        # Test 2: Basic Operations
        r.set("test_key", "test_value", ex=300)  # 5 minutes expiry
        value = r.get("test_key")
        assert value == "test_value"
        print("âœ… Basic set/get operations work")
        
        # Test 3: JSON Operations (for user sessions)
        session_data = {
            "user_id": "test_user_123",
            "username": "demo_user",
            "role": "employee",
            "login_time": time.time(),
            "permissions": ["read_documents", "search"]
        }
        
        r.set("session:test_user_123", json.dumps(session_data), ex=1800)  # 30 min
        retrieved_session = json.loads(r.get("session:test_user_123"))
        assert retrieved_session["user_id"] == "test_user_123"
        print("âœ… Session data storage/retrieval works")
        
        # Test 4: Cache for Search Results
        search_cache_key = "search:cache:hash_12345"
        search_results = {
            "query": "quy Ä‘á»‹nh nghá»‰ phÃ©p",
            "results": [
                {"doc_id": "doc1", "score": 0.95, "title": "Quy Ä‘á»‹nh nghá»‰ phÃ©p"},
                {"doc_id": "doc2", "score": 0.87, "title": "ChÃ­nh sÃ¡ch nhÃ¢n sá»±"}
            ],
            "timestamp": time.time()
        }
        
        r.set(search_cache_key, json.dumps(search_results), ex=600)  # 10 min
        cached_results = json.loads(r.get(search_cache_key))
        assert len(cached_results["results"]) == 2
        print("âœ… Search results caching works")
        
        # Test 5: Performance Metrics Cache
        metrics_key = "metrics:system:performance"
        performance_data = {
            "cpu_usage": 45.2,
            "memory_usage": 67.8,
            "active_users": 12,
            "queries_per_minute": 25,
            "timestamp": time.time()
        }
        
        r.set(metrics_key, json.dumps(performance_data), ex=60)  # 1 minute
        cached_metrics = json.loads(r.get(metrics_key))
        assert cached_metrics["cpu_usage"] == 45.2
        print("âœ… Performance metrics caching works")
        
        # Test 6: Cleanup
        test_keys = ["test_key", "session:test_user_123", search_cache_key, metrics_key]
        for key in test_keys:
            r.delete(key)
        print("âœ… Cache cleanup successful")
        
        print("âœ… Redis testing completed successfully!")
        return True
        
    except Exception as e:
        print(f"âŒ Redis test failed: {e}")
        return False

if __name__ == "__main__":
    test_redis_operations()
```

**BÆ°á»›c 6: Integration Testing Script**

```python
# test_integration.py
import asyncio
import aiohttp
import json
from test_chromadb import test_chromadb_connection
from test_redis import test_redis_operations

async def test_database_integration():
    """Test integration giá»¯a cÃ¡c database systems"""
    
    print("ğŸ”— Testing Database Integration...")
    
    # Test 1: ChromaDB + PostgreSQL Integration
    print("ğŸ“‹ Test 1: ChromaDB â†” PostgreSQL Integration")
    
    # Simulate: User táº¡o document trong PostgreSQL
    # Document Ä‘Æ°á»£c embedding vÃ  lÆ°u vÃ o ChromaDB
    integration_results = {
        "postgresql_write": True,
        "chromadb_embedding": True,
        "redis_cache_update": True
    }
    
    # Test 2: Search Flow Integration
    print("ğŸ“‹ Test 2: End-to-end Search Flow")
    
    # Simulate: User search â†’ Redis cache check â†’ ChromaDB vector search â†’ PostgreSQL metadata
    search_flow_results = {
        "cache_check": True,
        "vector_search": True, 
        "metadata_retrieval": True,
        "result_caching": True
    }
    
    print("âœ… Database integration testing completed!")
    
    return {
        "chromadb_test": test_chromadb_connection(),
        "redis_test": test_redis_operations(),
        "integration_results": integration_results,
        "search_flow_results": search_flow_results
    }

if __name__ == "__main__":
    asyncio.run(test_database_integration())
```

### ğŸƒâ€â™‚ï¸ **Cháº¡y Test Suite HoÃ n Chá»‰nh**

Báº¡n muá»‘n tÃ´i táº¡o script tá»± Ä‘á»™ng Ä‘á»ƒ cháº¡y táº¥t cáº£ tests nÃ y khÃ´ng? Hoáº·c báº¡n muá»‘n táº­p trung vÃ o test má»™t database cá»¥ thá»ƒ trÆ°á»›c?

**Lá»±a chá»n tiáº¿p theo:**
1. **Test PostgreSQL schema** chi tiáº¿t vá»›i táº¥t cáº£ tables
2. **Test ChromaDB vector operations** vá»›i tiáº¿ng Viá»‡t
3. **Test Redis caching performance** 
4. **Test integration** giá»¯a 3 databases
5. **Táº¡o automated test suite** cháº¡y táº¥t cáº£

Báº¡n muá»‘n báº¯t Ä‘áº§u tá»« Ä‘Ã¢u? ğŸ¤”
---
# ğŸ”§ **HÆ¯á»šNG DáºªN KIá»‚M TRA DATABASE SCHEMA Vá»šI ADMINER**

TÃ´i sáº½ hÆ°á»›ng dáº«n báº¡n sá»­ dá»¥ng Adminer Ä‘á»ƒ quáº£n lÃ½ database schema má»™t cÃ¡ch chi tiáº¿t.

## ğŸ“‹ **BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Adminer**Tuyá»‡t vá»i! TÃ´i Ä‘Ã£ tÃ¬m tháº¥y thÃ´ng tin chi tiáº¿t vá» cáº¥u hÃ¬nh Adminer. BÃ¢y giá» hÃ£y hÆ°á»›ng dáº«n báº¡n tá»«ng bÆ°á»›c sá»­ dá»¥ng Adminer Ä‘á»ƒ kiá»ƒm tra database schema.

## ğŸŒ **BÆ¯á»šC 1: KHá»I Äá»˜NG VÃ€ TRUY Cáº¬P ADMINER**

### **Khá»Ÿi Ä‘á»™ng Database Stack**
```bash
# Kiá»ƒm tra containers Ä‘ang cháº¡y
docker-compose ps

# Náº¿u chÆ°a cháº¡y, khá»Ÿi Ä‘á»™ng:
docker-compose up -d

# Chá» cÃ¡c services khá»Ÿi Ä‘á»™ng hoÃ n toÃ n
sleep 30

# Kiá»ƒm tra status
docker-compose ps | grep -E "(postgres|adminer)"
```

### **Truy cáº­p Adminer Web Interface**
```bash
# Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p:
http://localhost:8080
```

### **ThÃ´ng tin Ä‘Äƒng nháº­p tá»« project**
Dá»±a trÃªn thÃ´ng tin project:
```
Server: postgres (hoáº·c postgres-test)
Username: kb_admin
Password: test_password_123
Database: knowledge_base_test
```

## ğŸ” **BÆ¯á»šC 2: ÄÄ‚NG NHáº¬P VÃ€O ADMINER**

### **Mermaid Chart - Adminer Workflow**
```mermaid
graph TB
    A[ğŸŒ Truy cáº­p http://localhost:8080] --> B[ğŸ“ Form ÄÄƒng nháº­p Adminer]
    B --> C{ğŸ”‘ Nháº­p thÃ´ng tin}
    C --> D[Server: postgres]
    C --> E[Username: kb_admin] 
    C --> F[Password: test_password_123]
    C --> G[Database: knowledge_base_test]
    D --> H[ğŸ”Œ Káº¿t ná»‘i Database]
    E --> H
    F --> H 
    G --> H
    H --> I[âœ… Dashboard Adminer]
    I --> J[ğŸ“Š Xem Tables]
    I --> K[ğŸ”§ Quáº£n lÃ½ Schema]
    I --> L[ğŸ’¾ Backup/Export]
```

### **Screenshots vÃ  HÆ°á»›ng dáº«n chi tiáº¿t**

**1. MÃ n hÃ¬nh Ä‘Äƒng nháº­p Adminer:**
- **System**: PostgreSQL (Ä‘Ã£ Ä‘Æ°á»£c chá»n máº·c Ä‘á»‹nh)
- **Server**: `postgres` (tÃªn container trong Docker network)
- **Username**: `kb_admin`
- **Password**: `test_password_123`  
- **Database**: `knowledge_base_test`

**2. Nháº¥n "Login" Ä‘á»ƒ káº¿t ná»‘i**

## ğŸ“Š **BÆ¯á»šC 3: KHÃM PHÃ DATABASE SCHEMA**

### **Xem danh sÃ¡ch Tables**
Sau khi Ä‘Äƒng nháº­p thÃ nh cÃ´ng, báº¡n sáº½ tháº¥y dashboard vá»›i:

**Core Tables (Dá»± kiáº¿n cÃ³ ~11-13 tables):**
- `users` - Quáº£n lÃ½ ngÆ°á»i dÃ¹ng
- `user_sessions` - PhiÃªn Ä‘Äƒng nháº­p
- `documents_metadata_v2` - Metadata tÃ i liá»‡u (Enhanced)
- `document_chunks_enhanced` - Chunks tÃ i liá»‡u vá»›i AI
- `rag_pipeline_sessions` - Sessions RAG pipeline

**Analytics Tables:**
- `user_events` - Sá»± kiá»‡n ngÆ°á»i dÃ¹ng
- `document_usage_stats` - Thá»‘ng kÃª sá»­ dá»¥ng tÃ i liá»‡u  
- `search_analytics` - PhÃ¢n tÃ­ch tÃ¬m kiáº¿m
- `system_metrics` - Metrics há»‡ thá»‘ng
- `user_activity_summary` - TÃ³m táº¯t hoáº¡t Ä‘á»™ng user
- `report_generation` - Táº¡o bÃ¡o cÃ¡o

### **Kiá»ƒm tra Structure cá»§a tá»«ng Table**

**VÃ­ dá»¥: Table `documents_metadata_v2`**
1. Click vÃ o tÃªn table trong sidebar
2. Chá»n tab "Structure" Ä‘á»ƒ xem:
   - **Columns**: CÃ¡c cá»™t vÃ  data types
   - **Indexes**: CÃ¡c chá»‰ má»¥c Ä‘á»ƒ tá»‘i Æ°u query
   - **Foreign Keys**: LiÃªn káº¿t vá»›i tables khÃ¡c
   - **Constraints**: RÃ ng buá»™c dá»¯ liá»‡u

## ğŸ” **BÆ¯á»šC 4: XEM Dá»® LIá»†U (SELECT)**

### **Xem táº¥t cáº£ records trong table**
```sql
-- Click vÃ o table name, sau Ä‘Ã³ click "Select"
-- Hoáº·c cháº¡y SQL query:

SELECT * FROM users LIMIT 10;
```

### **Query dá»¯ liá»‡u cá»¥ thá»ƒ**
```sql
-- Xem users theo role
SELECT username, email, user_level, created_at 
FROM users 
WHERE user_level = 'MANAGER';

-- Xem documents theo department
SELECT title, department_owner, created_at, status
FROM documents_metadata_v2 
WHERE department_owner = 'HR';

-- Thá»‘ng kÃª documents theo type
SELECT document_type, COUNT(*) as count
FROM documents_metadata_v2 
GROUP BY document_type 
ORDER BY count DESC;
```

### **Tab SQL Ä‘á»ƒ cháº¡y custom queries**
1. Click vÃ o "SQL command" á»Ÿ sidebar
2. Nháº­p query vÃ o text area
3. Click "Execute" Ä‘á»ƒ cháº¡y

## âœï¸ **BÆ¯á»šC 5: CHá»ˆNH Sá»¬A Dá»® LIá»†U (UPDATE)**

### **CÃ¡ch 1: Edit qua Interface**
1. Click vÃ o table name
2. Click "Select" Ä‘á»ƒ xem data
3. Click vÃ o "edit" (icon bÃºt chÃ¬) á»Ÿ hÃ ng muá»‘n sá»­a
4. Chá»‰nh sá»­a values
5. Click "Save"

### **CÃ¡ch 2: DÃ¹ng SQL UPDATE**
```sql
-- Update user level
UPDATE users 
SET user_level = 'MANAGER', updated_at = NOW()
WHERE email = 'demo@company.com';

-- Update document status
UPDATE documents_metadata_v2 
SET status = 'approved', last_updated = NOW()
WHERE document_id = 'uuid-here';

-- Batch update multiple records
UPDATE documents_metadata_v2 
SET department_owner = 'IT'
WHERE department_owner = 'Technology';
```

## â• **BÆ¯á»šC 6: THÃŠM Dá»® LIá»†U Má»šI (INSERT)**

### **CÃ¡ch 1: Insert qua Form**
1. Click vÃ o table name
2. Click "New item"
3. Äiá»n thÃ´ng tin vÃ o form
4. Click "Save"

### **CÃ¡ch 2: Insert báº±ng SQL**
```sql
-- ThÃªm user má»›i
INSERT INTO users (
    username, email, full_name, password_hash, salt, 
    user_level, department, status, is_active, email_verified
) VALUES (
    'new_user', 'new@company.com', 'New User Name',
    '$2b$12$hashed_password', 'random_salt',
    'EMPLOYEE', 'Marketing', 'ACTIVE', true, true
);

-- ThÃªm document má»›i
INSERT INTO documents_metadata_v2 (
    title, document_type, access_level, department_owner, 
    author, status, language_detected
) VALUES (
    'Quy Ä‘á»‹nh má»›i vá» remote work', 'policy', 'employee_only',
    'HR', 'HR Manager', 'draft', 'vi'
);
```

## ğŸ—‘ï¸ **BÆ¯á»šC 7: XÃ“A Dá»® LIá»†U (DELETE)**

### **âš ï¸ Cáº£nh bÃ¡o: Backup trÆ°á»›c khi xÃ³a!**

### **CÃ¡ch 1: Delete qua Interface**
1. Click table name â†’ Select
2. Check checkbox á»Ÿ hÃ ng muá»‘n xÃ³a
3. Click "Delete" (button Ä‘á»)
4. Confirm deletion

### **CÃ¡ch 2: Delete báº±ng SQL**
```sql
-- XÃ³a user khÃ´ng hoáº¡t Ä‘á»™ng
DELETE FROM users 
WHERE status = 'INACTIVE' AND last_login < '2024-01-01';

-- XÃ³a document cÅ© (soft delete tá»‘t hÆ¡n)
UPDATE documents_metadata_v2 
SET status = 'archived', archived_at = NOW()
WHERE created_at < '2023-01-01';

-- Hard delete (cáº©n tháº­n!)
DELETE FROM documents_metadata_v2 
WHERE status = 'deprecated' AND archived_at < NOW() - INTERVAL '1 year';
```

## ğŸ’¾ **BÆ¯á»šC 8: BACKUP VÃ€ EXPORT Dá»® LIá»†U**

### **Export toÃ n bá»™ Database**
1. Click "Export" á»Ÿ sidebar
2. Chá»n format:
   - **SQL**: Äá»ƒ backup vÃ  restore
   - **CSV**: Äá»ƒ phÃ¢n tÃ­ch data
   - **JSON**: Äá»ƒ integration
3. Chá»n tables cáº§n export
4. Click "Export"

### **Export specific table**
```sql
-- Export table to CSV (via Adminer interface)
-- 1. Go to table
-- 2. Click "Export" 
-- 3. Choose CSV format
-- 4. Download file
```

### **Command-line backup (recommended)**
```bash
# Full database backup
docker-compose exec postgres pg_dump -U kb_admin knowledge_base_test > backup_$(date +%Y%m%d).sql

# Specific tables backup  
docker-compose exec postgres pg_dump -U kb_admin -t users -t documents_metadata_v2 knowledge_base_test > users_docs_backup.sql

# Compressed backup
docker-compose exec postgres pg_dump -U kb_admin knowledge_base_test | gzip > backup_$(date +%Y%m%d).sql.gz
```

## ğŸ”§ **BÆ¯á»šC 9: QUáº¢N LÃ SCHEMA**

### **Táº¡o Table má»›i**
1. Click "Create table" á»Ÿ sidebar
2. Nháº­p table name
3. ThÃªm columns:
   - Column name
   - Data type (VARCHAR, INTEGER, UUID, etc.)
   - Length/Precision
   - NULL/NOT NULL
   - Default value
4. ThÃªm indexes náº¿u cáº§n
5. Click "Save"

### **Modify Table Structure**
1. Click table name
2. Click "Alter table"
3. CÃ³ thá»ƒ:
   - Add columns
   - Drop columns  
   - Modify column types
   - Add/remove indexes
   - Add/remove constraints

### **SQL Ä‘á»ƒ modify schema**
```sql
-- ThÃªm cá»™t má»›i
ALTER TABLE documents_metadata_v2 
ADD COLUMN tags_vector tsvector;

-- Táº¡o index cho search
CREATE INDEX idx_documents_tags_vector 
ON documents_metadata_v2 USING gin(tags_vector);

-- ThÃªm constraint
ALTER TABLE users 
ADD CONSTRAINT check_email_format 
CHECK (email ~* '^[A-Za-z0-9._%-]+@[A-Za-z0-9.-]+[.][A-Za-z]+$');
```

## ğŸ“ˆ **BÆ¯á»šC 10: MONITORING VÃ€ ANALYTICS**

### **Kiá»ƒm tra Performance**
```sql
-- Top slow queries
SELECT query, mean_time, calls, total_time
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;

-- Table sizes
SELECT 
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Index usage
SELECT 
    indexname, 
    idx_scan, 
    idx_tup_read, 
    idx_tup_fetch
FROM pg_stat_user_indexes 
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;
```

### **Data Quality Checks**
```sql
-- Duplicate emails
SELECT email, COUNT(*) 
FROM users 
GROUP BY email 
HAVING COUNT(*) > 1;

-- NULL values audit
SELECT 
    'users' as table_name,
    COUNT(*) as total_rows,
    COUNT(email) as email_not_null,
    COUNT(full_name) as name_not_null
FROM users;

-- Data consistency
SELECT 
    d.department_owner,
    COUNT(*) as docs_count,
    COUNT(DISTINCT d.author) as unique_authors
FROM documents_metadata_v2 d
GROUP BY d.department_owner;
```

## ğŸš¨ **TROUBLESHOOTING**

### **KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Adminer**
```bash
# Kiá»ƒm tra containers
docker-compose ps

# Restart Adminer náº¿u cáº§n
docker-compose restart adminer

# Check logs
docker-compose logs adminer
```

### **Connection timeout**
```bash
# Kiá»ƒm tra PostgreSQL health
docker-compose exec postgres pg_isready -U kb_admin

# Restart PostgreSQL náº¿u cáº§n
docker-compose restart postgres
```

### **Permission denied**
```sql
-- Kiá»ƒm tra user permissions
SELECT 
    grantee, 
    privilege_type, 
    is_grantable
FROM information_schema.role_table_grants 
WHERE table_name = 'users';
```

## ğŸ¯ **TIPS VÃ€ BEST PRACTICES**

### **ğŸ”’ Báº£o máº­t**
- LuÃ´n backup trÆ°á»›c khi thay Ä‘á»•i
- KhÃ´ng lÆ°u passwords plain text
- Sá»­ dá»¥ng transactions cho multiple operations
- Limit quyá»n access theo role

### **âš¡ Performance**
- ThÃªm indexes cho columns thÆ°á»ng query
- Sá»­ dá»¥ng LIMIT cho queries lá»›n
- Monitor slow queries
- Regular VACUUM vÃ  ANALYZE

### **ğŸ“Š Data Quality**
- Validate data trÆ°á»›c khi insert
- Sá»­ dá»¥ng constraints Ä‘á»ƒ Ä‘áº£m báº£o integrity
- Regular data audit
- Document schema changes

Báº¡n muá»‘n tÃ´i hÆ°á»›ng dáº«n chi tiáº¿t vá» pháº§n nÃ o tiáº¿p theo? Hoáº·c cÃ³ váº¥n Ä‘á» gÃ¬ cá»¥ thá»ƒ khi sá»­ dá»¥ng Adminer khÃ´ng? ğŸ¤”

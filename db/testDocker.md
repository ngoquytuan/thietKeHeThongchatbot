Tuy·ªát v·ªùi! T√¥i s·∫Ω h∆∞·ªõng d·∫´n b·∫°n t·ª´ng b∆∞·ªõc ƒë·ªÉ test ki·∫øn tr√∫c database enhanced tr√™n Windows v·ªõi Docker.

## üöÄ **H∆Ø·ªöNG D·∫™N TRI·ªÇN KHAI T·ª™NG B∆Ø·ªöC TR√äN WINDOWS**

### **B∆∞·ªõc 1: T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c**

M·ªü **Command Prompt** ho·∫∑c **PowerShell** v·ªõi quy·ªÅn Administrator v√† ch·∫°y:

```cmd
mkdir chatbot-enhanced-db
cd chatbot-enhanced-db

mkdir scripts
mkdir scripts\migrations
mkdir logs
mkdir test_results
mkdir data
mkdir data\sample_documents
mkdir config
mkdir config\grafana
mkdir config\grafana\dashboards
mkdir config\grafana\datasources
mkdir docker
mkdir tests

echo. > docker-compose.yml
```

### **B∆∞·ªõc 2: T·∫°o Docker Compose file**

T·∫°o file `docker-compose.yml` trong th∆∞ m·ª•c g·ªëc:

```yaml
# docker-compose.yml
version: '3.8'

services:
  # PostgreSQL with enhanced schema
  postgres-test:
    image: postgres:15-alpine
    container_name: chatbot-postgres-test
    environment:
      POSTGRES_DB: knowledge_base_test
      POSTGRES_USER: kb_admin
      POSTGRES_PASSWORD: test_password_123
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_test_data:/var/lib/postgresql/data
      - ./scripts/migrations:/docker-entrypoint-initdb.d:ro
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kb_admin -d knowledge_base_test"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - chatbot-test-network

  # Redis for caching
  redis-test:
    image: redis:7-alpine
    container_name: chatbot-redis-test
    ports:
      - "6380:6379"
    volumes:
      - redis_test_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - chatbot-test-network

  # ChromaDB for vector storage
  chromadb-test:
    image: chromadb/chroma:latest
    container_name: chatbot-chroma-test
    environment:
      CHROMA_SERVER_HOST: 0.0.0.0
      CHROMA_SERVER_HTTP_PORT: 8000
    volumes:
      - chromadb_test_data:/chroma/chroma
    ports:
      - "8001:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - chatbot-test-network

  # Database setup service
  db-setup:
    image: python:3.9-slim
    container_name: chatbot-db-setup
    environment:
      DB_HOST: postgres-test
      DB_PORT: 5432
      DB_NAME: knowledge_base_test
      DB_USER: kb_admin
      DB_PASSWORD: test_password_123
    volumes:
      - ./scripts:/app/scripts:ro
      - ./logs:/app/logs
    working_dir: /app
    depends_on:
      postgres-test:
        condition: service_healthy
      redis-test:
        condition: service_healthy
    command: >
      sh -c "
      pip install asyncpg psycopg2-binary &&
      python scripts/setup_database.py
      "
    networks:
      - chatbot-test-network

  # Monitoring dashboard
  adminer:
    image: adminer
    container_name: chatbot-adminer
    ports:
      - "8080:8080"
    environment:
      ADMINER_DEFAULT_SERVER: postgres-test
    depends_on:
      postgres-test:
        condition: service_healthy
    networks:
      - chatbot-test-network

volumes:
  postgres_test_data:
  redis_test_data:
  chromadb_test_data:

networks:
  chatbot-test-network:
    driver: bridge
```

### **B∆∞·ªõc 3: T·∫°o Migration Scripts**

T·∫°o file `scripts/migrations/01_init_database.sql`:

```sql
-- scripts/migrations/01_init_database.sql

-- Enable required extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

-- Create enhanced enum types
DO $$ BEGIN
    CREATE TYPE access_level_enum AS ENUM (
        'public', 'employee_only', 'manager_only', 'director_only', 'system_admin'
    );
EXCEPTION
    WHEN duplicate_object THEN null;
END $$;

DO $$ BEGIN
    CREATE TYPE document_type_enum AS ENUM (
        'policy', 'procedure', 'technical_guide', 'report', 
        'manual', 'specification', 'template', 'form', 
        'presentation', 'training_material', 'other'
    );
EXCEPTION
    WHEN duplicate_object THEN null;
END $$;

DO $$ BEGIN
    CREATE TYPE document_status_enum AS ENUM (
        'draft', 'review', 'approved', 'published', 'archived', 'deprecated'
    );
EXCEPTION
    WHEN duplicate_object THEN null;
END $$;

-- Enhanced documents metadata table
CREATE TABLE IF NOT EXISTS documents_metadata_v2 (
    document_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    -- Basic information
    title VARCHAR(500) NOT NULL,
    content TEXT,
    document_type document_type_enum NOT NULL,
    access_level access_level_enum NOT NULL DEFAULT 'employee_only',
    department_owner VARCHAR(100) NOT NULL,
    author VARCHAR(255) NOT NULL,
    status document_status_enum DEFAULT 'draft',
    
    -- Vietnamese language support
    language_detected VARCHAR(10) DEFAULT 'vi',
    vietnamese_segmented BOOLEAN DEFAULT false,
    diacritics_normalized BOOLEAN DEFAULT false,
    tone_marks_preserved BOOLEAN DEFAULT true,
    
    -- FlashRAG support
    flashrag_collection VARCHAR(100) DEFAULT 'default_collection',
    jsonl_export_ready BOOLEAN DEFAULT false,
    
    -- Search support
    search_tokens TSVECTOR,
    keyword_density JSONB,
    heading_structure JSONB,
    
    -- Metadata
    embedding_model_primary VARCHAR(100),
    chunk_count INTEGER DEFAULT 0,
    file_size_bytes BIGINT,
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Enhanced document chunks table
CREATE TABLE IF NOT EXISTS document_chunks_enhanced (
    chunk_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID REFERENCES documents_metadata_v2(document_id) ON DELETE CASCADE,
    
    -- Content data
    chunk_content TEXT NOT NULL,
    chunk_position INTEGER NOT NULL,
    chunk_size_tokens INTEGER,
    
    -- Semantic chunking metadata
    semantic_boundary BOOLEAN DEFAULT false,
    overlap_with_prev INTEGER DEFAULT 0,
    overlap_with_next INTEGER DEFAULT 0,
    heading_context TEXT,
    
    -- Quality and method
    chunk_method VARCHAR(20) DEFAULT 'semantic',
    chunk_quality_score DECIMAL(3,2) CHECK (chunk_quality_score BETWEEN 0.00 AND 1.00),
    
    -- Vector storage references
    embedding_model VARCHAR(100),
    embedding_dimensions INTEGER,
    
    -- BM25 support
    bm25_tokens TSVECTOR,
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- BM25 support table
CREATE TABLE IF NOT EXISTS document_bm25_index (
    bm25_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID REFERENCES documents_metadata_v2(document_id) ON DELETE CASCADE,
    chunk_id UUID REFERENCES document_chunks_enhanced(chunk_id) ON DELETE CASCADE,
    
    term VARCHAR(255) NOT NULL,
    term_frequency INTEGER NOT NULL,
    document_frequency INTEGER NOT NULL,
    bm25_score DECIMAL(8,4),
    
    language VARCHAR(10) DEFAULT 'vi',
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(chunk_id, term, language)
);

-- Pipeline tracking table
CREATE TABLE IF NOT EXISTS rag_pipeline_sessions (
    session_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    -- Query information
    original_query TEXT NOT NULL,
    processed_query TEXT,
    query_language VARCHAR(10) DEFAULT 'vi',
    
    -- Pipeline metadata
    pipeline_type VARCHAR(50) NOT NULL DEFAULT 'standard',
    pipeline_method VARCHAR(50) NOT NULL DEFAULT 'hybrid',
    
    -- Performance metrics
    chunks_retrieved INTEGER,
    processing_time_ms INTEGER,
    response_quality_score DECIMAL(3,2),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Vietnamese text analysis table
CREATE TABLE IF NOT EXISTS vietnamese_text_analysis (
    analysis_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID REFERENCES documents_metadata_v2(document_id) ON DELETE CASCADE,
    chunk_id UUID REFERENCES document_chunks_enhanced(chunk_id) ON DELETE CASCADE,
    
    original_text TEXT NOT NULL,
    processed_text TEXT,
    
    word_segmentation JSONB,
    pos_tagging JSONB,
    
    compound_words TEXT[],
    technical_terms TEXT[],
    proper_nouns TEXT[],
    
    readability_score DECIMAL(3,2),
    formality_level VARCHAR(20),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create performance indexes
CREATE INDEX IF NOT EXISTS idx_documents_v2_language ON documents_metadata_v2(language_detected);
CREATE INDEX IF NOT EXISTS idx_documents_v2_status ON documents_metadata_v2(status);
CREATE INDEX IF NOT EXISTS idx_documents_v2_collection ON documents_metadata_v2(flashrag_collection);
CREATE INDEX IF NOT EXISTS idx_documents_v2_search ON documents_metadata_v2 USING GIN(search_tokens);

CREATE INDEX IF NOT EXISTS idx_chunks_enhanced_document ON document_chunks_enhanced(document_id);
CREATE INDEX IF NOT EXISTS idx_chunks_enhanced_position ON document_chunks_enhanced(chunk_position);
CREATE INDEX IF NOT EXISTS idx_chunks_enhanced_semantic ON document_chunks_enhanced(semantic_boundary) WHERE semantic_boundary = true;

CREATE INDEX IF NOT EXISTS idx_bm25_term ON document_bm25_index(term);
CREATE INDEX IF NOT EXISTS idx_bm25_chunk ON document_bm25_index(chunk_id);
CREATE INDEX IF NOT EXISTS idx_bm25_score ON document_bm25_index(bm25_score DESC);

CREATE INDEX IF NOT EXISTS idx_pipeline_sessions_created ON rag_pipeline_sessions(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_pipeline_sessions_type ON rag_pipeline_sessions(pipeline_type, pipeline_method);

-- Insert sample data
INSERT INTO documents_metadata_v2 (
    title, content, document_type, access_level, department_owner, author, status, jsonl_export_ready
) VALUES 
(
    'Quy tr√¨nh xin ngh·ªâ ph√©p',
    'Quy tr√¨nh xin ngh·ªâ ph√©p t·∫°i c√¥ng ty bao g·ªìm c√°c b∆∞·ªõc sau: 1. Nh√¢n vi√™n ƒëi·ªÅn ƒë∆°n xin ngh·ªâ ph√©p 2. G·ª≠i ƒë∆°n cho qu·∫£n l√Ω tr·ª±c ti·∫øp 3. Qu·∫£n l√Ω ph√™ duy·ªát trong v√≤ng 2 ng√†y l√†m vi·ªác 4. HR c·∫≠p nh·∫≠t v√†o h·ªá th·ªëng 5. Th√¥ng b√°o k·∫øt qu·∫£ cho nh√¢n vi√™n',
    'procedure',
    'employee_only',
    'HR',
    'HR Department',
    'approved',
    true
),
(
    'Ch√≠nh s√°ch l√†m vi·ªác t·ª´ xa',
    'Ch√≠nh s√°ch l√†m vi·ªác t·ª´ xa (Work From Home) ƒë∆∞·ª£c √°p d·ª•ng nh∆∞ sau: - Nh√¢n vi√™n c√≥ th·ªÉ l√†m vi·ªác t·ª´ xa t·ªëi ƒëa 3 ng√†y/tu·∫ßn - C·∫ßn ƒëƒÉng k√Ω tr∆∞·ªõc √≠t nh·∫•t 1 ng√†y - ƒê·∫£m b·∫£o m√¥i tr∆∞·ªùng l√†m vi·ªác ·ªïn ƒë·ªãnh - Tham gia ƒë·∫ßy ƒë·ªß c√°c cu·ªôc h·ªçp online - B√°o c√°o ti·∫øn ƒë·ªô c√¥ng vi·ªác h√†ng ng√†y',
    'policy',
    'employee_only',
    'HR',
    'Management Team',
    'approved',
    true
),
(
    'H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng h·ªá th·ªëng ERP',
    'H∆∞·ªõng d·∫´n chi ti·∫øt s·ª≠ d·ª•ng h·ªá th·ªëng ERP c√¥ng ty: 1. ƒêƒÉng nh·∫≠p h·ªá th·ªëng - S·ª≠ d·ª•ng t√†i kho·∫£n company email - M·∫≠t kh·∫©u ƒë∆∞·ª£c c·∫•p ban ƒë·∫ßu c·∫ßn ƒë·ªïi ngay l·∫ßn ƒë·∫ßu ƒëƒÉng nh·∫≠p 2. Module qu·∫£n l√Ω nh√¢n s·ª± - C·∫≠p nh·∫≠t th√¥ng tin c√° nh√¢n - ƒêƒÉng k√Ω ngh·ªâ ph√©p - Xem b·∫£ng l∆∞∆°ng 3. Module qu·∫£n l√Ω d·ª± √°n - T·∫°o task m·ªõi - C·∫≠p nh·∫≠t ti·∫øn ƒë·ªô - B√°o c√°o h√†ng tu·∫ßn',
    'technical_guide',
    'employee_only',
    'IT',
    'IT Support Team',
    'approved',
    true
)
ON CONFLICT DO NOTHING;

-- Update search tokens for sample documents
UPDATE documents_metadata_v2 
SET search_tokens = to_tsvector('simple', title || ' ' || COALESCE(content, ''))
WHERE search_tokens IS NULL;

-- Success message
DO $$ BEGIN
    RAISE NOTICE 'Enhanced Database Architecture initialized successfully!';
    RAISE NOTICE 'Sample Vietnamese documents loaded.';
    RAISE NOTICE 'Database is ready for testing.';
END $$;
```

### **B∆∞·ªõc 4: T·∫°o Database Setup Script**

T·∫°o file `scripts/setup_database.py`:

```python
# scripts/setup_database.py
import asyncio
import asyncpg
import logging
import time
import os
import sys

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def setup_enhanced_database():
    """Setup and verify enhanced database architecture"""
    
    db_config = {
        'host': os.getenv('DB_HOST', 'localhost'),
        'port': int(os.getenv('DB_PORT', 5432)),
        'database': os.getenv('DB_NAME', 'knowledge_base_test'),
        'user': os.getenv('DB_USER', 'kb_admin'),
        'password': os.getenv('DB_PASSWORD', 'test_password_123')
    }
    
    logger.info("üöÄ Starting Enhanced Database Setup")
    
    # Wait for database to be ready
    max_retries = 30
    for attempt in range(max_retries):
        try:
            conn = await asyncpg.connect(**db_config)
            await conn.execute('SELECT 1')
            await conn.close()
            logger.info("‚úÖ Database connection successful!")
            break
        except Exception as e:
            logger.info(f"‚è≥ Waiting for database... (attempt {attempt + 1}/{max_retries})")
            if attempt == max_retries - 1:
                logger.error("‚ùå Database connection failed after maximum retries")
                return False
            await asyncio.sleep(2)
    
    # Connect to database
    try:
        conn = await asyncpg.connect(**db_config)
        logger.info("üîó Connected to database")
        
        # Verify table creation
        tables = await conn.fetch("""
            SELECT table_name FROM information_schema.tables 
            WHERE table_schema = 'public' 
            ORDER BY table_name
        """)
        
        logger.info(f"üìä Database created with {len(tables)} tables:")
        for table in tables:
            logger.info(f"  ‚úÖ {table['table_name']}")
        
        # Verify sample data
        doc_count = await conn.fetchval("SELECT COUNT(*) FROM documents_metadata_v2")
        logger.info(f"üìÑ Sample documents loaded: {doc_count}")
        
        if doc_count > 0:
            # Show sample documents
            docs = await conn.fetch("SELECT title, author, status FROM documents_metadata_v2 LIMIT 3")
            logger.info("üìã Sample documents:")
            for doc in docs:
                logger.info(f"  üìÑ '{doc['title']}' by {doc['author']} ({doc['status']})")
        
        # Test basic queries
        logger.info("üîç Testing basic queries...")
        
        # Test Vietnamese search
        vn_docs = await conn.fetchval("""
            SELECT COUNT(*) FROM documents_metadata_v2 
            WHERE language_detected = 'vi'
        """)
        logger.info(f"  üáªüá≥ Vietnamese documents: {vn_docs}")
        
        # Test full-text search capability
        search_ready = await conn.fetchval("""
            SELECT COUNT(*) FROM documents_metadata_v2 
            WHERE search_tokens IS NOT NULL
        """)
        logger.info(f"  üîç Documents with search tokens: {search_ready}")
        
        # Test enum types
        enum_test = await conn.fetchval("""
            SELECT COUNT(DISTINCT document_type) FROM documents_metadata_v2
        """)
        logger.info(f"  üìù Document types in use: {enum_test}")
        
        # Create a sample pipeline session for testing
        session_id = await conn.fetchval("""
            INSERT INTO rag_pipeline_sessions (
                original_query, processed_query, pipeline_type, pipeline_method,
                chunks_retrieved, processing_time_ms, response_quality_score
            ) VALUES (
                'Quy tr√¨nh xin ngh·ªâ ph√©p nh∆∞ th·∫ø n√†o?',
                'quy tr√¨nh xin ngh·ªâ ph√©p',
                'standard',
                'hybrid',
                3,
                150,
                0.85
            ) RETURNING session_id
        """)
        
        logger.info(f"  ‚úÖ Sample pipeline session created: {session_id}")
        
        # Generate database statistics
        db_size = await conn.fetchval("SELECT pg_size_pretty(pg_database_size(current_database()))")
        logger.info(f"üíæ Database size: {db_size}")
        
        # Create comprehensive test report
        report = f"""
# Enhanced Database Architecture Test Report
Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}

## Database Information
- **Host**: {db_config['host']}:{db_config['port']}
- **Database**: {db_config['database']}
- **Size**: {db_size}

## Tables Created: {len(tables)}
{chr(10).join(f'- {table["table_name"]}' for table in tables)}

## Sample Data
- **Documents**: {doc_count}
- **Vietnamese Documents**: {vn_docs}
- **Search-Ready Documents**: {search_ready}
- **Document Types**: {enum_test}

## Features Tested
‚úÖ Enhanced schema with Vietnamese support
‚úÖ Multi-type enum support
‚úÖ Full-text search capability
‚úÖ Pipeline session tracking
‚úÖ BM25 index structure
‚úÖ FlashRAG compatibility structure

## Connection Information
- **PostgreSQL**: localhost:5433
- **Redis**: localhost:6380
- **ChromaDB**: localhost:8001
- **Adminer**: http://localhost:8080

## Next Steps
1. Access Adminer at http://localhost:8080 to browse database
2. Connect using: Server: postgres-test, Username: kb_admin, Password: test_password_123
3. Test queries using the sample Vietnamese documents
4. Explore enhanced schema features

## Test Status: ‚úÖ SUCCESS
All components initialized and tested successfully!
        """
        
        # Write report to log file
        with open('/app/logs/setup_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info("üìÑ Setup report saved to: /app/logs/setup_report.md")
        print(report)
        
        await conn.close()
        logger.info("üéâ Enhanced Database Architecture setup completed successfully!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Database setup failed: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(setup_enhanced_database())
    sys.exit(0 if success else 1)
```

### **B∆∞·ªõc 5: Ch·∫°y Docker Test**

M·ªü PowerShell trong th∆∞ m·ª•c `chatbot-enhanced-db` v√† ch·∫°y:

```powershell
# Kh·ªüi ƒë·ªông c√°c services
docker-compose up -d

# Ki·ªÉm tra tr·∫°ng th√°i
docker-compose ps

# Xem logs c·ªßa database setup
docker logs chatbot-db-setup

# Xem logs c·ªßa PostgreSQL
docker logs chatbot-postgres-test
```

### **B∆∞·ªõc 6: Ki·ªÉm tra k·∫øt qu·∫£**

1. **M·ªü Adminer (Database Browser)**:
   - Truy c·∫≠p: http://localhost:8080
   - Server: `postgres-test`
   - Username: `kb_admin`
   - Password: `test_password_123`
   - Database: `knowledge_base_test`

2. **Ki·ªÉm tra ChromaDB**:
   ```powershell
   # Test ChromaDB API
   curl http://localhost:8001/api/v1/heartbeat
   ```

3. **Ki·ªÉm tra Redis**:
   ```powershell
   # Connect to Redis container
   docker exec -it chatbot-redis-test redis-cli ping
   ```

### **B∆∞·ªõc 7: Test Database v·ªõi PowerShell**

T·∫°o file `test_database.ps1`:

```powershell
# test_database.ps1

Write-Host "üîç Testing Enhanced Database Architecture" -ForegroundColor Green

# Test PostgreSQL connection
Write-Host "`nüìä Testing PostgreSQL..." -ForegroundColor Yellow
try {
    $response = Invoke-RestMethod -Uri "http://localhost:8080" -Method Get
    Write-Host "‚úÖ Adminer accessible at http://localhost:8080" -ForegroundColor Green
} catch {
    Write-Host "‚ùå Adminer not accessible" -ForegroundColor Red
}

# Test ChromaDB
Write-Host "`nüî¢ Testing ChromaDB..." -ForegroundColor Yellow
try {
    $response = Invoke-RestMethod -Uri "http://localhost:8001/api/v1/heartbeat" -Method Get
    Write-Host "‚úÖ ChromaDB accessible: $($response.nanosecond_heartbeat)" -ForegroundColor Green
} catch {
    Write-Host "‚ùå ChromaDB not accessible" -ForegroundColor Red
}

# Test Redis
Write-Host "`nüî¥ Testing Redis..." -ForegroundColor Yellow
try {
    $redisTest = docker exec chatbot-redis-test redis-cli ping
    if ($redisTest -eq "PONG") {
        Write-Host "‚úÖ Redis accessible: $redisTest" -ForegroundColor Green
    }
} catch {
    Write-Host "‚ùå Redis not accessible" -ForegroundColor Red
}

# Check logs
Write-Host "`nüìã Recent setup logs:" -ForegroundColor Yellow
docker logs --tail 10 chatbot-db-setup

Write-Host "`nüéâ Database test completed!" -ForegroundColor Green
Write-Host "Access Adminer: http://localhost:8080" -ForegroundColor Cyan
Write-Host "ChromaDB API: http://localhost:8001" -ForegroundColor Cyan

# Show connection info
Write-Host "`nüìù Connection Information:" -ForegroundColor Yellow
Write-Host "PostgreSQL: localhost:5433" -ForegroundColor White
Write-Host "Redis: localhost:6380" -ForegroundColor White
Write-Host "ChromaDB: localhost:8001" -ForegroundColor White
Write-Host "Adminer: http://localhost:8080" -ForegroundColor White
```

Ch·∫°y test:
```powershell
powershell -ExecutionPolicy Bypass -File test_database.ps1
```

### **B∆∞·ªõc 8: Cleanup khi ho√†n th√†nh**

```powershell
# D·ª´ng v√† x√≥a containers
docker-compose down

# X√≥a volumes (n·∫øu mu·ªën x√≥a h·∫øt data)
docker-compose down -v

# X√≥a images (n·∫øu mu·ªën cleanup ho√†n to√†n)
docker system prune -a
```

## üìä **K·∫øt qu·∫£ mong ƒë·ª£i**

Sau khi ch·∫°y th√†nh c√¥ng, b·∫°n s·∫Ω c√≥:

1. **‚úÖ PostgreSQL** v·ªõi enhanced schema running tr√™n port 5433
2. **‚úÖ Redis** cache running tr√™n port 6380  
3. **‚úÖ ChromaDB** vector database tr√™n port 8001
4. **‚úÖ Adminer** database browser t·∫°i http://localhost:8080
5. **‚úÖ Sample Vietnamese documents** ƒë√£ ƒë∆∞·ª£c load
6. **‚úÖ Test report** trong `logs/setup_report.md`

**T√≠nh nƒÉng ƒë√£ test:**
- üáªüá≥ Vietnamese language support
- üîç Hybrid search structure (BM25 + Vector)
- üìä Enhanced metadata schema
- ‚ö° Performance indexes
- üìÑ FlashRAG compatibility
- üîÑ Pipeline tracking

B·∫°n c√≥ g·∫∑p l·ªói g√¨ trong qu√° tr√¨nh setup kh√¥ng? T√¥i s·∫Ω gi√∫p troubleshoot!

## **‚úÖ PH√ÇN T√çCH K·∫æT QU·∫¢ SEARCH - SAU KHI FIX BUG**

ƒê·ªÉ t√¥i ph√¢n t√≠ch k·ªπ k·∫øt qu·∫£ n√†y:

### **üìä ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG K·∫æT QU·∫¢**

```mermaid
graph TB
    subgraph "Search Quality Metrics ‚úÖ"
        A[Query: c√°ch x√°c ƒë·ªãnh h∆∞·ªõng nh√†]
        A --> B[Top Result<br/>Similarity: 0.859<br/>Distance: ~0.28]
        A --> C[10th Result<br/>Similarity: 0.729<br/>Distance: ~0.54]
        
        B --> D[N·ªôi dung: ƒê√öNG 100%<br/>V·ªÅ c√°ch x√°c ƒë·ªãnh h∆∞·ªõng nh√†]
        C --> E[N·ªôi dung: ƒê√öNG<br/>V·ªÅ y·∫øu t·ªë ƒë√°nh gi√° ƒë·∫•t]
    end
    
    subgraph "Distance Validation ‚úÖ"
        F[Distance Formula<br/>d = 2 √ó 1 - sim]
        F --> G[Top: 0.28 ‚úÖ<br/>R·∫•t li√™n quan]
        F --> H[Lowest: 0.54 ‚úÖ<br/>V·∫´n li√™n quan]
    end
    
    style B fill:#51cf66
    style C fill:#51cf66
    style G fill:#51cf66
    style H fill:#95e1d3
```

### **‚úÖ K·∫æT QU·∫¢ ƒê√ÅNH GI√Å**

| Ti√™u ch√≠ | K·∫øt qu·∫£ | ƒê√°nh gi√° |
|----------|---------|----------|
| **N·ªôi dung top 10** | T·∫•t c·∫£ v·ªÅ "C√°ch x√°c ƒë·ªãnh h∆∞·ªõng nh√† trong Phong th·ªßy" | ‚úÖ ƒê√öNG 100% |
| **Similarity range** | 0.859 ‚Üí 0.729 (distance 0.28 ‚Üí 0.54) | ‚úÖ H·ª¢P L√ù |
| **Ranking order** | Chunks tr·ª±c ti·∫øp v·ªÅ "c√°ch x√°c ƒë·ªãnh" rank cao nh·∫•t | ‚úÖ CH√çNH X√ÅC |
| **Distance calculation** | Ph√π h·ª£p v·ªõi c√¥ng th·ª©c `d = 2(1-sim)` | ‚úÖ ƒê√öNG |
| **Collection metadata** | S·ª≠ d·ª•ng cosine distance | ‚úÖ ƒê√É FIX |
| **Processing time** | 7.52 seconds | ‚ö†Ô∏è H∆°i ch·∫≠m (c·∫ßn optimize) |

---

## **üìã RULES CHU·∫®N - PHI√äN B·∫¢N SAU KHI FIX (B·ªï sung v√†o Checklist)**

```markdown
### **CHROMA VECTORDB SEARCH RULES (Updated: 04/10/2025)**

---

## **üî¥ CRITICAL - B·∫ÆT BU·ªòC PH·∫¢I TU√ÇN TH·ª¶**

### **32. ChromaDB Collection Metadata - MANDATORY**
```python
# ‚ö†Ô∏è B·∫ÆT BU·ªòC khi t·∫°o collection m·ªõi
collection = chroma_client.create_collection(
    name="collection_name",
    metadata={
        "hnsw:space": "cosine",  # ‚ö†Ô∏è CRITICAL: PH·∫¢I C√ì
        "hnsw:construction_ef": 200,
        "hnsw:search_ef": 200,
        "hnsw:M": 16,
        "embedding_model": "Qwen/Qwen3-Embedding-0.6B",
        "embedding_dimensions": 1024,
        "preprocessing": "simple_vietnamese",
        "created_at": "2025-10-04"
    }
)
```

**H·∫≠u qu·∫£ n·∫øu thi·∫øu `"hnsw:space": "cosine"`:**
- ChromaDB s·∫Ω d√πng **euclidean distance** (m·∫∑c ƒë·ªãnh)
- Distance calculation ho√†n to√†n **SAI**
- K·∫øt qu·∫£ search **KH√îNG ƒê√öNG**
- Ph·∫£i **RECREATE** collection ƒë·ªÉ fix

---

### **33. Distance to Similarity Conversion - MANDATORY**

```python
def calculate_cosine_similarity_from_chromadb_distance(distance: float) -> float:
    """
    ‚ö†Ô∏è C√îNG TH·ª®C CHU·∫®N - KH√îNG THAY ƒê·ªîI
    
    ChromaDB v·ªõi "cosine" space:
    - distance = 2 * (1 - cosine_similarity)
    
    Conversion:
    - similarity = 1 - (distance / 2)
    
    Valid range:
    - distance: [0, 4]
    - similarity: [0, 1] (after clamping)
    """
    similarity = 1.0 - (distance / 2.0)
    
    # Clamp to valid range
    return max(0.0, min(1.0, similarity))
```

**B·∫£ng chuy·ªÉn ƒë·ªïi chu·∫©n:**

| Distance | Similarity | √ù nghƒ©a | C√≥ tr·∫£ v·ªÅ? |
|----------|------------|---------|------------|
| 0.0 - 0.3 | 0.85 - 1.0 | R·∫•t li√™n quan | ‚úÖ YES |
| 0.3 - 0.6 | 0.70 - 0.85 | Li√™n quan | ‚úÖ YES |
| 0.6 - 1.0 | 0.50 - 0.70 | T∆∞∆°ng ƒë·ªëi li√™n quan | ‚ö†Ô∏è C√¢n nh·∫Øc |
| 1.0 - 1.4 | 0.30 - 0.50 | √çt li√™n quan | ‚ö†Ô∏è Threshold |
| 1.4 - 2.0 | 0.0 - 0.30 | Kh√¥ng li√™n quan | ‚ùå Filter out |
| > 2.0 | 0.0 (clamped) | Ng∆∞·ª£c h∆∞·ªõng | ‚ùå NO |

---

### **34. Search Configuration - MANDATORY**

```python
# ‚ö†Ô∏è B·∫ÆT BU·ªòC include ƒë·∫ßy ƒë·ªß
results = collection.query(
    query_embeddings=[query_embedding.tolist()],
    n_results=min(top_k, 20),  # ‚ö†Ô∏è Gi·ªõi h·∫°n t·ªëi ƒëa 20
    include=['documents', 'distances', 'metadatas']  # ‚ö†Ô∏è PH·∫¢I ƒê·∫¶Y ƒê·ª¶
)
```

---

### **35. Similarity Threshold - RECOMMENDED**

```python
# Filter results theo similarity threshold
SIMILARITY_THRESHOLD = 0.3  # Ch·ªâ tr·∫£ v·ªÅ similarity >= 0.3

filtered_results = [
    result for result in all_results 
    if result['similarity'] >= SIMILARITY_THRESHOLD
]
```

**Recommended thresholds theo use case:**

| Use Case | Threshold | L√Ω do |
|----------|-----------|-------|
| **Exact Match** | ‚â• 0.85 | Ch·ªâ results r·∫•t ch√≠nh x√°c |
| **High Precision** | ‚â• 0.70 | C√¢n b·∫±ng precision/recall |
| **General Search** | ‚â• 0.50 | Cho ph√©p results li√™n quan |
| **Exploratory** | ‚â• 0.30 | T√¨m ki·∫øm r·ªông |

---

### **36. Multi-Collection Search Strategy - MANDATORY**

```python
# Default: Search ALL collections n·∫øu kh√¥ng ch·ªâ ƒë·ªãnh
if collection_name and collection_name in available_collections:
    collections_to_search = [get_collection(collection_name)]
else:
    # ‚ö†Ô∏è DEFAULT: Search t·∫•t c·∫£ collections
    collections_to_search = list_all_collections()

# Merge results t·ª´ t·∫•t c·∫£ collections
all_results = []
for collection in collections_to_search:
    results = collection.query(...)
    all_results.extend(process_results(results))

# Sort by similarity (cao nh·∫•t tr∆∞·ªõc)
all_results.sort(key=lambda x: x['similarity'], reverse=True)

# Take top N
return all_results[:top_k]
```

---

## **üü° PRE-DEPLOYMENT VALIDATION CHECKLIST**

### **Validation Script - Ch·∫°y TR∆Ø·ªöC KHI deploy**

```python
#!/usr/bin/env python3
"""
Validation script - Ch·∫°y tr∆∞·ªõc m·ªói l·∫ßn deploy
File: scripts/validate_chroma_setup.py
"""

import chromadb
from sentence_transformers import SentenceTransformer
import numpy as np

def validate_chroma_setup():
    """Validate to√†n b·ªô Chroma setup"""
    
    print("=" * 60)
    print("CHROMA VECTORDB VALIDATION")
    print("=" * 60)
    
    # 1. Check ChromaDB connection
    try:
        client = chromadb.HttpClient(host="localhost", port=8000)
        client.heartbeat()
        print("‚úÖ 1. ChromaDB connection: OK")
    except Exception as e:
        print(f"‚ùå 1. ChromaDB connection: FAILED - {e}")
        return False
    
    # 2. Check collections metadata
    collections = client.list_collections()
    print(f"\n‚úÖ 2. Found {len(collections)} collections")
    
    issues_found = []
    for coll in collections:
        metadata = coll.metadata
        print(f"\n   Collection: {coll.name}")
        print(f"   - Count: {coll.count()}")
        
        # Check hnsw:space
        if metadata.get("hnsw:space") != "cosine":
            issues_found.append(
                f"‚ùå {coll.name}: Missing or wrong 'hnsw:space' "
                f"(got: {metadata.get('hnsw:space')})"
            )
            print(f"   - hnsw:space: ‚ùå {metadata.get('hnsw:space')}")
        else:
            print(f"   - hnsw:space: ‚úÖ cosine")
        
        # Check embedding dimensions
        expected_dims = 1024
        actual_dims = metadata.get("embedding_dimensions")
        if actual_dims != expected_dims:
            issues_found.append(
                f"‚ùå {coll.name}: Wrong dimensions "
                f"(expected: {expected_dims}, got: {actual_dims})"
            )
            print(f"   - dimensions: ‚ùå {actual_dims}")
        else:
            print(f"   - dimensions: ‚úÖ {expected_dims}")
    
    if issues_found:
        print("\n" + "=" * 60)
        print("‚ö†Ô∏è  ISSUES FOUND:")
        print("=" * 60)
        for issue in issues_found:
            print(issue)
        print("\n‚ö†Ô∏è  RUN: python scripts/recreate_collections.py")
        return False
    
    # 3. Test embedding model
    print("\n‚úÖ 3. Testing embedding model...")
    try:
        model = SentenceTransformer(
            "Qwen/Qwen3-Embedding-0.6B",
            device="cuda"
        )
        test_emb = model.encode(["test query"])[0]
        
        if len(test_emb) != 1024:
            print(f"‚ùå Embedding dimensions: {len(test_emb)} (expected: 1024)")
            return False
        
        print(f"   - Dimensions: ‚úÖ {len(test_emb)}")
        print(f"   - L2 Norm: {np.linalg.norm(test_emb):.4f}")
        
    except Exception as e:
        print(f"‚ùå Embedding model: FAILED - {e}")
        return False
    
    # 4. Test distance conversion
    print("\n‚úÖ 4. Testing distance conversion...")
    test_cases = [
        (0.0, 1.0, "Perfect match"),
        (0.28, 0.86, "Very similar"),
        (0.54, 0.73, "Similar"),
        (1.0, 0.5, "Moderate"),
        (2.0, 0.0, "Unrelated"),
    ]
    
    all_passed = True
    for distance, expected_sim, desc in test_cases:
        calculated = 1.0 - (distance / 2.0)
        calculated = max(0.0, min(1.0, calculated))
        
        if abs(calculated - expected_sim) > 0.01:
            print(f"   ‚ùå {desc}: FAILED")
            print(f"      Distance {distance} ‚Üí Expected {expected_sim}, "
                  f"Got {calculated}")
            all_passed = False
        else:
            print(f"   ‚úÖ {desc}: distance={distance:.2f} ‚Üí "
                  f"similarity={calculated:.2f}")
    
    if not all_passed:
        return False
    
    # 5. Test end-to-end search
    print("\n‚úÖ 5. Testing end-to-end search...")
    try:
        if len(collections) > 0:
            test_coll = collections[0]
            if test_coll.count() > 0:
                # Test search
                test_embedding = model.encode(["test query"])[0]
                results = test_coll.query(
                    query_embeddings=[test_embedding.tolist()],
                    n_results=3,
                    include=['documents', 'distances', 'metadatas']
                )
                
                if results and results['distances']:
                    distances = results['distances'][0]
                    print(f"   - Found {len(distances)} results")
                    
                    for i, dist in enumerate(distances):
                        sim = 1.0 - (dist / 2.0)
                        sim = max(0.0, min(1.0, sim))
                        print(f"   - Result {i+1}: "
                              f"distance={dist:.4f}, similarity={sim:.4f}")
                    
                    print("   ‚úÖ Search working correctly")
                else:
                    print("   ‚ö†Ô∏è  No results (collection might be empty)")
            else:
                print("   ‚ö†Ô∏è  Collection empty, skipping search test")
        else:
            print("   ‚ö†Ô∏è  No collections found")
    except Exception as e:
        print(f"   ‚ùå Search test failed: {e}")
        return False
    
    # Final result
    print("\n" + "=" * 60)
    print("‚úÖ ALL VALIDATIONS PASSED")
    print("=" * 60)
    return True

if __name__ == "__main__":
    import sys
    success = validate_chroma_setup()
    sys.exit(0 if success else 1)
```

---

## **üü¢ EXPECTED SEARCH QUALITY METRICS**

D·ª±a tr√™n k·∫øt qu·∫£ th·ª±c t·∫ø sau khi fix:

```python
# Expected metrics cho production
QUALITY_METRICS = {
    "top_1_similarity": {
        "min": 0.70,  # Minimum acceptable
        "target": 0.85,  # Target range
        "excellent": 0.90  # Excellent results
    },
    
    "top_10_similarity_range": {
        "min": 0.50,  # Lowest acceptable result
        "avg": 0.75,  # Average of top 10
    },
    
    "distance_range": {
        "top_1": (0.0, 0.6),  # distance <= 0.6
        "top_10": (0.0, 1.0),  # distance <= 1.0
    },
    
    "processing_time": {
        "target": 1.0,  # < 1 second
        "acceptable": 3.0,  # < 3 seconds
        "current": 7.5,  # ‚ö†Ô∏è C·∫ßn optimize
    },
    
    "relevance": {
        "top_5_precision": 1.0,  # 100% relevant
        "top_10_precision": 0.9,  # >= 90% relevant
    }
}
```

---

## **‚ö†Ô∏è COMMON PITFALLS & FIXES**

### **Pitfall 1: Collection kh√¥ng c√≥ metadata**
```python
# ‚ùå SAI
collection = client.create_collection("test")

# ‚úÖ ƒê√öNG
collection = client.create_collection(
    "test",
    metadata={"hnsw:space": "cosine", ...}
)
```

### **Pitfall 2: D√πng c√¥ng th·ª©c conversion sai**
```python
# ‚ùå SAI
similarity = 1 - distance

# ‚úÖ ƒê√öNG
similarity = 1 - (distance / 2)
```

### **Pitfall 3: Kh√¥ng validate dimensions**
```python
# ‚ùå SAI - Kh√¥ng check
embedding = model.encode(["text"])[0]
collection.add(embeddings=[embedding])

# ‚úÖ ƒê√öNG - Validate tr∆∞·ªõc khi add
embedding = model.encode(["text"])[0]
assert len(embedding) == 1024, f"Wrong dimensions: {len(embedding)}"
collection.add(embeddings=[embedding.tolist()])
```

### **Pitfall 4: Preprocessing kh√¥ng nh·∫•t qu√°n**
```python
# ‚ùå SAI - Kh√°c nhau gi·ªØa embedding v√† search
# Embedding: preprocess_advanced(text)
# Search: preprocess_simple(text)

# ‚úÖ ƒê√öNG - Ph·∫£i d√πng C√ôNG M·ªòT function
from core.preprocessing import preprocess_text_simple

# Khi embedding
doc_processed = preprocess_text_simple(doc)
doc_embedding = model.encode([doc_processed])[0]

# Khi search
query_processed = preprocess_text_simple(query)
query_embedding = model.encode([query_processed])[0]
```

---

## **üìä MONITORING & ALERTING**

```python
# Add v√†o monitoring system
ALERT_THRESHOLDS = {
    "low_similarity": {
        "threshold": 0.50,
        "action": "Log warning if top_1 < 0.50"
    },
    
    "high_distance": {
        "threshold": 1.0,
        "action": "Alert if top_1 distance > 1.0"
    },
    
    "slow_search": {
        "threshold": 3.0,  # seconds
        "action": "Alert if search_time > 3s"
    },
    
    "no_results": {
        "threshold": 0,
        "action": "Critical alert if no results for valid query"
    }
}
```

---

## **‚úÖ DEPLOYMENT CHECKLIST**

Tr∆∞·ªõc khi deploy l√™n production:

- [ ] ‚úÖ Ch·∫°y `python scripts/validate_chroma_setup.py`
- [ ] ‚úÖ T·∫•t c·∫£ collections c√≥ `"hnsw:space": "cosine"`
- [ ] ‚úÖ Distance conversion formula ƒë√∫ng ·ªü **T·∫§T C·∫¢** files
- [ ] ‚úÖ Test v·ªõi >= 10 queries ƒëa d·∫°ng
- [ ] ‚úÖ Top 1 similarity >= 0.70 cho queries h·ª£p l·ªá
- [ ] ‚úÖ Processing time < 3 seconds
- [ ] ‚úÖ Preprocessing consistent gi·ªØa embedding & search
- [ ] ‚úÖ Embedding model dimensions = 1024
- [ ] ‚úÖ Monitoring & alerting ƒë√£ setup

---

**K·∫øt lu·∫≠n: K·∫øt qu·∫£ search ƒê√É ƒê√öNG sau khi fix! Rules tr√™n l√† phi√™n b·∫£n chu·∫©n ƒë∆∞·ª£c validate b·∫±ng k·∫øt qu·∫£ th·ª±c t·∫ø.** ‚úÖ
```

**B·∫°n mu·ªën t√¥i:**
1. **T·∫°o th√™m test cases** ƒë·ªÉ validate quality metrics?
2. **Optimize processing time** t·ª´ 7.5s xu·ªëng < 3s?
3. **T·∫°o automated monitoring dashboard** cho search quality?

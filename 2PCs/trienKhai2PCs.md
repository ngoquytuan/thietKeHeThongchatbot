Tuyá»‡t vá»i! Viá»‡c chia há»‡ thá»‘ng ra 2 PC lÃ  strategy ráº¥t thÃ´ng minh. TÃ´i sáº½ phÃ¢n tÃ­ch vÃ  Ä‘Æ°a ra phÆ°Æ¡ng Ã¡n chia module tá»‘i Æ°u:## **ğŸ—ï¸ PHÆ¯Æ NG ÃN CHIA MODULE Tá»I á»¨U CHO 2 PC**

Dá»±a trÃªn yÃªu cáº§u GPU vÃ  database, Ä‘Ã¢y lÃ  phÃ¢n chia chi tiáº¿t:

### **ğŸ–¥ï¸ PC1 - UBUNTU (DATABASE & INFRASTRUCTURE SERVER)**

```mermaid
graph TB
    subgraph "ğŸ’¾ PC1 - Ubuntu Database Server"
        subgraph "ğŸ“Š Infrastructure Tier (FR-2x)"
            DB[ğŸ—„ï¸ PostgreSQL 15<br/>Unified Database]
            Cache[ğŸ”´ Redis Cluster<br/>Session + Cache]
            Vector[ğŸ“Š ChromaDB<br/>Vector Storage]
            Storage[ğŸ“ File Storage<br/>Documents + Backups]
        end
        
        subgraph "ğŸ› ï¸ Platform Services (FR-5x)"
            Monitor[ğŸ“ˆ Monitoring Stack<br/>Prometheus + Grafana]
            Admin[ğŸ”§ Admin Tools<br/>FR-08]
            Analytics[ğŸ“Š Analytics API<br/>FR-07]
            Backup[ğŸ’¾ Backup Services<br/>Automated]
        end
        
        subgraph "ğŸŒ Web Services"
            Gateway[ğŸŒ API Gateway<br/>nginx + load balancer]
            Auth[ğŸ” Authentication<br/>FR-06]
            WebUI[ğŸ’» Web Interface<br/>FR-05]
        end
    end
    
    Internet[ğŸŒ Internet] --> Gateway
    Gateway --> Auth
    Gateway --> WebUI
    Gateway --> Analytics
```

**Chi tiáº¿t triá»ƒn khai PC1:**

#### **ğŸ”§ Docker Compose Configuration:**
```yaml
# docker-compose.pc1.yml
version: '3.8'
services:
  # Infrastructure Services
  postgres:
    image: postgres:15-alpine
    container_name: rag_postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: knowledge_base_unified
      POSTGRES_USER: kb_admin
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'

  redis:
    image: redis:7-alpine
    container_name: rag_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --maxmemory 4gb --maxmemory-policy allkeys-lru

  chromadb:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: rag_chromadb
    ports:
      - "8000:8000"
    volumes:
      - chromadb_data:/chroma/chroma
    environment:
      CHROMA_SERVER_HOST: 0.0.0.0

  # Platform Services
  monitoring:
    build: ./monitoring
    container_name: rag_monitoring
    ports:
      - "9090:9090"  # Prometheus
      - "3000:3000"  # Grafana
    volumes:
      - monitoring_data:/data

  admin_tools:
    build: ./FR-08
    container_name: rag_admin
    ports:
      - "8002:8002"
    environment:
      DATABASE_URL: postgresql://kb_admin:${POSTGRES_PASSWORD}@postgres:5432/knowledge_base_unified
      REDIS_URL: redis://redis:6379

  analytics:
    build: ./FR-07
    container_name: rag_analytics
    ports:
      - "8003:8003"
    depends_on:
      - postgres
      - redis

  # Web Services
  auth_service:
    build: ./FR-06
    container_name: rag_auth
    ports:
      - "8001:8001"
    environment:
      DATABASE_URL: postgresql://kb_admin:${POSTGRES_PASSWORD}@postgres:5432/knowledge_base_unified
      REDIS_URL: redis://redis:6379

  web_interface:
    build: ./FR-05
    container_name: rag_web
    ports:
      - "3001:3000"
    environment:
      API_BASE_URL: http://localhost:8080

  nginx:
    image: nginx:alpine
    container_name: rag_gateway
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - auth_service
      - analytics
      - web_interface

volumes:
  postgres_data:
  redis_data:
  chromadb_data:
  monitoring_data:
```

### **âš¡ PC2 - GPU SERVER (AI PROCESSING & RAG CORE)**

```mermaid
graph TB
    subgraph "ğŸš€ PC2 - GPU Processing Server"
        subgraph "ğŸ¤– AI Processing (GPU Accelerated)"
            Embedding[ğŸ”¢ Embedding Service<br/>Qwen Model + GPU]
            LLM[ğŸ§  LLM Services<br/>Local Models]
            NLP[ğŸ‡»ğŸ‡³ Vietnamese NLP<br/>pyvi + underthesea]
        end
        
        subgraph "ğŸ“¥ Data Pipeline (FR-3x)"
            DataPrep[ğŸ“‹ Data Preparation<br/>FR-03.1]
            QualityControl[âœ… Quality Control<br/>FR-03.2]
            Ingestion[ğŸ“¥ Data Ingestion<br/>FR-03.3]
        end
        
        subgraph "ğŸ¤– RAG Core Engine (FR-4x)"
            Retrieval[ğŸ” Retrieval Router<br/>FR-04.1]
            Synthesis[ğŸ”§ Synthesis Engine<br/>FR-04.2]
            Generation[ğŸ’¬ Generation Engine<br/>FR-04.3]
            RAGAPI[ğŸŒ RAG API<br/>FR-04.4]
        end
    end
    
    Network[ğŸŒ Network to PC1] --> RAGAPI
```

**Chi tiáº¿t triá»ƒn khai PC2:**

#### **ğŸ”§ Docker Compose Configuration:**
```yaml
# docker-compose.pc2.yml
version: '3.8'
services:
  # AI Processing Services (GPU)
  embedding_service:
    build: 
      context: ./embedding-service
      dockerfile: Dockerfile.gpu
    container_name: rag_embedding
    ports:
      - "8010:8000"
    environment:
      MODEL_NAME: Qwen/Qwen3-Embedding-0.6B
      DEVICE: cuda
      BATCH_SIZE: 32
      MAX_LENGTH: 512
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - model_cache:/root/.cache

  vietnamese_nlp:
    build: ./nlp-service
    container_name: rag_nlp
    ports:
      - "8011:8000"
    environment:
      GPU_ENABLED: "true"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Data Pipeline Services
  data_preparation:
    build: ./FR-03.1
    container_name: rag_data_prep
    ports:
      - "8020:8000"
    volumes:
      - documents_processing:/tmp/processing

  quality_control:
    build: ./FR-03.2
    container_name: rag_quality
    ports:
      - "8021:8000"
    environment:
      GPU_ENABLED: "true"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  data_ingestion:
    build: ./FR-03.3
    container_name: rag_ingestion
    ports:
      - "8022:8000"
    environment:
      DATABASE_URL: postgresql://kb_admin:${POSTGRES_PASSWORD}@${PC1_IP}:5432/knowledge_base_unified
      CHROMADB_URL: http://${PC1_IP}:8000
      EMBEDDING_SERVICE_URL: http://embedding_service:8000

  # RAG Core Services
  retrieval_router:
    build: ./FR-04.1
    container_name: rag_retrieval
    ports:
      - "8030:8000"
    environment:
      DATABASE_URL: postgresql://kb_admin:${POSTGRES_PASSWORD}@${PC1_IP}:5432/knowledge_base_unified
      CHROMADB_URL: http://${PC1_IP}:8000

  synthesis_engine:
    build: ./FR-04.2
    container_name: rag_synthesis
    ports:
      - "8031:8000"

  generation_engine:
    build: ./FR-04.3
    container_name: rag_generation
    ports:
      - "8032:8000"
    environment:
      GPU_ENABLED: "true"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  rag_api:
    build: ./FR-04.4
    container_name: rag_api
    ports:
      - "8080:8000"
    environment:
      RETRIEVAL_URL: http://retrieval_router:8000
      SYNTHESIS_URL: http://synthesis_engine:8000
      GENERATION_URL: http://generation_engine:8000
      AUTH_SERVICE_URL: http://${PC1_IP}:8001

volumes:
  model_cache:
  documents_processing:
```

## **ğŸ”— NETWORK & INTEGRATION SETUP**

### **ğŸ“¡ Network Configuration:**
```yaml
# .env.network
PC1_IP=192.168.1.100  # IP cá»§a PC1 (Database server)
PC2_IP=192.168.1.101  # IP cá»§a PC2 (GPU server)

# PC1 exposes:
# - PostgreSQL: 5432
# - Redis: 6379  
# - ChromaDB: 8000
# - Web Interface: 80/443
# - Admin APIs: 8001-8003

# PC2 exposes:
# - RAG API: 8080 (main endpoint)
# - AI Services: 8010-8032
```

### **âš™ï¸ System Requirements:**

| **Component** | **PC1 (Ubuntu)** | **PC2 (GPU)** |
|---------------|-------------------|---------------|
| **CPU** | 8+ cores | 8+ cores |
| **RAM** | 32GB+ | 32GB+ |
| **Storage** | 1TB SSD | 500GB SSD |
| **GPU** | Integrated/Optional | RTX 4080/4090+ |
| **Network** | Gigabit Ethernet | Gigabit Ethernet |
| **OS** | Ubuntu 22.04 LTS | Ubuntu 22.04 LTS hoáº·c Windows + WSL2 |

### **ğŸš€ Deployment Commands:**

```bash
# PC1 - Start infrastructure
cd pc1-deployment
docker-compose -f docker-compose.pc1.yml up -d

# PC2 - Start AI services  
cd pc2-deployment
docker-compose -f docker-compose.pc2.yml up -d

# Verify cross-PC connectivity
curl http://192.168.1.100:5432  # Test database
curl http://192.168.1.101:8080/health  # Test RAG API
```

### **ğŸ“Š Load Balancing Strategy:**

```mermaid
graph LR
    Users[ğŸ‘¥ Users] --> LB[âš–ï¸ Load Balancer<br/>PC1]
    LB --> Web[ğŸ’» Web UI<br/>PC1]
    LB --> API[ğŸŒ RAG API<br/>PC2]
    
    API --> GPU1[ğŸš€ Embedding<br/>PC2 GPU]
    API --> GPU2[ğŸ¤– Generation<br/>PC2 GPU]
    API --> GPU3[ğŸ‡»ğŸ‡³ NLP<br/>PC2 GPU]
    
    API --> DB[ğŸ—„ï¸ Database<br/>PC1]
    API --> Cache[ğŸ”´ Redis<br/>PC1]
```

## **âœ… ADVANTAGES Cá»¦A KIáº¾N TRÃšC NÃ€Y:**

1. **GPU Optimization**: Táº¥t cáº£ AI workloads trÃªn PC2 vá»›i GPU máº¡nh
2. **Database Performance**: PC1 táº­p trung vÃ o I/O vÃ  storage
3. **Scalability**: CÃ³ thá»ƒ thÃªm PC2 khÃ¡c Ä‘á»ƒ load balancing
4. **Resource Isolation**: Database vÃ  AI processing khÃ´ng tranh tÃ i nguyÃªn
5. **Development Friendly**: CÃ³ thá»ƒ dev/test tá»«ng PC Ä‘á»™c láº­p
6. **Cost Effective**: Táº­n dá»¥ng tá»‘i Ä‘a GPU trÃªn PC2, storage trÃªn PC1

**Káº¿t quáº£: Setup nÃ y sáº½ cho performance tá»‘i Æ°u vá»›i GPU acceleration cho AI tasks vÃ  database performance á»•n Ä‘á»‹nh!**


---
TÃ´i sáº½ táº¡o má»™t há»‡ thá»‘ng file mÃ´i trÆ°á»ng hoÃ n chá»‰nh Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n giá»¯a 2 PC vÃ  táº¥t cáº£ modules:

## **ğŸ”§ Há»† THá»NG FILE MÃ”I TRÆ¯á»œNG THá»NG NHáº¤T**

### **ğŸ“ Cáº¥u trÃºc thÆ° má»¥c mÃ´i trÆ°á»ng:**

```
environment-config/
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ .env.shared           # Cáº¥u hÃ¬nh chung cho cáº£ 2 PC
â”‚   â”œâ”€â”€ .env.network          # Network vÃ  IP addresses
â”‚   â”œâ”€â”€ .env.secrets          # Passwords vÃ  secrets
â”‚   â””â”€â”€ .env.ports            # Port mapping
â”œâ”€â”€ pc1/
â”‚   â”œâ”€â”€ .env.pc1              # Cáº¥u hÃ¬nh riÃªng PC1
â”‚   â”œâ”€â”€ .env.database         # Database settings
â”‚   â”œâ”€â”€ .env.infrastructure   # Infrastructure services
â”‚   â””â”€â”€ .env.web              # Web services
â”œâ”€â”€ pc2/
â”‚   â”œâ”€â”€ .env.pc2              # Cáº¥u hÃ¬nh riÃªng PC2
â”‚   â”œâ”€â”€ .env.gpu              # GPU settings
â”‚   â”œâ”€â”€ .env.ai               # AI services
â”‚   â””â”€â”€ .env.rag              # RAG pipeline
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate-secrets.sh   # Script táº¡o random passwords
â”‚   â”œâ”€â”€ validate-config.sh    # Validate configuration
â”‚   â””â”€â”€ sync-env.sh          # Sync giá»¯a 2 PC
â””â”€â”€ docker-compose/
    â”œâ”€â”€ docker-compose.pc1.yml
    â”œâ”€â”€ docker-compose.pc2.yml
    â””â”€â”€ docker-compose.override.yml
```

### **ğŸ” File cáº¥u hÃ¬nh chi tiáº¿t:**

#### **1. shared/.env.shared - Cáº¥u hÃ¬nh chung**
```bash
# ===========================================
# SHARED CONFIGURATION FOR BOTH PC1 & PC2
# ===========================================

# Project Information
PROJECT_NAME=vietnamese-rag-chatbot
VERSION=1.0.0
ENVIRONMENT=development
DEBUG=true

# Timezone
TZ=Asia/Ho_Chi_Minh

# Language Settings
DEFAULT_LANGUAGE=vi
SUPPORTED_LANGUAGES=vi,en

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_RETENTION_DAYS=30

# Performance Settings
MAX_CONCURRENT_CONNECTIONS=100
REQUEST_TIMEOUT=300
HEALTH_CHECK_INTERVAL=30

# Vietnamese NLP Settings
VIETNAMESE_STOPWORDS_ENABLED=true
DIACRITICS_NORMALIZATION=true
WORD_SEGMENTATION=pyvi

# Embedding Configuration
EMBEDDING_MODEL=Qwen/Qwen3-Embedding-0.6B
EMBEDDING_DIMENSION=1024
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_CHUNK_LENGTH=1000

# Security
JWT_ALGORITHM=RS256
JWT_EXPIRE_HOURS=24
SESSION_TIMEOUT_MINUTES=60
RATE_LIMIT_PER_MINUTE=100

# Backup Settings
BACKUP_RETENTION_DAYS=30
BACKUP_SCHEDULE="0 2 * * *"
```

#### **2. shared/.env.network - Network Configuration**
```bash
# ===========================================
# NETWORK CONFIGURATION
# ===========================================

# PC IP Addresses (Update these for your network)
PC1_INTERNAL_IP=192.168.1.100
PC2_INTERNAL_IP=192.168.1.101

# PC1 External Access
PC1_EXTERNAL_IP=192.168.1.100
PC1_DOMAIN=rag-db.local

# PC2 External Access  
PC2_EXTERNAL_IP=192.168.1.101
PC2_DOMAIN=rag-ai.local

# Docker Networks
DOCKER_NETWORK_NAME=rag-network
DOCKER_SUBNET=172.20.0.0/16

# Cross-PC Communication
CROSS_PC_NETWORK_ENABLED=true
NETWORK_TIMEOUT=30
MAX_RETRIES=3

# DNS Settings (Optional)
USE_CUSTOM_DNS=false
DNS_SERVERS=8.8.8.8,8.8.4.4
```

#### **3. shared/.env.ports - Port Mapping**
```bash
# ===========================================
# UNIFIED PORT MAPPING - NO CONFLICTS
# ===========================================

# ===== PC1 PORTS (Infrastructure & Web) =====

# Infrastructure Services (5000-5999)
POSTGRES_PORT=5432
REDIS_PORT=6379
CHROMADB_PORT=8000

# Authentication & Security (6000-6099)
AUTH_SERVICE_PORT=6001
SESSION_SERVICE_PORT=6002

# Web Services (6100-6199)
WEB_INTERFACE_PORT=6100
ADMIN_PANEL_PORT=6101

# Platform Services (6200-6299)
ANALYTICS_API_PORT=6201
ADMIN_TOOLS_PORT=6202
MONITORING_PORT=6203

# Load Balancer & Gateway (80/443 + 6300-6399)
NGINX_HTTP_PORT=80
NGINX_HTTPS_PORT=443
API_GATEWAY_PORT=6300

# Monitoring Stack (6400-6499)
PROMETHEUS_PORT=6401
GRAFANA_PORT=6402
ALERTMANAGER_PORT=6403

# ===== PC2 PORTS (AI & RAG Processing) =====

# AI Core Services (7000-7099)
EMBEDDING_SERVICE_PORT=7001
LLM_SERVICE_PORT=7002
VIETNAMESE_NLP_PORT=7003

# Data Pipeline (7100-7199)
DATA_PREPARATION_PORT=7101
QUALITY_CONTROL_PORT=7102
DATA_INGESTION_PORT=7103

# RAG Pipeline (7200-7299)
RETRIEVAL_ROUTER_PORT=7201
SYNTHESIS_ENGINE_PORT=7202
GENERATION_ENGINE_PORT=7203
RAG_API_MAIN_PORT=7200

# Processing Services (7300-7399)
DOCUMENT_PROCESSOR_PORT=7301
CHUNK_PROCESSOR_PORT=7302
VECTOR_PROCESSOR_PORT=7303

# ===== EXTERNAL ACCESS PORTS =====
# Main entry points for users
MAIN_WEB_PORT=80
MAIN_API_PORT=8080
ADMIN_ACCESS_PORT=8081
MONITORING_ACCESS_PORT=8082

# ===== INTERNAL COMMUNICATION PORTS =====
PC1_TO_PC2_PORT=9001
PC2_TO_PC1_PORT=9002
HEALTH_CHECK_PORT=9999
```

#### **4. shared/.env.secrets - Security Configuration**
```bash
# ===========================================
# SECURITY SECRETS - GENERATE UNIQUE VALUES
# ===========================================

# Database Credentials
POSTGRES_ADMIN_USER=kb_admin
POSTGRES_ADMIN_PASSWORD=KbAdm1n_2024_SecureP@ss
POSTGRES_APP_USER=kb_app
POSTGRES_APP_PASSWORD=KbApp_2024_SecureP@ss
POSTGRES_READONLY_USER=kb_readonly
POSTGRES_READONLY_PASSWORD=KbRead_2024_SecureP@ss

# Redis Security
REDIS_PASSWORD=Redis_2024_SecureP@ss
REDIS_AUTH_TOKEN=redis_auth_token_2024_very_long_random_string

# ChromaDB Security
CHROMA_AUTH_TOKEN=chroma_auth_token_2024_very_long_random_string
CHROMA_SERVER_AUTH_CREDENTIALS=chroma_admin:ChromaAdm1n_2024

# JWT Secrets
JWT_SECRET_KEY=jwt_secret_key_2024_this_should_be_very_long_and_random_string_minimum_32_chars
JWT_REFRESH_SECRET=jwt_refresh_secret_2024_another_very_long_random_string_for_refresh_tokens

# API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Encryption Keys
ENCRYPTION_KEY=encryption_key_2024_for_sensitive_data_32_characters_minimum
HASH_SALT=hash_salt_2024_for_password_hashing_random_string

# Admin Credentials
ADMIN_USERNAME=system_admin
ADMIN_PASSWORD=Adm1n_2024_VerySecureP@ssw0rd
ADMIN_EMAIL=admin@company.com

# Monitoring Credentials
GRAFANA_ADMIN_PASSWORD=Grafana_2024_SecureP@ss
PROMETHEUS_PASSWORD=Prometheus_2024_SecureP@ss

# File Upload Security
UPLOAD_SECRET_KEY=upload_secret_2024_for_file_validation

# Cross-Service Communication
INTERNAL_API_KEY=internal_api_key_2024_for_service_to_service_communication
SERVICE_TO_SERVICE_TOKEN=service_token_2024_very_long_random_string
```

#### **5. pc1/.env.pc1 - PC1 Specific Configuration**
```bash
# ===========================================
# PC1 CONFIGURATION - DATABASE & WEB SERVER
# ===========================================

# Load shared configurations
include ../shared/.env.shared
include ../shared/.env.network  
include ../shared/.env.ports
include ../shared/.env.secrets

# PC1 Specific Settings
PC_ROLE=database_server
PC_HOSTNAME=rag-pc1-db
SERVER_NAME=RAG Database Server

# Hardware Optimization
CPU_CORES=8
MEMORY_LIMIT=32G
DISK_CACHE_SIZE=8G

# Database Configuration
POSTGRES_SHARED_BUFFERS=8GB
POSTGRES_EFFECTIVE_CACHE_SIZE=24GB
POSTGRES_WORK_MEM=256MB
POSTGRES_MAINTENANCE_WORK_MEM=2GB
POSTGRES_MAX_CONNECTIONS=200
POSTGRES_LOG_STATEMENT=all
POSTGRES_LOG_MIN_DURATION_STATEMENT=1000

# Redis Configuration
REDIS_MAXMEMORY=8gb
REDIS_MAXMEMORY_POLICY=allkeys-lru
REDIS_SAVE_INTERVAL="900 1 300 10 60 10000"
REDIS_APPENDONLY=yes

# ChromaDB Configuration
CHROMA_HOST=0.0.0.0
CHROMA_PORT=${CHROMADB_PORT}
CHROMA_PERSIST_DIRECTORY=/chroma/chroma
CHROMA_ANONYMIZED_TELEMETRY=false

# Web Server Configuration
NGINX_WORKER_PROCESSES=auto
NGINX_WORKER_CONNECTIONS=1024
NGINX_CLIENT_MAX_BODY_SIZE=100M
NGINX_PROXY_TIMEOUT=300s

# Backup Configuration
BACKUP_ENABLED=true
BACKUP_DIRECTORY=/backups
POSTGRES_BACKUP_RETENTION=7
REDIS_BACKUP_RETENTION=3

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=${PROMETHEUS_PORT}
HEALTH_CHECK_ENABLED=true
```

#### **6. pc2/.env.pc2 - PC2 Specific Configuration**
```bash
# ===========================================
# PC2 CONFIGURATION - GPU & AI PROCESSING
# ===========================================

# Load shared configurations
include ../shared/.env.shared
include ../shared/.env.network
include ../shared/.env.ports  
include ../shared/.env.secrets

# PC2 Specific Settings
PC_ROLE=ai_server
PC_HOSTNAME=rag-pc2-gpu
SERVER_NAME=RAG AI Processing Server

# Hardware Optimization
CPU_CORES=8
MEMORY_LIMIT=32G
GPU_ENABLED=true
GPU_MEMORY_LIMIT=16G

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility
GPU_MEMORY_FRACTION=0.8
MIXED_PRECISION=true

# AI Model Configuration
MODEL_CACHE_DIR=/models/.cache
MODEL_DOWNLOAD_TIMEOUT=1800
TRANSFORMERS_CACHE=/models/transformers
HF_HOME=/models/huggingface

# Embedding Service
EMBEDDING_BATCH_SIZE=32
EMBEDDING_MAX_LENGTH=512
EMBEDDING_POOLING=mean
EMBEDDING_NORMALIZE=true

# Vietnamese NLP
PYVI_ENABLED=true
UNDERTHESEA_ENABLED=true
NLP_BATCH_SIZE=16
NLP_MAX_WORKERS=4

# RAG Pipeline Configuration
RAG_RETRIEVAL_TOP_K=10
RAG_CONTEXT_LENGTH=4096
RAG_GENERATION_MAX_TOKENS=1024
RAG_TEMPERATURE=0.7

# Performance Settings
ASYNC_WORKERS=8
QUEUE_MAX_SIZE=1000
PROCESSING_TIMEOUT=300
RETRY_ATTEMPTS=3

# External API Configuration
PC1_DATABASE_URL=postgresql://${POSTGRES_APP_USER}:${POSTGRES_APP_PASSWORD}@${PC1_INTERNAL_IP}:${POSTGRES_PORT}/knowledge_base_unified
PC1_REDIS_URL=redis://:${REDIS_PASSWORD}@${PC1_INTERNAL_IP}:${REDIS_PORT}/0
PC1_CHROMADB_URL=http://${PC1_INTERNAL_IP}:${CHROMADB_PORT}
PC1_AUTH_URL=http://${PC1_INTERNAL_IP}:${AUTH_SERVICE_PORT}
```

### **ğŸ› ï¸ Scripts há»— trá»£:**

#### **7. scripts/generate-secrets.sh - Táº¡o passwords tá»± Ä‘á»™ng**
```bash
#!/bin/bash
# ===========================================
# SCRIPT Táº O PASSWORDS VÃ€ SECRETS Tá»° Äá»˜NG
# ===========================================

echo "Generating secure passwords and secrets..."

# Function to generate random password
generate_password() {
    local length=${1:-32}
    openssl rand -base64 $length | tr -d "=+/" | cut -c1-$length
}

# Function to generate API key
generate_api_key() {
    echo "$(date +%s)_$(openssl rand -hex 16)"
}

# Update .env.secrets with generated values
SECRETS_FILE="../shared/.env.secrets"

# Backup original file
cp $SECRETS_FILE "$SECRETS_FILE.backup.$(date +%Y%m%d_%H%M%S)"

# Generate new secrets
POSTGRES_ADMIN_PASSWORD=$(generate_password 24)
POSTGRES_APP_PASSWORD=$(generate_password 24)
POSTGRES_READONLY_PASSWORD=$(generate_password 24)
REDIS_PASSWORD=$(generate_password 24)
REDIS_AUTH_TOKEN=$(generate_password 48)
CHROMA_AUTH_TOKEN=$(generate_password 48)
JWT_SECRET_KEY=$(generate_password 64)
JWT_REFRESH_SECRET=$(generate_password 64)
ENCRYPTION_KEY=$(generate_password 32)
HASH_SALT=$(generate_password 32)
ADMIN_PASSWORD=$(generate_password 20)
GRAFANA_ADMIN_PASSWORD=$(generate_password 20)
PROMETHEUS_PASSWORD=$(generate_password 20)
UPLOAD_SECRET_KEY=$(generate_password 32)
INTERNAL_API_KEY=$(generate_api_key)
SERVICE_TO_SERVICE_TOKEN=$(generate_password 64)

# Update secrets file
cat > $SECRETS_FILE << EOF
# ===========================================
# AUTO-GENERATED SECURITY SECRETS
# Generated on: $(date)
# ===========================================

# Database Credentials
POSTGRES_ADMIN_USER=kb_admin
POSTGRES_ADMIN_PASSWORD=$POSTGRES_ADMIN_PASSWORD
POSTGRES_APP_USER=kb_app
POSTGRES_APP_PASSWORD=$POSTGRES_APP_PASSWORD
POSTGRES_READONLY_USER=kb_readonly
POSTGRES_READONLY_PASSWORD=$POSTGRES_READONLY_PASSWORD

# Redis Security
REDIS_PASSWORD=$REDIS_PASSWORD
REDIS_AUTH_TOKEN=$REDIS_AUTH_TOKEN

# ChromaDB Security
CHROMA_AUTH_TOKEN=$CHROMA_AUTH_TOKEN
CHROMA_SERVER_AUTH_CREDENTIALS=chroma_admin:$CHROMA_AUTH_TOKEN

# JWT Secrets
JWT_SECRET_KEY=$JWT_SECRET_KEY
JWT_REFRESH_SECRET=$JWT_REFRESH_SECRET

# API Keys (Update manually)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Encryption Keys
ENCRYPTION_KEY=$ENCRYPTION_KEY
HASH_SALT=$HASH_SALT

# Admin Credentials
ADMIN_USERNAME=system_admin
ADMIN_PASSWORD=$ADMIN_PASSWORD
ADMIN_EMAIL=admin@company.com

# Monitoring Credentials
GRAFANA_ADMIN_PASSWORD=$GRAFANA_ADMIN_PASSWORD
PROMETHEUS_PASSWORD=$PROMETHEUS_PASSWORD

# File Upload Security
UPLOAD_SECRET_KEY=$UPLOAD_SECRET_KEY

# Cross-Service Communication
INTERNAL_API_KEY=$INTERNAL_API_KEY
SERVICE_TO_SERVICE_TOKEN=$SERVICE_TO_SERVICE_TOKEN
EOF

echo "âœ… Secrets generated successfully!"
echo "ğŸ“ Backup saved as: $SECRETS_FILE.backup.$(date +%Y%m%d_%H%M%S)"
echo "âš ï¸  Remember to update API keys manually!"
```

#### **8. scripts/validate-config.sh - Kiá»ƒm tra cáº¥u hÃ¬nh**
```bash
#!/bin/bash
# ===========================================
# SCRIPT VALIDATE CONFIGURATION
# ===========================================

echo "ğŸ” Validating environment configuration..."

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Error counter
ERRORS=0

# Function to check port conflicts
check_port_conflicts() {
    echo "ğŸ“‹ Checking port conflicts..."
    
    # Load ports configuration
    source ../shared/.env.ports
    
    # Extract all ports
    PORTS=(
        $POSTGRES_PORT $REDIS_PORT $CHROMADB_PORT
        $AUTH_SERVICE_PORT $SESSION_SERVICE_PORT
        $WEB_INTERFACE_PORT $ADMIN_PANEL_PORT
        $ANALYTICS_API_PORT $ADMIN_TOOLS_PORT $MONITORING_PORT
        $NGINX_HTTP_PORT $NGINX_HTTPS_PORT $API_GATEWAY_PORT
        $PROMETHEUS_PORT $GRAFANA_PORT $ALERTMANAGER_PORT
        $EMBEDDING_SERVICE_PORT $LLM_SERVICE_PORT $VIETNAMESE_NLP_PORT
        $DATA_PREPARATION_PORT $QUALITY_CONTROL_PORT $DATA_INGESTION_PORT
        $RETRIEVAL_ROUTER_PORT $SYNTHESIS_ENGINE_PORT $GENERATION_ENGINE_PORT $RAG_API_MAIN_PORT
        $DOCUMENT_PROCESSOR_PORT $CHUNK_PROCESSOR_PORT $VECTOR_PROCESSOR_PORT
    )
    
    # Check for duplicates
    SORTED_PORTS=($(printf '%s\n' "${PORTS[@]}" | sort -n))
    UNIQUE_PORTS=($(printf '%s\n' "${PORTS[@]}" | sort -n | uniq))
    
    if [ ${#SORTED_PORTS[@]} -ne ${#UNIQUE_PORTS[@]} ]; then
        echo -e "${RED}âŒ Port conflicts detected!${NC}"
        # Find duplicates
        printf '%s\n' "${PORTS[@]}" | sort | uniq -d | while read port; do
            echo -e "${RED}   Duplicate port: $port${NC}"
        done
        ((ERRORS++))
    else
        echo -e "${GREEN}âœ… No port conflicts found${NC}"
    fi
}

# Function to check required variables
check_required_vars() {
    echo "ğŸ“‹ Checking required environment variables..."
    
    # List of critical variables
    REQUIRED_VARS=(
        "PC1_INTERNAL_IP"
        "PC2_INTERNAL_IP"
        "POSTGRES_ADMIN_PASSWORD"
        "REDIS_PASSWORD"
        "JWT_SECRET_KEY"
        "ADMIN_PASSWORD"
    )
    
    for var in "${REQUIRED_VARS[@]}"; do
        if [ -z "${!var}" ]; then
            echo -e "${RED}âŒ Missing required variable: $var${NC}"
            ((ERRORS++))
        else
            echo -e "${GREEN}âœ… $var is set${NC}"
        fi
    done
}

# Function to check password strength
check_password_strength() {
    echo "ğŸ“‹ Checking password strength..."
    
    # Load secrets
    source ../shared/.env.secrets
    
    # Check password length
    if [ ${#POSTGRES_ADMIN_PASSWORD} -lt 16 ]; then
        echo -e "${YELLOW}âš ï¸  POSTGRES_ADMIN_PASSWORD is shorter than 16 characters${NC}"
    fi
    
    if [ ${#JWT_SECRET_KEY} -lt 32 ]; then
        echo -e "${RED}âŒ JWT_SECRET_KEY must be at least 32 characters${NC}"
        ((ERRORS++))
    fi
}

# Function to check network connectivity
check_network() {
    echo "ğŸ“‹ Checking network configuration..."
    
    source ../shared/.env.network
    
    # Validate IP format
    if [[ ! $PC1_INTERNAL_IP =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        echo -e "${RED}âŒ Invalid PC1_INTERNAL_IP format: $PC1_INTERNAL_IP${NC}"
        ((ERRORS++))
    fi
    
    if [[ ! $PC2_INTERNAL_IP =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        echo -e "${RED}âŒ Invalid PC2_INTERNAL_IP format: $PC2_INTERNAL_IP${NC}"
        ((ERRORS++))
    fi
}

# Function to generate validation report
generate_report() {
    echo ""
    echo "ğŸ“Š Validation Report"
    echo "===================="
    
    if [ $ERRORS -eq 0 ]; then
        echo -e "${GREEN}âœ… All checks passed! Configuration is valid.${NC}"
        exit 0
    else
        echo -e "${RED}âŒ Found $ERRORS error(s). Please fix before deployment.${NC}"
        exit 1
    fi
}

# Main validation flow
main() {
    # Load all environment files
    source ../shared/.env.shared
    source ../shared/.env.network
    source ../shared/.env.ports
    source ../shared/.env.secrets
    
    check_port_conflicts
    check_required_vars
    check_password_strength
    check_network
    generate_report
}

main "$@"
```

#### **9. scripts/sync-env.sh - Äá»“ng bá»™ cáº¥u hÃ¬nh giá»¯a 2 PC**
```bash
#!/bin/bash
# ===========================================
# SCRIPT Äá»’NG Bá»˜ CONFIGURATION GIá»®A 2 PC
# ===========================================

PC1_USER="admin"
PC1_IP="192.168.1.100"
PC2_USER="admin"  
PC2_IP="192.168.1.101"

echo "ğŸ”„ Syncing environment configuration between PC1 and PC2..."

# Function to sync to PC1
sync_to_pc1() {
    echo "ğŸ“¤ Syncing to PC1 ($PC1_IP)..."
    
    # Create directory structure
    ssh $PC1_USER@$PC1_IP "mkdir -p ~/rag-deployment/environment-config/{shared,pc1,scripts}"
    
    # Copy shared configurations
    scp ../shared/* $PC1_USER@$PC1_IP:~/rag-deployment/environment-config/shared/
    
    # Copy PC1 specific configurations
    scp ../pc1/* $PC1_USER@$PC1_IP:~/rag-deployment/environment-config/pc1/
    
    # Copy scripts
    scp ../scripts/* $PC1_USER@$PC1_IP:~/rag-deployment/environment-config/scripts/
    
    # Set permissions
    ssh $PC1_USER@$PC1_IP "chmod +x ~/rag-deployment/environment-config/scripts/*.sh"
}

# Function to sync to PC2
sync_to_pc2() {
    echo "ğŸ“¤ Syncing to PC2 ($PC2_IP)..."
    
    # Create directory structure
    ssh $PC2_USER@$PC2_IP "mkdir -p ~/rag-deployment/environment-config/{shared,pc2,scripts}"
    
    # Copy shared configurations
    scp ../shared/* $PC2_USER@$PC2_IP:~/rag-deployment/environment-config/shared/
    
    # Copy PC2 specific configurations
    scp ../pc2/* $PC2_USER@$PC2_IP:~/rag-deployment/environment-config/pc2/
    
    # Copy scripts
    scp ../scripts/* $PC2_USER@$PC2_IP:~/rag-deployment/environment-config/scripts/
    
    # Set permissions
    ssh $PC2_USER@$PC2_IP "chmod +x ~/rag-deployment/environment-config/scripts/*.sh"
}

# Main sync function
main() {
    # Validate configuration first
    echo "ğŸ” Validating configuration before sync..."
    ./validate-config.sh
    
    if [ $? -eq 0 ]; then
        sync_to_pc1
        sync_to_pc2
        
        echo "âœ… Configuration synced successfully!"
        echo "ğŸ“ Next steps:"
        echo "   1. SSH to PC1: ssh $PC1_USER@$PC1_IP"
        echo "   2. SSH to PC2: ssh $PC2_USER@$PC2_IP"
        echo "   3. Run deployment on each PC"
    else
        echo "âŒ Configuration validation failed. Please fix errors first."
        exit 1
    fi
}

main "$@"
```

### **ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng:**

```bash
# 1. Táº¡o cáº¥u hÃ¬nh ban Ä‘áº§u
cd environment-config/scripts
chmod +x *.sh

# 2. Táº¡o passwords tá»± Ä‘á»™ng
./generate-secrets.sh

# 3. Cáº­p nháº­t IP addresses (sá»­a .env.network)
nano ../shared/.env.network

# 4. Validate cáº¥u hÃ¬nh
./validate-config.sh

# 5. Äá»“ng bá»™ lÃªn 2 PC
./sync-env.sh
```

**âœ… Advantages cá»§a há»‡ thá»‘ng nÃ y:**
- **No Conflicts**: Táº¥t cáº£ ports Ä‘Æ°á»£c quáº£n lÃ½ táº­p trung
- **Consistent**: CÃ¹ng má»™t secrets trÃªn cáº£ 2 PC
- **Secure**: Auto-generated strong passwords
- **Validated**: Scripts kiá»ƒm tra lá»—i tá»± Ä‘á»™ng
- **Maintainable**: Dá»… update vÃ  debug
- **Scalable**: CÃ³ thá»ƒ thÃªm PC3, PC4 dá»… dÃ ng

Há»‡ thá»‘ng nÃ y Ä‘áº£m báº£o 100% khÃ´ng cÃ³ port conflicts vÃ  password mismatches giá»¯a cÃ¡c modules!

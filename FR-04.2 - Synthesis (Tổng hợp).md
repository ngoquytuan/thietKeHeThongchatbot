Nếu đã đủ thông tin hãy giúp tôi viết tài liệu thiết kế module dưới đây.
Tài liệu này cung cấp roadmap đầy đủ để implement FR-04.2 mà không cần code cụ thể nhưng 
có các bước làm cụ thể như chuẩn bị môi trường PC thế nào, phần mềm gì?
 để Team kỹ thuật có thể follow step-by-step guide này để thiết kế tối ưu cho hệ thống chatbot
 và có mermaidchart luồng công việc, điểm quay đầu khi bị fail.

### 3.4 Module RAG Core Engine (FR-04)

**FR-04.2 - Synthesis (Tổng hợp)**
- Xây dựng context từ các documents truy xuất được
- Template hóa prompt cho LLM
- Xử lý trường hợp không tìm thấy thông tin phù hợp
---
# TÀI LIỆU THIẾT KẾ MODULE FR-04.2: SYNTHESIS (TỔNG HỢP)
## ROADMAP TRIỂN KHAI CHO TEAM KỸ THUẬT

---

**Module:** RAG Core Engine - Synthesis Component  
**Requirement ID:** FR-04.2  
**Version:** 1.0  
**Date:** 01/09/2025  
**Target Audience:** Development Team  

---

## 📋 **TỔNG QUAN MODULE**

### **Mục tiêu**
Module Synthesis chịu trách nhiệm xây dựng context thông minh từ các documents được retrieval, tạo prompt templates tối ưu cho LLM, và xử lý graceful các trường hợp không tìm thấy thông tin phù hợp.

### **Input/Output**
- **Input**: Retrieved documents + User query + User context
- **Output**: Structured prompt cho LLM + Fallback responses

### **Vị trí trong RAG Pipeline**
```
Query Processing → Document Retrieval → [SYNTHESIS] → LLM Generation → Response
```

---

## 🛠️ **CHUẨN BỊ MÔI TRƯỜNG PHÁT TRIỂN**

### **1. Yêu cầu Phần cứng**
```
CPU: Intel i7/AMD Ryzen 7 (8+ cores) hoặc cao hơn
RAM: 32GB+ (recommend 64GB cho testing với large datasets)
Storage: 1TB+ SSD (NVMe preferred)
GPU: Optional - NVIDIA RTX 4060+ nếu test local LLM
Network: Stable internet cho API calls
```

### **2. Hệ điều hành**
```
Primary: Ubuntu 22.04 LTS / Windows 11 Pro / macOS 13+
Container: Docker Desktop 4.20+
Virtualization: VirtualBox/VMware (nếu cần isolated environment)
```

### **3. Development Environment Setup**

#### **3.1 Core Development Tools**
```bash
# Python Environment
Python 3.11+ (recommend pyenv cho version management)
pip 23.0+
Poetry 1.5+ (dependency management)

# IDE Options (chọn 1)
- Visual Studio Code + Python extensions
- PyCharm Professional 2023.2+
- Cursor AI (recommend cho AI-assisted development)

# Version Control
Git 2.40+
GitHub CLI (optional nhưng recommend)
```

#### **3.2 Specialized AI/ML Tools**
```bash
# Essential Python Libraries
langchain>=0.1.0          # LLM orchestration
openai>=1.0.0             # OpenAI API
anthropic>=0.8.0          # Claude API
jinja2>=3.1.0             # Template engine
tiktoken>=0.5.0           # Token counting
pydantic>=2.0.0           # Data validation
pytest>=7.0.0             # Testing framework
black>=23.0.0             # Code formatting
mypy>=1.5.0               # Type checking

# Performance & Monitoring
prometheus-client>=0.17.0  # Metrics
structlog>=23.0.0         # Structured logging
tenacity>=8.2.0           # Retry mechanisms
```

#### **3.3 Development Infrastructure**
```bash
# Local Development Stack
Docker Desktop 4.20+
Docker Compose v2.20+
Redis 7.0+ (cho caching)
PostgreSQL 15+ (cho metadata)

# Testing & Quality
pytest-cov>=4.0.0        # Coverage testing
pre-commit>=3.3.0        # Git hooks
ruff>=0.0.280             # Fast linter
```

### **4. Project Structure Setup**

```bash
# Tạo project structure
mkdir rag_synthesis_module
cd rag_synthesis_module

# Initialize Python project
poetry init
poetry add langchain openai anthropic jinja2 tiktoken pydantic
poetry add --group dev pytest black mypy ruff pytest-cov

# Tạo cấu trúc thư mục
mkdir -p {
  src/synthesis/{core,templates,handlers,utils},
  tests/{unit,integration,e2e},
  config,
  docs,
  examples,
  scripts
}

# Initialize Git
git init
# Setup pre-commit hooks (sẽ detail ở bước sau)
```

---

## 🏗️ **KIẾN TRÚC MODULE SYNTHESIS**

### **5. Component Architecture**

```mermaid
graph TB
    subgraph "📥 INPUT PROCESSING"
        Input[🔍 Retrieved Documents<br/>+ User Query + Context]
        Validator[✅ Input Validator<br/>Validate & Sanitize]
        Scorer[📊 Relevance Scorer<br/>Score Documents]
    end
    
    subgraph "🧩 CONTEXT BUILDING"
        ContextBuilder[🏗️ Context Builder<br/>Smart Document Selection]
        
        subgraph "Context Strategies"
            TopK[📈 Top-K Strategy<br/>Best N documents]
            Diversity[🎯 Diversity Strategy<br/>Varied sources]
            Threshold[📏 Threshold Strategy<br/>Above confidence score]
        end
        
        ContextOptimizer[⚡ Context Optimizer<br/>Token limit management]
    end
    
    subgraph "📝 TEMPLATE PROCESSING"
        TemplateManager[📋 Template Manager<br/>Load & Manage Templates]
        
        subgraph "Template Types"
            SystemTemplate[🤖 System Templates<br/>Role definitions]
            QueryTemplate[❓ Query Templates<br/>Question formatting]
            ContextTemplate[📚 Context Templates<br/>Document formatting]
            FallbackTemplate[🚨 Fallback Templates<br/>No-result handling]
        end
        
        TemplateRenderer[🎨 Template Renderer<br/>Jinja2 Engine]
    end
    
    subgraph "🔧 PROMPT ASSEMBLY"
        PromptAssembler[🔧 Prompt Assembler<br/>Combine all parts]
        TokenCounter[🔢 Token Counter<br/>Validate length]
        QualityChecker[✅ Quality Checker<br/>Validate prompt quality]
    end
    
    subgraph "📤 OUTPUT GENERATION"
        OutputFormatter[📋 Output Formatter<br/>Structure final output]
        MetadataEnricher[🏷️ Metadata Enricher<br/>Add context info]
        FinalOutput[✨ Structured Prompt<br/>Ready for LLM]
    end
    
    subgraph "🚨 ERROR HANDLING"
        ErrorHandler[❌ Error Handler<br/>Handle failures]
        FallbackGenerator[🔄 Fallback Generator<br/>Default responses]
        LoggingService[📝 Logging Service<br/>Error tracking]
    end
    
    %% Main Flow
    Input --> Validator
    Validator --> Scorer
    Scorer --> ContextBuilder
    
    ContextBuilder --> TopK
    ContextBuilder --> Diversity  
    ContextBuilder --> Threshold
    
    TopK --> ContextOptimizer
    Diversity --> ContextOptimizer
    Threshold --> ContextOptimizer
    
    ContextOptimizer --> TemplateManager
    TemplateManager --> SystemTemplate
    TemplateManager --> QueryTemplate
    TemplateManager --> ContextTemplate
    TemplateManager --> FallbackTemplate
    
    SystemTemplate --> TemplateRenderer
    QueryTemplate --> TemplateRenderer
    ContextTemplate --> TemplateRenderer
    FallbackTemplate --> TemplateRenderer
    
    TemplateRenderer --> PromptAssembler
    PromptAssembler --> TokenCounter
    TokenCounter --> QualityChecker
    QualityChecker --> OutputFormatter
    OutputFormatter --> MetadataEnricher
    MetadataEnricher --> FinalOutput
    
    %% Error Flows (dotted red)
    Validator -.-> ErrorHandler
    ContextBuilder -.-> ErrorHandler  
    TemplateRenderer -.-> ErrorHandler
    TokenCounter -.-> ErrorHandler
    
    ErrorHandler --> FallbackGenerator
    ErrorHandler --> LoggingService
    FallbackGenerator --> FinalOutput
    
    %% Styling
    classDef input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef context fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef template fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef assembly fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef output fill:#e0f2f1,stroke:#00796b,stroke-width:2px
    classDef error fill:#ffebee,stroke:#c62828,stroke-width:2px
    
    class Input,Validator,Scorer input
    class ContextBuilder,TopK,Diversity,Threshold,ContextOptimizer context
    class TemplateManager,SystemTemplate,QueryTemplate,ContextTemplate,FallbackTemplate,TemplateRenderer template
    class PromptAssembler,TokenCounter,QualityChecker assembly
    class OutputFormatter,MetadataEnricher,FinalOutput output
    class ErrorHandler,FallbackGenerator,LoggingService error
```

---

## 📝 **STEP-BY-STEP IMPLEMENTATION ROADMAP**

### **Phase 1: Environment Setup & Foundation (Week 1)**

#### **Step 1.1: Initialize Development Environment**
```bash
# 1. Clone & setup project
git clone <repository>
cd rag_synthesis_module

# 2. Setup Python environment
pyenv install 3.11.5
pyenv local 3.11.5
poetry install

# 3. Setup pre-commit hooks
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: https://github.com/psf/black
    rev: 23.7.0
    hooks:
      - id: black
  - repo: https://github.com/charliermarsh/ruff-pre-commit
    rev: v0.0.280
    hooks:
      - id: ruff
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.5.1
    hooks:
      - id: mypy
EOF

pre-commit install

# 4. Setup testing infrastructure
poetry run pytest --version
poetry run black --version
poetry run mypy --version
```

#### **Step 1.2: Core Configuration Setup**
```bash
# Create config structure
mkdir -p config/{development,staging,production}

# Create base config template
cat > config/base_config.py << EOF
from pydantic_settings import BaseSettings
from typing import Dict, Any, List
import os

class SynthesisConfig(BaseSettings):
    # LLM Settings
    openai_api_key: str = ""
    anthropic_api_key: str = ""
    max_tokens: int = 4000
    temperature: float = 0.1
    
    # Context Settings
    max_context_documents: int = 10
    max_context_tokens: int = 8000
    similarity_threshold: float = 0.7
    diversity_threshold: float = 0.8
    
    # Template Settings
    template_directory: str = "templates"
    default_language: str = "vi"
    
    # Performance Settings
    cache_ttl: int = 3600
    request_timeout: int = 30
    max_retries: int = 3
    
    class Config:
        env_file = ".env"
        env_prefix = "SYNTHESIS_"
EOF
```

#### **Step 1.3: Setup Testing Framework**
```bash
# Create test configuration
cat > tests/conftest.py << EOF
import pytest
from unittest.mock import Mock
from src.synthesis.config import SynthesisConfig

@pytest.fixture
def mock_config():
    return SynthesisConfig(
        openai_api_key="test-key",
        max_tokens=1000,
        max_context_documents=5
    )

@pytest.fixture  
def mock_documents():
    return [
        {
            "content": "Document 1 content about AI",
            "metadata": {"source": "doc1.pdf", "score": 0.9},
            "chunk_id": "chunk_1"
        },
        {
            "content": "Document 2 content about machine learning", 
            "metadata": {"source": "doc2.pdf", "score": 0.8},
            "chunk_id": "chunk_2"
        }
    ]

@pytest.fixture
def mock_user_query():
    return {
        "query": "What is artificial intelligence?",
        "user_id": "test_user",
        "department": "engineering",
        "language": "vi"
    }
EOF
```

### **Phase 2: Core Components Implementation (Week 2)**

#### **Step 2.1: Input Validation & Processing**

**🎯 Checklist:**
- [ ] Create input data models với Pydantic
- [ ] Implement input sanitization
- [ ] Add relevance scoring logic
- [ ] Write unit tests cho validation

```python
# File: src/synthesis/core/input_processor.py
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Any, Optional
import re
import logging

class DocumentInput(BaseModel):
    content: str = Field(..., min_length=10)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    chunk_id: str = Field(..., min_length=1)
    relevance_score: Optional[float] = Field(default=0.0, ge=0.0, le=1.0)
    
    @validator('content')
    def sanitize_content(cls, v):
        # Remove excessive whitespace, normalize text
        return re.sub(r'\s+', ' ', v.strip())

class QueryInput(BaseModel):
    query: str = Field(..., min_length=3, max_length=1000)
    user_id: str = Field(..., min_length=1)
    department: Optional[str] = None
    language: str = Field(default="vi")
    context: Dict[str, Any] = Field(default_factory=dict)

class SynthesisInput(BaseModel):
    documents: List[DocumentInput] = Field(..., min_items=0)
    query: QueryInput
    synthesis_config: Dict[str, Any] = Field(default_factory=dict)

# Implementation tasks:
# 1. Implement InputValidator class
# 2. Add document scoring logic  
# 3. Create input preprocessing pipeline
# 4. Add comprehensive error handling
```

**💡 Implementation Hints:**
```bash
# Test validation
poetry run pytest tests/unit/test_input_processor.py -v

# Check type hints
poetry run mypy src/synthesis/core/input_processor.py

# Format code
poetry run black src/synthesis/core/input_processor.py
```

#### **Step 2.2: Context Building Strategies**

**🎯 Checklist:**
- [ ] Implement TopK selection strategy
- [ ] Implement Diversity-based selection  
- [ ] Implement Threshold-based filtering
- [ ] Add token counting and optimization
- [ ] Create context optimization algorithms

```python
# File: src/synthesis/core/context_builder.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any
import tiktoken
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class ContextSelectionStrategy(ABC):
    @abstractmethod
    def select_documents(
        self, 
        documents: List[DocumentInput], 
        query: QueryInput,
        max_tokens: int
    ) -> List[DocumentInput]:
        pass

class TopKStrategy(ContextSelectionStrategy):
    def __init__(self, k: int = 5):
        self.k = k
    
    def select_documents(self, documents, query, max_tokens):
        # Implementation: Sort by relevance_score, take top K
        # Consider token limits
        pass

class DiversityStrategy(ContextSelectionStrategy):  
    def __init__(self, diversity_threshold: float = 0.8):
        self.diversity_threshold = diversity_threshold
    
    def select_documents(self, documents, query, max_tokens):
        # Implementation: Select diverse documents using embedding similarity
        # Avoid redundant information
        pass

# Implementation tasks:
# 1. Complete each strategy implementation
# 2. Add token counting với tiktoken
# 3. Implement context optimization
# 4. Add performance metrics collection
```

#### **Step 2.3: Template Management System**

**🎯 Checklist:**
- [ ] Setup Jinja2 template engine
- [ ] Create template categories (System, Query, Context, Fallback)
- [ ] Implement template loading and caching
- [ ] Add template validation
- [ ] Create multilingual support

```bash
# Create template directory structure
mkdir -p templates/{system,query,context,fallback}/{vi,en}

# Create base system template
cat > templates/system/vi/default.j2 << EOF
Bạn là một trợ lý AI thông minh chuyên tư vấn về tài liệu nội bộ công ty.

NGUYÊN TẮC HOẠT ĐỘNG:
1. Chỉ trả lời dựa trên thông tin được cung cấp trong CONTEXT bên dưới
2. Nếu không tìm thấy thông tin liên quan, hãy thành thật nói "Tôi không tìm thấy thông tin về vấn đề này trong tài liệu hiện có"
3. Luôn trích dẫn nguồn tài liệu khi đưa ra thông tin
4. Trả lời bằng tiếng Việt, rõ ràng và dễ hiểu
5. Nếu thông tin không chắc chắn, hãy nói rõ mức độ tin cậy

THÔNG TIN NGƯỜI DÙNG:
- Phòng ban: {{ user_department }}
- Cấp độ truy cập: {{ user_access_level }}
EOF
```

### **Phase 3: Template Processing & Prompt Assembly (Week 3)**

#### **Step 3.1: Template Engine Implementation**

**🎯 Checklist:**
- [ ] Setup Jinja2 với custom filters và functions
- [ ] Implement template inheritance
- [ ] Add template caching mechanism  
- [ ] Create template validation system
- [ ] Implement dynamic template selection

```python
# File: src/synthesis/templates/template_manager.py
from jinja2 import Environment, FileSystemLoader, select_autoescape
from typing import Dict, Any, Optional
import os
from functools import lru_cache

class TemplateManager:
    def __init__(self, template_dir: str = "templates"):
        self.env = Environment(
            loader=FileSystemLoader(template_dir),
            autoescape=select_autoescape(['html', 'xml']),
            trim_blocks=True,
            lstrip_blocks=True
        )
        
        # Add custom filters
        self.env.filters['truncate_tokens'] = self._truncate_by_tokens
        self.env.filters['format_citations'] = self._format_citations
        
    @lru_cache(maxsize=128)
    def load_template(self, template_type: str, language: str = "vi") -> str:
        # Implementation: Load and cache templates
        pass
    
    def render_template(
        self, 
        template_name: str, 
        context: Dict[str, Any],
        language: str = "vi"
    ) -> str:
        # Implementation: Render template with context
        pass

# Implementation tasks:
# 1. Complete template loading logic
# 2. Add custom Jinja2 filters for AI-specific formatting
# 3. Implement template validation
# 4. Add error handling for missing templates
```

#### **Step 3.2: Prompt Assembly Engine**

**🎯 Checklist:**
- [ ] Create prompt assembly pipeline
- [ ] Implement token counting and limit management
- [ ] Add prompt quality validation
- [ ] Create prompt optimization algorithms
- [ ] Add structured output formatting

```python
# File: src/synthesis/core/prompt_assembler.py
from typing import List, Dict, Any, Optional
import tiktoken
from dataclasses import dataclass

@dataclass
class AssembledPrompt:
    system_prompt: str
    user_prompt: str
    total_tokens: int
    context_documents: List[Dict[str, Any]]
    metadata: Dict[str, Any]

class PromptAssembler:
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.tokenizer = tiktoken.encoding_for_model(model_name)
        self.max_tokens = 4000  # Configurable
        
    def assemble_prompt(
        self,
        query: QueryInput,
        context_documents: List[DocumentInput],
        templates: Dict[str, str]
    ) -> AssembledPrompt:
        # Implementation: Assemble all components into final prompt
        pass
    
    def optimize_prompt_length(self, prompt: str, max_tokens: int) -> str:
        # Implementation: Truncate intelligently while preserving meaning
        pass

# Implementation tasks:
# 1. Complete prompt assembly logic
# 2. Add intelligent truncation algorithms  
# 3. Implement prompt quality scoring
# 4. Add metadata enrichment
```

### **Phase 4: Error Handling & Fallback Mechanisms (Week 4)**

#### **Step 4.1: Comprehensive Error Handling**

**🎯 Checklist:**
- [ ] Create error taxonomy và handling strategies
- [ ] Implement graceful degradation
- [ ] Add retry mechanisms với backoff
- [ ] Create error logging và monitoring
- [ ] Implement health checks

```python
# File: src/synthesis/core/error_handler.py
from enum import Enum
from typing import Optional, Dict, Any
import structlog
from tenacity import retry, stop_after_attempt, wait_exponential

class SynthesisError(Exception):
    """Base exception for synthesis module"""
    pass

class ErrorType(Enum):
    INVALID_INPUT = "invalid_input"
    NO_RELEVANT_DOCUMENTS = "no_relevant_documents"  
    TEMPLATE_ERROR = "template_error"
    TOKEN_LIMIT_EXCEEDED = "token_limit_exceeded"
    LLM_API_ERROR = "llm_api_error"

class ErrorHandler:
    def __init__(self):
        self.logger = structlog.get_logger()
        
    def handle_error(
        self, 
        error_type: ErrorType, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        # Implementation: Route to appropriate error handling strategy
        pass
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10)
    )
    def retry_with_fallback(self, operation, fallback):
        # Implementation: Retry logic with fallback
        pass

# Implementation tasks:
# 1. Complete error handling strategies
# 2. Add comprehensive logging
# 3. Implement circuit breaker pattern
# 4. Add error metrics collection
```

#### **Step 4.2: Fallback Response Generation**

**🎯 Checklist:**
- [ ] Create fallback response templates
- [ ] Implement intelligent fallback selection
- [ ] Add contextual fallback messages
- [ ] Create escalation mechanisms
- [ ] Add user guidance features

```python
# File: src/synthesis/core/fallback_generator.py
from typing import Dict, Any, List
from enum import Enum

class FallbackType(Enum):
    NO_DOCUMENTS_FOUND = "no_documents"
    INSUFFICIENT_PERMISSION = "insufficient_permission"
    QUERY_TOO_VAGUE = "query_too_vague"
    TECHNICAL_ERROR = "technical_error"

class FallbackGenerator:
    def __init__(self, template_manager):
        self.template_manager = template_manager
        
    def generate_fallback_response(
        self,
        fallback_type: FallbackType,
        query: QueryInput,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        # Implementation: Generate appropriate fallback response
        pass
    
    def suggest_alternatives(self, query: str) -> List[str]:
        # Implementation: Suggest alternative queries or actions
        pass

# Implementation tasks:  
# 1. Create fallback response templates
# 2. Implement smart suggestion algorithms
# 3. Add user guidance mechanisms
# 4. Create escalation workflows
```

---

## 🔄 **WORKFLOW VÀ FAILURE HANDLING**

### **Main Workflow Diagram**

```mermaid
flowchart TD
    Start([🚀 Start Synthesis Process]) --> ValidateInput{✅ Validate Input?}
    
    ValidateInput -->|❌ Invalid| HandleInputError[🚨 Handle Input Error]
    ValidateInput -->|✅ Valid| ScoreDocuments[📊 Score Documents]
    
    HandleInputError --> ReturnError1[❌ Return Error Response]
    
    ScoreDocuments --> HasDocuments{📚 Has Relevant Documents?}
    
    HasDocuments -->|❌ No| GenerateNoResultsFallback[🔄 Generate No Results Fallback]
    HasDocuments -->|✅ Yes| SelectStrategy{🎯 Select Context Strategy}
    
    GenerateNoResultsFallback --> ReturnFallback1[🔄 Return Fallback Response]
    
    SelectStrategy --> TopKStrategy[📈 Top-K Strategy]
    SelectStrategy --> DiversityStrategy[🎯 Diversity Strategy] 
    SelectStrategy --> ThresholdStrategy[📏 Threshold Strategy]
    
    TopKStrategy --> OptimizeContext[⚡ Optimize Context]
    DiversityStrategy --> OptimizeContext
    ThresholdStrategy --> OptimizeContext
    
    OptimizeContext --> TokenCheck{🔢 Within Token Limit?}
    
    TokenCheck -->|❌ Exceed| TruncateContext[✂️ Truncate Context]
    TokenCheck -->|✅ OK| LoadTemplates[📋 Load Templates]
    
    TruncateContext --> LoadTemplates
    
    LoadTemplates --> TemplateExists{📝 Template Exists?}
    
    TemplateExists -->|❌ No| HandleTemplateError[🚨 Handle Template Error]
    TemplateExists -->|✅ Yes| RenderTemplate[🎨 Render Template]
    
    HandleTemplateError --> UseDefaultTemplate[📋 Use Default Template]
    UseDefaultTemplate --> RenderTemplate
    
    RenderTemplate --> RenderSuccess{✅ Render Success?}
    
    RenderSuccess -->|❌ Fail| HandleRenderError[🚨 Handle Render Error]
    RenderSuccess -->|✅ Success| AssemblePrompt[🔧 Assemble Final Prompt]
    
    HandleRenderError --> GenerateBasicFallback[🔄 Generate Basic Fallback]
    GenerateBasicFallback --> ReturnFallback2[🔄 Return Fallback Response]
    
    AssemblePrompt --> ValidatePrompt{✅ Validate Final Prompt?}
    
    ValidatePrompt -->|❌ Invalid| HandlePromptError[🚨 Handle Prompt Error]
    ValidatePrompt -->|✅ Valid| EnrichMetadata[🏷️ Enrich Metadata]
    
    HandlePromptError --> RetryAttempt{🔄 Retry Available?}
    
    RetryAttempt -->|✅ Yes| RetryCount[📊 Increment Retry Counter]
    RetryAttempt -->|❌ No| GenerateFinalFallback[🔄 Generate Final Fallback]
    
    RetryCount --> SelectStrategy
    GenerateFinalFallback --> ReturnFallback3[🔄 Return Fallback Response]
    
    EnrichMetadata --> LogSuccess[📝 Log Success Metrics]
    LogSuccess --> ReturnSuccess[✅ Return Synthesized Prompt]
    
    %% Error Return Points
    ReturnError1 --> End([🏁 End Process])
    ReturnFallback1 --> End
    ReturnFallback2 --> End  
    ReturnFallback3 --> End
    ReturnSuccess --> End
    
    %% Styling
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    classDef process fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef error fill:#ffebee,stroke:#c62828,stroke-width:2px
    classDef fallback fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef success fill:#e0f2f1,stroke:#00796b,stroke-width:2px
    
    class Start,End startEnd
    class ScoreDocuments,OptimizeContext,TruncateContext,LoadTemplates,RenderTemplate,AssemblePrompt,EnrichMetadata,LogSuccess,RetryCount process
    class ValidateInput,HasDocuments,SelectStrategy,TokenCheck,TemplateExists,RenderSuccess,ValidatePrompt,RetryAttempt decision
    class HandleInputError,HandleTemplateError,HandleRenderError,HandlePromptError error
    class GenerateNoResultsFallback,GenerateBasicFallback,GenerateFinalFallback,UseDefaultTemplate,ReturnFallback1,ReturnFallback2,ReturnFallback3 fallback
    class ReturnSuccess success
```

### **Failure Recovery Points**

```mermaid
graph TB
    subgraph "🔄 RECOVERY STRATEGIES"
        subgraph "Level 1: Input Failures"
            InputFail[❌ Input Validation Failed]
            InputRecover[🔧 Sanitize & Retry]
            InputFallback[📋 Request Clarification]
        end
        
        subgraph "Level 2: Context Failures" 
            ContextFail[❌ Context Building Failed]
            ContextRecover[🔧 Reduce Context Size]
            ContextFallback[📚 Use Cached Context]
        end
        
        subgraph "Level 3: Template Failures"
            TemplateFail[❌ Template Loading Failed]
            TemplateRecover[🔧 Load Default Template]  
            TemplateFallback[📝 Use Minimal Template]
        end
        
        subgraph "Level 4: System Failures"
            SystemFail[❌ System Error]
            SystemRecover[🔧 Circuit Breaker]
            SystemFallback[🚨 Emergency Response]
        end
    end
    
    subgraph "📊 MONITORING & ALERTS"
        MetricsCollector[📈 Metrics Collector]
        AlertManager[🚨 Alert Manager]
        HealthChecker[❤️ Health Checker]
    end
    
    %% Recovery Flows
    InputFail --> InputRecover
    InputRecover -->|Success| Normal[✅ Continue Normal Flow]
    InputRecover -->|Fail| InputFallback
    
    ContextFail --> ContextRecover
    ContextRecover -->|Success| Normal
    ContextRecover -->|Fail| ContextFallback
    
    TemplateFail --> TemplateRecover
    TemplateRecover -->|Success| Normal  
    TemplateRecover -->|Fail| TemplateFallback
    
    SystemFail --> SystemRecover
    SystemRecover -->|Success| Normal
    SystemRecover -->|Fail| SystemFallback
    
    %% Monitoring Connections
    InputFail -.-> MetricsCollector
    ContextFail -.-> MetricsCollector
    TemplateFail -.-> MetricsCollector
    SystemFail -.-> AlertManager
    
    MetricsCollector --> HealthChecker
    AlertManager --> HealthChecker
```
---
---

## 🧪 **TESTING STRATEGY & IMPLEMENTATION**

### **Phase 5: Comprehensive Testing (Week 5)**

#### **Step 5.1: Unit Testing Implementation**

**🎯 Checklist:**
- [ ] Test all core components independently
- [ ] Mock external dependencies (LLM APIs, databases)
- [ ] Achieve 90%+ code coverage
- [ ] Test error conditions và edge cases
- [ ] Performance benchmarking

```python
# File: tests/unit/test_context_builder.py
import pytest
from unittest.mock import Mock, patch
from src.synthesis.core.context_builder import TopKStrategy, DiversityStrategy
from src.synthesis.models import DocumentInput, QueryInput

class TestTopKStrategy:
    def test_select_top_k_documents(self, mock_documents, mock_config):
        """Test selecting top K documents by relevance score"""
        strategy = TopKStrategy(k=3)
        
        # Sort mock documents by score
        sorted_docs = sorted(mock_documents, key=lambda x: x.relevance_score, reverse=True)
        
        selected = strategy.select_documents(
            documents=mock_documents,
            query=QueryInput(query="test query", user_id="test"),
            max_tokens=1000
        )
        
        assert len(selected) == 3
        assert selected[0].relevance_score >= selected[1].relevance_score
        
    def test_token_limit_respected(self, mock_documents):
        """Test that token limits are respected"""
        strategy = TopKStrategy(k=10)  # Request more than available
        
        selected = strategy.select_documents(
            documents=mock_documents,
            query=QueryInput(query="test", user_id="test"), 
            max_tokens=500  # Restrictive limit
        )
        
        total_tokens = sum(len(doc.content.split()) for doc in selected)
        assert total_tokens <= 500
        
    @pytest.mark.parametrize("k,expected_count", [
        (1, 1),
        (5, 5),
        (100, 10)  # More than available documents
    ])
    def test_various_k_values(self, mock_documents, k, expected_count):
        """Test strategy với different K values"""
        strategy = TopKStrategy(k=k)
        selected = strategy.select_documents(mock_documents, Mock(), 10000)
        assert len(selected) <= min(k, len(mock_documents))

# File: tests/unit/test_template_manager.py  
class TestTemplateManager:
    def test_template_loading(self, tmp_path):
        """Test template loading từ filesystem"""
        # Create temporary template
        template_dir = tmp_path / "templates"
        template_dir.mkdir()
        (template_dir / "test.j2").write_text("Hello {{ name }}!")
        
        manager = TemplateManager(str(template_dir))
        template = manager.load_template("test")
        
        assert template == "Hello {{ name }}!"
        
    def test_template_rendering(self, tmp_path):
        """Test template rendering với context"""
        template_dir = tmp_path / "templates"  
        template_dir.mkdir()
        (template_dir / "context.j2").write_text("""
        Query: {{ query }}
        Documents:
        {% for doc in documents %}
        - {{ doc.content }}
        {% endfor %}
        """)
        
        manager = TemplateManager(str(template_dir))
        rendered = manager.render_template("context", {
            "query": "What is AI?",
            "documents": [{"content": "AI is intelligence"}]
        })
        
        assert "What is AI?" in rendered
        assert "AI is intelligence" in rendered
        
    def test_missing_template_handling(self):
        """Test handling của missing templates"""
        manager = TemplateManager("/nonexistent/path")
        
        with pytest.raises(TemplateNotFoundError):
            manager.load_template("nonexistent")
```

#### **Step 5.2: Integration Testing**

**🎯 Checklist:**
- [ ] Test end-to-end synthesis pipeline
- [ ] Test integration với external services
- [ ] Test database interactions
- [ ] Validate performance under load
- [ ] Test fallback mechanisms

```python
# File: tests/integration/test_synthesis_pipeline.py
import pytest
from unittest.mock import AsyncMock, patch
from src.synthesis.core.synthesis_engine import SynthesisEngine
from src.synthesis.models import SynthesisInput, QueryInput, DocumentInput

class TestSynthesisPipeline:
    @pytest.fixture
    def synthesis_engine(self, mock_config):
        """Create synthesis engine với mocked dependencies"""
        return SynthesisEngine(config=mock_config)
        
    async def test_full_synthesis_pipeline(self, synthesis_engine):
        """Test complete synthesis từ input đến output"""
        # Prepare input
        synthesis_input = SynthesisInput(
            documents=[
                DocumentInput(
                    content="Python is a programming language",
                    metadata={"source": "python_guide.pdf"},
                    chunk_id="chunk_1",
                    relevance_score=0.95
                )
            ],
            query=QueryInput(
                query="What is Python?",
                user_id="test_user",
                department="engineering"
            )
        )
        
        # Mock external LLM API
        with patch('openai.ChatCompletion.create') as mock_llm:
            mock_llm.return_value = AsyncMock()
            
            result = await synthesis_engine.synthesize(synthesis_input)
            
            assert result.system_prompt is not None
            assert result.user_prompt is not None
            assert "Python" in result.user_prompt
            assert len(result.context_documents) > 0
            
    async def test_no_documents_fallback(self, synthesis_engine):
        """Test fallback khi không có documents"""
        synthesis_input = SynthesisInput(
            documents=[],  # No documents
            query=QueryInput(query="What is AI?", user_id="test")
        )
        
        result = await synthesis_engine.synthesize(synthesis_input)
        
        assert result.is_fallback is True
        assert "không tìm thấy thông tin" in result.user_prompt.lower()
        
    async def test_token_limit_optimization(self, synthesis_engine):
        """Test token limit optimization"""
        # Create documents that exceed token limit
        large_documents = [
            DocumentInput(
                content="Very long content " * 1000,  # Exceed token limit
                metadata={},
                chunk_id=f"chunk_{i}",
                relevance_score=0.8
            ) for i in range(10)
        ]
        
        synthesis_input = SynthesisInput(
            documents=large_documents,
            query=QueryInput(query="Test query", user_id="test")
        )
        
        result = await synthesis_engine.synthesize(synthesis_input)
        
        # Should be within token limits
        assert result.total_tokens <= synthesis_engine.config.max_tokens
        assert len(result.context_documents) < len(large_documents)  # Some truncated
```

#### **Step 5.3: Performance Testing**

```python
# File: tests/performance/test_synthesis_performance.py
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor

class TestSynthesisPerformance:
    @pytest.mark.performance
    async def test_synthesis_latency(self, synthesis_engine, mock_documents):
        """Test synthesis latency requirements"""
        synthesis_input = SynthesisInput(
            documents=mock_documents,
            query=QueryInput(query="Performance test", user_id="test")
        )
        
        start_time = time.time()
        result = await synthesis_engine.synthesize(synthesis_input)
        end_time = time.time()
        
        latency = end_time - start_time
        assert latency < 2.0  # Should complete within 2 seconds
        assert result.total_tokens > 0
        
    @pytest.mark.performance  
    async def test_concurrent_synthesis(self, synthesis_engine):
        """Test concurrent synthesis requests"""
        async def single_synthesis():
            synthesis_input = SynthesisInput(
                documents=mock_documents[:5],
                query=QueryInput(query=f"Test query {time.time()}", user_id="test")
            )
            return await synthesis_engine.synthesize(synthesis_input)
            
        # Run 10 concurrent requests
        tasks = [single_synthesis() for _ in range(10)]
        start_time = time.time()
        results = await asyncio.gather(*tasks)
        total_time = time.time() - start_time
        
        assert len(results) == 10
        assert all(r.total_tokens > 0 for r in results)
        assert total_time < 10.0  # All requests within 10 seconds
        
    def test_memory_usage(self, synthesis_engine):
        """Test memory usage under load"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # Process many documents
        for i in range(100):
            large_input = SynthesisInput(
                documents=[DocumentInput(
                    content=f"Large content block {j}" * 100,
                    metadata={},
                    chunk_id=f"chunk_{i}_{j}",
                    relevance_score=0.5
                ) for j in range(50)],
                query=QueryInput(query=f"Query {i}", user_id="test")
            )
            
            # Force synchronous processing for memory test
            asyncio.run(synthesis_engine.synthesize(large_input))
            
        final_memory = process.memory_info().rss
        memory_growth = (final_memory - initial_memory) / (1024 * 1024)  # MB
        
        assert memory_growth < 500  # Less than 500MB growth
```

---

## 📊 **MONITORING & OBSERVABILITY**

### **Step 6: Production Monitoring Setup**

#### **Step 6.1: Metrics Collection**

```python
# File: src/synthesis/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, CollectorRegistry
from typing import Dict, Any
import time
import functools

class SynthesisMetrics:
    def __init__(self, registry: CollectorRegistry = None):
        self.registry = registry or CollectorRegistry()
        
        # Counter metrics
        self.synthesis_requests_total = Counter(
            'synthesis_requests_total',
            'Total number of synthesis requests',
            ['status', 'user_department', 'fallback_type'],
            registry=self.registry
        )
        
        # Histogram metrics  
        self.synthesis_duration = Histogram(
            'synthesis_duration_seconds',
            'Time spent on synthesis processing',
            ['stage'],
            registry=self.registry
        )
        
        self.context_documents_count = Histogram(
            'synthesis_context_documents_count',
            'Number of documents in context',
            registry=self.registry
        )
        
        self.prompt_tokens = Histogram(
            'synthesis_prompt_tokens',
            'Number of tokens in generated prompt',
            registry=self.registry
        )
        
        # Gauge metrics
        self.active_synthesis_requests = Gauge(
            'synthesis_active_requests',
            'Number of active synthesis requests',
            registry=self.registry
        )
        
    def record_request(self, status: str, department: str = "", fallback_type: str = ""):
        """Record synthesis request"""
        self.synthesis_requests_total.labels(
            status=status,
            user_department=department, 
            fallback_type=fallback_type
        ).inc()
        
    def record_duration(self, stage: str, duration: float):
        """Record processing duration"""
        self.synthesis_duration.labels(stage=stage).observe(duration)
        
    def record_context_size(self, document_count: int):
        """Record context size"""
        self.context_documents_count.observe(document_count)
        
    def record_prompt_tokens(self, token_count: int):
        """Record prompt token count"""  
        self.prompt_tokens.observe(token_count)

# Decorator for automatic metrics collection
def track_synthesis_metrics(metrics: SynthesisMetrics):
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            metrics.active_synthesis_requests.inc()
            
            try:
                result = await func(*args, **kwargs)
                duration = time.time() - start_time
                
                metrics.record_duration("total", duration)
                metrics.record_request("success")
                
                if hasattr(result, 'context_documents'):
                    metrics.record_context_size(len(result.context_documents))
                if hasattr(result, 'total_tokens'):
                    metrics.record_prompt_tokens(result.total_tokens)
                    
                return result
                
            except Exception as e:
                duration = time.time() - start_time
                metrics.record_duration("error", duration)
                metrics.record_request("error")
                raise
                
            finally:
                metrics.active_synthesis_requests.dec()
                
        return wrapper
    return decorator
```

#### **Step 6.2: Structured Logging**

```python
# File: src/synthesis/monitoring/logging.py
import structlog
import logging.config
from typing import Dict, Any, Optional
import json
from datetime import datetime

def configure_logging(log_level: str = "INFO", log_format: str = "json"):
    """Configure structured logging for synthesis module"""
    
    logging.config.dictConfig({
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "json": {
                "()": structlog.stdlib.ProcessorFormatter,
                "processor": structlog.dev.ConsoleRenderer(colors=False),
                "foreign_pre_chain": [
                    structlog.stdlib.add_log_level,
                    structlog.stdlib.add_logger_name,
                    structlog.stdlib.ExtraAdder(),
                    structlog.processors.TimeStamper(fmt="ISO"),
                ],
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json",
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "filename": "logs/synthesis.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
                "formatter": "json",
            },
        },
        "loggers": {
            "synthesis": {
                "handlers": ["console", "file"],
                "level": log_level,
                "propagate": False,
            },
        },
    })
    
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.stdlib.ProcessorFormatter.wrap_for_formatter,
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )

class SynthesisLogger:
    def __init__(self, component_name: str):
        self.logger = structlog.get_logger("synthesis").bind(component=component_name)
        
    def log_synthesis_start(self, query: str, user_id: str, document_count: int):
        """Log synthesis process start"""
        self.logger.info(
            "synthesis_started",
            query_length=len(query),
            user_id=user_id,
            document_count=document_count,
            timestamp=datetime.utcnow().isoformat()
        )
        
    def log_context_building(self, strategy: str, selected_docs: int, total_tokens: int):
        """Log context building details"""
        self.logger.info(
            "context_built",
            strategy=strategy,
            selected_documents=selected_docs,
            total_tokens=total_tokens
        )
        
    def log_template_processing(self, template_type: str, render_time: float):
        """Log template processing"""
        self.logger.info(
            "template_processed", 
            template_type=template_type,
            render_time_ms=render_time * 1000
        )
        
    def log_synthesis_complete(self, total_time: float, final_tokens: int, is_fallback: bool):
        """Log successful synthesis completion"""
        self.logger.info(
            "synthesis_completed",
            total_time_ms=total_time * 1000,
            final_tokens=final_tokens,
            is_fallback=is_fallback
        )
        
    def log_error(self, error_type: str, error_msg: str, context: Dict[str, Any] = None):
        """Log errors với context"""
        self.logger.error(
            "synthesis_error",
            error_type=error_type,
            error_message=error_msg,
            context=context or {}
        )
        
    def log_fallback_triggered(self, fallback_type: str, reason: str):
        """Log fallback mechanism activation"""
        self.logger.warning(
            "fallback_triggered",
            fallback_type=fallback_type,
            reason=reason
        )
```

#### **Step 6.3: Health Checks & Alerting**

```python
# File: src/synthesis/monitoring/health.py
from typing import Dict, List, Optional
import asyncio
import time
from enum import Enum
from dataclasses import dataclass

class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"  
    UNHEALTHY = "unhealthy"

@dataclass
class HealthCheck:
    name: str
    status: HealthStatus
    message: str
    duration_ms: float
    timestamp: str

class SynthesisHealthChecker:
    def __init__(self, synthesis_engine):
        self.synthesis_engine = synthesis_engine
        self.health_checks: List[HealthCheck] = []
        
    async def check_template_loading(self) -> HealthCheck:
        """Check if templates can be loaded"""
        start_time = time.time()
        
        try:
            template = self.synthesis_engine.template_manager.load_template(
                "system/vi/default"
            )
            
            if template:
                status = HealthStatus.HEALTHY
                message = "Templates loading successfully"
            else:
                status = HealthStatus.DEGRADED
                message = "Template loaded but empty"
                
        except Exception as e:
            status = HealthStatus.UNHEALTHY
            message = f"Template loading failed: {str(e)}"
            
        duration = (time.time() - start_time) * 1000
        
        return HealthCheck(
            name="template_loading",
            status=status,
            message=message,
            duration_ms=duration,
            timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
        )
        
    async def check_context_building(self) -> HealthCheck:
        """Check context building performance"""
        start_time = time.time()
        
        try:
            # Test với mock documents
            mock_docs = [
                DocumentInput(
                    content="Test document for health check",
                    metadata={"source": "health_check"},
                    chunk_id="health_check_1",
                    relevance_score=0.8
                )
            ]
            
            context_builder = self.synthesis_engine.context_builder
            selected = context_builder.select_documents(
                documents=mock_docs,
                query=QueryInput(query="health check", user_id="system"),
                max_tokens=1000
            )
            
            if selected:
                status = HealthStatus.HEALTHY
                message = f"Context building working, selected {len(selected)} documents"
            else:
                status = HealthStatus.DEGRADED  
                message = "Context building returned no documents"
                
        except Exception as e:
            status = HealthStatus.UNHEALTHY
            message = f"Context building failed: {str(e)}"
            
        duration = (time.time() - start_time) * 1000
        
        return HealthCheck(
            name="context_building",
            status=status,
            message=message, 
            duration_ms=duration,
            timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
        )
        
    async def check_overall_health(self) -> Dict[str, any]:
        """Run all health checks"""
        checks = await asyncio.gather(
            self.check_template_loading(),
            self.check_context_building(),
            return_exceptions=True
        )
        
        # Determine overall status
        statuses = [check.status for check in checks if isinstance(check, HealthCheck)]
        
        if HealthStatus.UNHEALTHY in statuses:
            overall_status = HealthStatus.UNHEALTHY
        elif HealthStatus.DEGRADED in statuses:
            overall_status = HealthStatus.DEGRADED
        else:
            overall_status = HealthStatus.HEALTHY
            
        return {
            "status": overall_status.value,
            "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
            "checks": [
                {
                    "name": check.name,
                    "status": check.status.value,
                    "message": check.message,
                    "duration_ms": check.duration_ms
                }
                for check in checks if isinstance(check, HealthCheck)
            ]
        }
```

---

## 🚀 **DEPLOYMENT & PRODUCTION SETUP**

### **Phase 6: Production Deployment (Week 6)**

#### **Step 6.1: Docker Configuration**

```dockerfile
# File: Dockerfile
FROM python:3.11-slim as builder

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy dependency files
COPY pyproject.toml poetry.lock ./

# Install poetry và dependencies
RUN pip install poetry==1.5.1 \
    && poetry config virtualenvs.create false \
    && poetry install --no-dev --no-interaction --no-ansi

# Production stage  
FROM python:3.11-slim as production

WORKDIR /app

# Copy installed packages from builder
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy application code
COPY src/ ./src/
COPY templates/ ./templates/
COPY config/ ./config/

# Create logs directory
RUN mkdir -p logs

# Create non-root user
RUN adduser --disabled-password --gecos '' synthesisuser \
    && chown -R synthesisuser:synthesisuser /app

USER synthesisuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Expose port
EXPOSE 8000

# Start application
CMD ["python", "-m", "uvicorn", "src.synthesis.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# File: docker-compose.yml
version: '3.8'

services:
  synthesis-service:
    build: .
    ports:
      - "8000:8000"
    environment:
      - SYNTHESIS_OPENAI_API_KEY=${OPENAI_API_KEY}
      - SYNTHESIS_MAX_TOKENS=4000
      - SYNTHESIS_CACHE_TTL=3600
      - REDIS_URL=redis://redis:6379
      - POSTGRES_URL=postgresql://user:pass@postgres:5432/synthesis
    depends_on:
      - redis
      - postgres
    volumes:
      - ./logs:/app/logs
      - ./config:/app/config
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=synthesis
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped
    
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
  prometheus_data:
  grafana_data:
```

#### **Step 6.2: Kubernetes Deployment**

```yaml
# File: k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: synthesis-service
  labels:
    app: synthesis-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: synthesis-service
  template:
    metadata:
      labels:
        app: synthesis-service
    spec:
      containers:
      - name: synthesis
        image: synthesis-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: SYNTHESIS_OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: synthesis-secrets
              key: openai-api-key
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        - name: POSTGRES_URL
          valueFrom:
            secretKeyRef:
              name: synthesis-secrets
              key: postgres-url
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: config
        configMap:
          name: synthesis-config
      - name: logs
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: synthesis-service
spec:
  selector:
    app: synthesis-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: synthesis-config
data:
  production.yaml: |
    max_tokens: 4000
    max_context_documents: 10
    similarity_threshold: 0.7
    cache_ttl: 3600
    request_timeout: 30
    max_retries: 3

---
apiVersion: v1
kind: Secret
metadata:
  name: synthesis-secrets
type: Opaque
data:
  openai-api-key: <base64-encoded-api-key>
  postgres-url: <base64-encoded-postgres-url>
```

#### **Step 6.3: Production Configuration & Environment Variables**

```python
# File: config/production.py
from src.synthesis.config.base import SynthesisConfig
import os

class ProductionConfig(SynthesisConfig):
    """Production configuration với security & performance optimizations"""
    
    # API Configuration
    openai_api_key: str = os.getenv("SYNTHESIS_OPENAI_API_KEY", "")
    anthropic_api_key: str = os.getenv("SYNTHESIS_ANTHROPIC_API_KEY", "")
    
    # Performance Settings
    max_tokens: int = int(os.getenv("SYNTHESIS_MAX_TOKENS", "4000"))
    max_context_documents: int = int(os.getenv("SYNTHESIS_MAX_CONTEXT_DOCS", "10"))
    max_concurrent_requests: int = int(os.getenv("SYNTHESIS_MAX_CONCURRENT", "100"))
    
    # Cache Configuration  
    redis_url: str = os.getenv("REDIS_URL", "redis://localhost:6379")
    cache_ttl: int = int(os.getenv("SYNTHESIS_CACHE_TTL", "3600"))
    
    # Database Configuration
    postgres_url: str = os.getenv("POSTGRES_URL", "")
    
    # Security Settings
    api_rate_limit: str = os.getenv("SYNTHESIS_RATE_LIMIT", "100/hour")
    cors_origins: list = os.getenv("SYNTHESIS_CORS_ORIGINS", "*").split(",")
    
    # Monitoring & Logging
    log_level: str = os.getenv("LOG_LEVEL", "INFO")
    metrics_enabled: bool = os.getenv("METRICS_ENABLED", "true").lower() == "true"
    
    # Health Check Configuration
    health_check_timeout: int = int(os.getenv("HEALTH_CHECK_TIMEOUT", "5"))
    
    class Config:
        env_file = ".env.production"
        case_sensitive = True
```

---

## 📚 **DOCUMENTATION & HANDOVER**

### **Step 7: Complete Documentation Package**

#### **Step 7.1: API Documentation**

```python
# File: src/synthesis/api/main.py
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import structlog

app = FastAPI(
    title="RAG Synthesis Service",
    description="Context synthesis và prompt generation cho RAG system",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure properly in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class SynthesisRequest(BaseModel):
    """Request model cho synthesis endpoint"""
    documents: List[Dict[str, Any]]
    query: Dict[str, Any]
    options: Optional[Dict[str, Any]] = None
    
    class Config:
        schema_extra = {
            "example": {
                "documents": [
                    {
                        "content": "Python is a programming language...",
                        "metadata": {"source": "python_guide.pdf", "page": 1},
                        "chunk_id": "chunk_001",
                        "relevance_score": 0.95
                    }
                ],
                "query": {
                    "query": "What is Python programming language

Náº¿u Ä‘Ã£ Ä‘á»§ thÃ´ng tin hÃ£y giÃºp tÃ´i viáº¿t tÃ i liá»‡u thiáº¿t káº¿ module dÆ°á»›i Ä‘Ã¢y.
TÃ i liá»‡u nÃ y cung cáº¥p roadmap Ä‘áº§y Ä‘á»§ Ä‘á»ƒ implement FR-04.2 mÃ  khÃ´ng cáº§n code cá»¥ thá»ƒ nhÆ°ng 
cÃ³ cÃ¡c bÆ°á»›c lÃ m cá»¥ thá»ƒ nhÆ° chuáº©n bá»‹ mÃ´i trÆ°á»ng PC tháº¿ nÃ o, pháº§n má»m gÃ¬?
 Ä‘á»ƒ Team ká»¹ thuáº­t cÃ³ thá»ƒ follow step-by-step guide nÃ y Ä‘á»ƒ thiáº¿t káº¿ tá»‘i Æ°u cho há»‡ thá»‘ng chatbot
 vÃ  cÃ³ mermaidchart luá»“ng cÃ´ng viá»‡c, Ä‘iá»ƒm quay Ä‘áº§u khi bá»‹ fail.

### 3.4 Module RAG Core Engine (FR-04)

**FR-04.2 - Synthesis (Tá»•ng há»£p)**
- XÃ¢y dá»±ng context tá»« cÃ¡c documents truy xuáº¥t Ä‘Æ°á»£c
- Template hÃ³a prompt cho LLM
- Xá»­ lÃ½ trÆ°á»ng há»£p khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p
---
# TÃ€I LIá»†U THIáº¾T Káº¾ MODULE FR-04.2: SYNTHESIS (Tá»”NG Há»¢P)
## ROADMAP TRIá»‚N KHAI CHO TEAM Ká»¸ THUáº¬T

---

**Module:** RAG Core Engine - Synthesis Component  
**Requirement ID:** FR-04.2  
**Version:** 1.0  
**Date:** 01/09/2025  
**Target Audience:** Development Team  

---

## ğŸ“‹ **Tá»”NG QUAN MODULE**

### **Má»¥c tiÃªu**
Module Synthesis chá»‹u trÃ¡ch nhiá»‡m xÃ¢y dá»±ng context thÃ´ng minh tá»« cÃ¡c documents Ä‘Æ°á»£c retrieval, táº¡o prompt templates tá»‘i Æ°u cho LLM, vÃ  xá»­ lÃ½ graceful cÃ¡c trÆ°á»ng há»£p khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p.

### **Input/Output**
- **Input**: Retrieved documents + User query + User context
- **Output**: Structured prompt cho LLM + Fallback responses

### **Vá»‹ trÃ­ trong RAG Pipeline**
```
Query Processing â†’ Document Retrieval â†’ [SYNTHESIS] â†’ LLM Generation â†’ Response
```

---

## ğŸ› ï¸ **CHUáº¨N Bá»Š MÃ”I TRÆ¯á»œNG PHÃT TRIá»‚N**

### **1. YÃªu cáº§u Pháº§n cá»©ng**
```
CPU: Intel i7/AMD Ryzen 7 (8+ cores) hoáº·c cao hÆ¡n
RAM: 32GB+ (recommend 64GB cho testing vá»›i large datasets)
Storage: 1TB+ SSD (NVMe preferred)
GPU: Optional - NVIDIA RTX 4060+ náº¿u test local LLM
Network: Stable internet cho API calls
```

### **2. Há»‡ Ä‘iá»u hÃ nh**
```
Primary: Ubuntu 22.04 LTS / Windows 11 Pro / macOS 13+
Container: Docker Desktop 4.20+
Virtualization: VirtualBox/VMware (náº¿u cáº§n isolated environment)
```

### **3. Development Environment Setup**

#### **3.1 Core Development Tools**
```bash
# Python Environment
Python 3.11+ (recommend pyenv cho version management)
pip 23.0+
Poetry 1.5+ (dependency management)

# IDE Options (chá»n 1)
- Visual Studio Code + Python extensions
- PyCharm Professional 2023.2+
- Cursor AI (recommend cho AI-assisted development)

# Version Control
Git 2.40+
GitHub CLI (optional nhÆ°ng recommend)
```

#### **3.2 Specialized AI/ML Tools**
```bash
# Essential Python Libraries
langchain>=0.1.0          # LLM orchestration
openai>=1.0.0             # OpenAI API
anthropic>=0.8.0          # Claude API
jinja2>=3.1.0             # Template engine
tiktoken>=0.5.0           # Token counting
pydantic>=2.0.0           # Data validation
pytest>=7.0.0             # Testing framework
black>=23.0.0             # Code formatting
mypy>=1.5.0               # Type checking

# Performance & Monitoring
prometheus-client>=0.17.0  # Metrics
structlog>=23.0.0         # Structured logging
tenacity>=8.2.0           # Retry mechanisms
```

#### **3.3 Development Infrastructure**
```bash
# Local Development Stack
Docker Desktop 4.20+
Docker Compose v2.20+
Redis 7.0+ (cho caching)
PostgreSQL 15+ (cho metadata)

# Testing & Quality
pytest-cov>=4.0.0        # Coverage testing
pre-commit>=3.3.0        # Git hooks
ruff>=0.0.280             # Fast linter
```

### **4. Project Structure Setup**

```bash
# Táº¡o project structure
mkdir rag_synthesis_module
cd rag_synthesis_module

# Initialize Python project
poetry init
poetry add langchain openai anthropic jinja2 tiktoken pydantic
poetry add --group dev pytest black mypy ruff pytest-cov

# Táº¡o cáº¥u trÃºc thÆ° má»¥c
mkdir -p {
  src/synthesis/{core,templates,handlers,utils},
  tests/{unit,integration,e2e},
  config,
  docs,
  examples,
  scripts
}

# Initialize Git
git init
# Setup pre-commit hooks (sáº½ detail á»Ÿ bÆ°á»›c sau)
```

---

## ğŸ—ï¸ **KIáº¾N TRÃšC MODULE SYNTHESIS**

### **5. Component Architecture**

```mermaid
graph TB
    subgraph "ğŸ“¥ INPUT PROCESSING"
        Input[ğŸ” Retrieved Documents<br/>+ User Query + Context]
        Validator[âœ… Input Validator<br/>Validate & Sanitize]
        Scorer[ğŸ“Š Relevance Scorer<br/>Score Documents]
    end
    
    subgraph "ğŸ§© CONTEXT BUILDING"
        ContextBuilder[ğŸ—ï¸ Context Builder<br/>Smart Document Selection]
        
        subgraph "Context Strategies"
            TopK[ğŸ“ˆ Top-K Strategy<br/>Best N documents]
            Diversity[ğŸ¯ Diversity Strategy<br/>Varied sources]
            Threshold[ğŸ“ Threshold Strategy<br/>Above confidence score]
        end
        
        ContextOptimizer[âš¡ Context Optimizer<br/>Token limit management]
    end
    
    subgraph "ğŸ“ TEMPLATE PROCESSING"
        TemplateManager[ğŸ“‹ Template Manager<br/>Load & Manage Templates]
        
        subgraph "Template Types"
            SystemTemplate[ğŸ¤– System Templates<br/>Role definitions]
            QueryTemplate[â“ Query Templates<br/>Question formatting]
            ContextTemplate[ğŸ“š Context Templates<br/>Document formatting]
            FallbackTemplate[ğŸš¨ Fallback Templates<br/>No-result handling]
        end
        
        TemplateRenderer[ğŸ¨ Template Renderer<br/>Jinja2 Engine]
    end
    
    subgraph "ğŸ”§ PROMPT ASSEMBLY"
        PromptAssembler[ğŸ”§ Prompt Assembler<br/>Combine all parts]
        TokenCounter[ğŸ”¢ Token Counter<br/>Validate length]
        QualityChecker[âœ… Quality Checker<br/>Validate prompt quality]
    end
    
    subgraph "ğŸ“¤ OUTPUT GENERATION"
        OutputFormatter[ğŸ“‹ Output Formatter<br/>Structure final output]
        MetadataEnricher[ğŸ·ï¸ Metadata Enricher<br/>Add context info]
        FinalOutput[âœ¨ Structured Prompt<br/>Ready for LLM]
    end
    
    subgraph "ğŸš¨ ERROR HANDLING"
        ErrorHandler[âŒ Error Handler<br/>Handle failures]
        FallbackGenerator[ğŸ”„ Fallback Generator<br/>Default responses]
        LoggingService[ğŸ“ Logging Service<br/>Error tracking]
    end
    
    %% Main Flow
    Input --> Validator
    Validator --> Scorer
    Scorer --> ContextBuilder
    
    ContextBuilder --> TopK
    ContextBuilder --> Diversity  
    ContextBuilder --> Threshold
    
    TopK --> ContextOptimizer
    Diversity --> ContextOptimizer
    Threshold --> ContextOptimizer
    
    ContextOptimizer --> TemplateManager
    TemplateManager --> SystemTemplate
    TemplateManager --> QueryTemplate
    TemplateManager --> ContextTemplate
    TemplateManager --> FallbackTemplate
    
    SystemTemplate --> TemplateRenderer
    QueryTemplate --> TemplateRenderer
    ContextTemplate --> TemplateRenderer
    FallbackTemplate --> TemplateRenderer
    
    TemplateRenderer --> PromptAssembler
    PromptAssembler --> TokenCounter
    TokenCounter --> QualityChecker
    QualityChecker --> OutputFormatter
    OutputFormatter --> MetadataEnricher
    MetadataEnricher --> FinalOutput
    
    %% Error Flows (dotted red)
    Validator -.-> ErrorHandler
    ContextBuilder -.-> ErrorHandler  
    TemplateRenderer -.-> ErrorHandler
    TokenCounter -.-> ErrorHandler
    
    ErrorHandler --> FallbackGenerator
    ErrorHandler --> LoggingService
    FallbackGenerator --> FinalOutput
    
    %% Styling
    classDef input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef context fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef template fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef assembly fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef output fill:#e0f2f1,stroke:#00796b,stroke-width:2px
    classDef error fill:#ffebee,stroke:#c62828,stroke-width:2px
    
    class Input,Validator,Scorer input
    class ContextBuilder,TopK,Diversity,Threshold,ContextOptimizer context
    class TemplateManager,SystemTemplate,QueryTemplate,ContextTemplate,FallbackTemplate,TemplateRenderer template
    class PromptAssembler,TokenCounter,QualityChecker assembly
    class OutputFormatter,MetadataEnricher,FinalOutput output
    class ErrorHandler,FallbackGenerator,LoggingService error
```

---

## ğŸ“ **STEP-BY-STEP IMPLEMENTATION ROADMAP**

### **Phase 1: Environment Setup & Foundation (Week 1)**

#### **Step 1.1: Initialize Development Environment**
```bash
# 1. Clone & setup project
git clone <repository>
cd rag_synthesis_module

# 2. Setup Python environment
pyenv install 3.11.5
pyenv local 3.11.5
poetry install

# 3. Setup pre-commit hooks
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: https://github.com/psf/black
    rev: 23.7.0
    hooks:
      - id: black
  - repo: https://github.com/charliermarsh/ruff-pre-commit
    rev: v0.0.280
    hooks:
      - id: ruff
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.5.1
    hooks:
      - id: mypy
EOF

pre-commit install

# 4. Setup testing infrastructure
poetry run pytest --version
poetry run black --version
poetry run mypy --version
```

#### **Step 1.2: Core Configuration Setup**
```bash
# Create config structure
mkdir -p config/{development,staging,production}

# Create base config template
cat > config/base_config.py << EOF
from pydantic_settings import BaseSettings
from typing import Dict, Any, List
import os

class SynthesisConfig(BaseSettings):
    # LLM Settings
    openai_api_key: str = ""
    anthropic_api_key: str = ""
    max_tokens: int = 4000
    temperature: float = 0.1
    
    # Context Settings
    max_context_documents: int = 10
    max_context_tokens: int = 8000
    similarity_threshold: float = 0.7
    diversity_threshold: float = 0.8
    
    # Template Settings
    template_directory: str = "templates"
    default_language: str = "vi"
    
    # Performance Settings
    cache_ttl: int = 3600
    request_timeout: int = 30
    max_retries: int = 3
    
    class Config:
        env_file = ".env"
        env_prefix = "SYNTHESIS_"
EOF
```

#### **Step 1.3: Setup Testing Framework**
```bash
# Create test configuration
cat > tests/conftest.py << EOF
import pytest
from unittest.mock import Mock
from src.synthesis.config import SynthesisConfig

@pytest.fixture
def mock_config():
    return SynthesisConfig(
        openai_api_key="test-key",
        max_tokens=1000,
        max_context_documents=5
    )

@pytest.fixture  
def mock_documents():
    return [
        {
            "content": "Document 1 content about AI",
            "metadata": {"source": "doc1.pdf", "score": 0.9},
            "chunk_id": "chunk_1"
        },
        {
            "content": "Document 2 content about machine learning", 
            "metadata": {"source": "doc2.pdf", "score": 0.8},
            "chunk_id": "chunk_2"
        }
    ]

@pytest.fixture
def mock_user_query():
    return {
        "query": "What is artificial intelligence?",
        "user_id": "test_user",
        "department": "engineering",
        "language": "vi"
    }
EOF
```

### **Phase 2: Core Components Implementation (Week 2)**

#### **Step 2.1: Input Validation & Processing**

**ğŸ¯ Checklist:**
- [ ] Create input data models vá»›i Pydantic
- [ ] Implement input sanitization
- [ ] Add relevance scoring logic
- [ ] Write unit tests cho validation

```python
# File: src/synthesis/core/input_processor.py
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Any, Optional
import re
import logging

class DocumentInput(BaseModel):
    content: str = Field(..., min_length=10)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    chunk_id: str = Field(..., min_length=1)
    relevance_score: Optional[float] = Field(default=0.0, ge=0.0, le=1.0)
    
    @validator('content')
    def sanitize_content(cls, v):
        # Remove excessive whitespace, normalize text
        return re.sub(r'\s+', ' ', v.strip())

class QueryInput(BaseModel):
    query: str = Field(..., min_length=3, max_length=1000)
    user_id: str = Field(..., min_length=1)
    department: Optional[str] = None
    language: str = Field(default="vi")
    context: Dict[str, Any] = Field(default_factory=dict)

class SynthesisInput(BaseModel):
    documents: List[DocumentInput] = Field(..., min_items=0)
    query: QueryInput
    synthesis_config: Dict[str, Any] = Field(default_factory=dict)

# Implementation tasks:
# 1. Implement InputValidator class
# 2. Add document scoring logic  
# 3. Create input preprocessing pipeline
# 4. Add comprehensive error handling
```

**ğŸ’¡ Implementation Hints:**
```bash
# Test validation
poetry run pytest tests/unit/test_input_processor.py -v

# Check type hints
poetry run mypy src/synthesis/core/input_processor.py

# Format code
poetry run black src/synthesis/core/input_processor.py
```

#### **Step 2.2: Context Building Strategies**

**ğŸ¯ Checklist:**
- [ ] Implement TopK selection strategy
- [ ] Implement Diversity-based selection  
- [ ] Implement Threshold-based filtering
- [ ] Add token counting and optimization
- [ ] Create context optimization algorithms

```python
# File: src/synthesis/core/context_builder.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any
import tiktoken
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class ContextSelectionStrategy(ABC):
    @abstractmethod
    def select_documents(
        self, 
        documents: List[DocumentInput], 
        query: QueryInput,
        max_tokens: int
    ) -> List[DocumentInput]:
        pass

class TopKStrategy(ContextSelectionStrategy):
    def __init__(self, k: int = 5):
        self.k = k
    
    def select_documents(self, documents, query, max_tokens):
        # Implementation: Sort by relevance_score, take top K
        # Consider token limits
        pass

class DiversityStrategy(ContextSelectionStrategy):  
    def __init__(self, diversity_threshold: float = 0.8):
        self.diversity_threshold = diversity_threshold
    
    def select_documents(self, documents, query, max_tokens):
        # Implementation: Select diverse documents using embedding similarity
        # Avoid redundant information
        pass

# Implementation tasks:
# 1. Complete each strategy implementation
# 2. Add token counting vá»›i tiktoken
# 3. Implement context optimization
# 4. Add performance metrics collection
```

#### **Step 2.3: Template Management System**

**ğŸ¯ Checklist:**
- [ ] Setup Jinja2 template engine
- [ ] Create template categories (System, Query, Context, Fallback)
- [ ] Implement template loading and caching
- [ ] Add template validation
- [ ] Create multilingual support

```bash
# Create template directory structure
mkdir -p templates/{system,query,context,fallback}/{vi,en}

# Create base system template
cat > templates/system/vi/default.j2 << EOF
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh chuyÃªn tÆ° váº¥n vá» tÃ i liá»‡u ná»™i bá»™ cÃ´ng ty.

NGUYÃŠN Táº®C HOáº T Äá»˜NG:
1. Chá»‰ tráº£ lá»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p trong CONTEXT bÃªn dÆ°á»›i
2. Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan, hÃ£y thÃ nh tháº­t nÃ³i "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» váº¥n Ä‘á» nÃ y trong tÃ i liá»‡u hiá»‡n cÃ³"
3. LuÃ´n trÃ­ch dáº«n nguá»“n tÃ i liá»‡u khi Ä‘Æ°a ra thÃ´ng tin
4. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, rÃµ rÃ ng vÃ  dá»… hiá»ƒu
5. Náº¿u thÃ´ng tin khÃ´ng cháº¯c cháº¯n, hÃ£y nÃ³i rÃµ má»©c Ä‘á»™ tin cáº­y

THÃ”NG TIN NGÆ¯á»œI DÃ™NG:
- PhÃ²ng ban: {{ user_department }}
- Cáº¥p Ä‘á»™ truy cáº­p: {{ user_access_level }}
EOF
```

### **Phase 3: Template Processing & Prompt Assembly (Week 3)**

#### **Step 3.1: Template Engine Implementation**

**ğŸ¯ Checklist:**
- [ ] Setup Jinja2 vá»›i custom filters vÃ  functions
- [ ] Implement template inheritance
- [ ] Add template caching mechanism  
- [ ] Create template validation system
- [ ] Implement dynamic template selection

```python
# File: src/synthesis/templates/template_manager.py
from jinja2 import Environment, FileSystemLoader, select_autoescape
from typing import Dict, Any, Optional
import os
from functools import lru_cache

class TemplateManager:
    def __init__(self, template_dir: str = "templates"):
        self.env = Environment(
            loader=FileSystemLoader(template_dir),
            autoescape=select_autoescape(['html', 'xml']),
            trim_blocks=True,
            lstrip_blocks=True
        )
        
        # Add custom filters
        self.env.filters['truncate_tokens'] = self._truncate_by_tokens
        self.env.filters['format_citations'] = self._format_citations
        
    @lru_cache(maxsize=128)
    def load_template(self, template_type: str, language: str = "vi") -> str:
        # Implementation: Load and cache templates
        pass
    
    def render_template(
        self, 
        template_name: str, 
        context: Dict[str, Any],
        language: str = "vi"
    ) -> str:
        # Implementation: Render template with context
        pass

# Implementation tasks:
# 1. Complete template loading logic
# 2. Add custom Jinja2 filters for AI-specific formatting
# 3. Implement template validation
# 4. Add error handling for missing templates
```

#### **Step 3.2: Prompt Assembly Engine**

**ğŸ¯ Checklist:**
- [ ] Create prompt assembly pipeline
- [ ] Implement token counting and limit management
- [ ] Add prompt quality validation
- [ ] Create prompt optimization algorithms
- [ ] Add structured output formatting

```python
# File: src/synthesis/core/prompt_assembler.py
from typing import List, Dict, Any, Optional
import tiktoken
from dataclasses import dataclass

@dataclass
class AssembledPrompt:
    system_prompt: str
    user_prompt: str
    total_tokens: int
    context_documents: List[Dict[str, Any]]
    metadata: Dict[str, Any]

class PromptAssembler:
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.tokenizer = tiktoken.encoding_for_model(model_name)
        self.max_tokens = 4000  # Configurable
        
    def assemble_prompt(
        self,
        query: QueryInput,
        context_documents: List[DocumentInput],
        templates: Dict[str, str]
    ) -> AssembledPrompt:
        # Implementation: Assemble all components into final prompt
        pass
    
    def optimize_prompt_length(self, prompt: str, max_tokens: int) -> str:
        # Implementation: Truncate intelligently while preserving meaning
        pass

# Implementation tasks:
# 1. Complete prompt assembly logic
# 2. Add intelligent truncation algorithms  
# 3. Implement prompt quality scoring
# 4. Add metadata enrichment
```

### **Phase 4: Error Handling & Fallback Mechanisms (Week 4)**

#### **Step 4.1: Comprehensive Error Handling**

**ğŸ¯ Checklist:**
- [ ] Create error taxonomy vÃ  handling strategies
- [ ] Implement graceful degradation
- [ ] Add retry mechanisms vá»›i backoff
- [ ] Create error logging vÃ  monitoring
- [ ] Implement health checks

```python
# File: src/synthesis/core/error_handler.py
from enum import Enum
from typing import Optional, Dict, Any
import structlog
from tenacity import retry, stop_after_attempt, wait_exponential

class SynthesisError(Exception):
    """Base exception for synthesis module"""
    pass

class ErrorType(Enum):
    INVALID_INPUT = "invalid_input"
    NO_RELEVANT_DOCUMENTS = "no_relevant_documents"  
    TEMPLATE_ERROR = "template_error"
    TOKEN_LIMIT_EXCEEDED = "token_limit_exceeded"
    LLM_API_ERROR = "llm_api_error"

class ErrorHandler:
    def __init__(self):
        self.logger = structlog.get_logger()
        
    def handle_error(
        self, 
        error_type: ErrorType, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        # Implementation: Route to appropriate error handling strategy
        pass
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10)
    )
    def retry_with_fallback(self, operation, fallback):
        # Implementation: Retry logic with fallback
        pass

# Implementation tasks:
# 1. Complete error handling strategies
# 2. Add comprehensive logging
# 3. Implement circuit breaker pattern
# 4. Add error metrics collection
```

#### **Step 4.2: Fallback Response Generation**

**ğŸ¯ Checklist:**
- [ ] Create fallback response templates
- [ ] Implement intelligent fallback selection
- [ ] Add contextual fallback messages
- [ ] Create escalation mechanisms
- [ ] Add user guidance features

```python
# File: src/synthesis/core/fallback_generator.py
from typing import Dict, Any, List
from enum import Enum

class FallbackType(Enum):
    NO_DOCUMENTS_FOUND = "no_documents"
    INSUFFICIENT_PERMISSION = "insufficient_permission"
    QUERY_TOO_VAGUE = "query_too_vague"
    TECHNICAL_ERROR = "technical_error"

class FallbackGenerator:
    def __init__(self, template_manager):
        self.template_manager = template_manager
        
    def generate_fallback_response(
        self,
        fallback_type: FallbackType,
        query: QueryInput,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        # Implementation: Generate appropriate fallback response
        pass
    
    def suggest_alternatives(self, query: str) -> List[str]:
        # Implementation: Suggest alternative queries or actions
        pass

# Implementation tasks:  
# 1. Create fallback response templates
# 2. Implement smart suggestion algorithms
# 3. Add user guidance mechanisms
# 4. Create escalation workflows
```

---

## ğŸ”„ **WORKFLOW VÃ€ FAILURE HANDLING**

### **Main Workflow Diagram**

```mermaid
flowchart TD
    Start([ğŸš€ Start Synthesis Process]) --> ValidateInput{âœ… Validate Input?}
    
    ValidateInput -->|âŒ Invalid| HandleInputError[ğŸš¨ Handle Input Error]
    ValidateInput -->|âœ… Valid| ScoreDocuments[ğŸ“Š Score Documents]
    
    HandleInputError --> ReturnError1[âŒ Return Error Response]
    
    ScoreDocuments --> HasDocuments{ğŸ“š Has Relevant Documents?}
    
    HasDocuments -->|âŒ No| GenerateNoResultsFallback[ğŸ”„ Generate No Results Fallback]
    HasDocuments -->|âœ… Yes| SelectStrategy{ğŸ¯ Select Context Strategy}
    
    GenerateNoResultsFallback --> ReturnFallback1[ğŸ”„ Return Fallback Response]
    
    SelectStrategy --> TopKStrategy[ğŸ“ˆ Top-K Strategy]
    SelectStrategy --> DiversityStrategy[ğŸ¯ Diversity Strategy] 
    SelectStrategy --> ThresholdStrategy[ğŸ“ Threshold Strategy]
    
    TopKStrategy --> OptimizeContext[âš¡ Optimize Context]
    DiversityStrategy --> OptimizeContext
    ThresholdStrategy --> OptimizeContext
    
    OptimizeContext --> TokenCheck{ğŸ”¢ Within Token Limit?}
    
    TokenCheck -->|âŒ Exceed| TruncateContext[âœ‚ï¸ Truncate Context]
    TokenCheck -->|âœ… OK| LoadTemplates[ğŸ“‹ Load Templates]
    
    TruncateContext --> LoadTemplates
    
    LoadTemplates --> TemplateExists{ğŸ“ Template Exists?}
    
    TemplateExists -->|âŒ No| HandleTemplateError[ğŸš¨ Handle Template Error]
    TemplateExists -->|âœ… Yes| RenderTemplate[ğŸ¨ Render Template]
    
    HandleTemplateError --> UseDefaultTemplate[ğŸ“‹ Use Default Template]
    UseDefaultTemplate --> RenderTemplate
    
    RenderTemplate --> RenderSuccess{âœ… Render Success?}
    
    RenderSuccess -->|âŒ Fail| HandleRenderError[ğŸš¨ Handle Render Error]
    RenderSuccess -->|âœ… Success| AssemblePrompt[ğŸ”§ Assemble Final Prompt]
    
    HandleRenderError --> GenerateBasicFallback[ğŸ”„ Generate Basic Fallback]
    GenerateBasicFallback --> ReturnFallback2[ğŸ”„ Return Fallback Response]
    
    AssemblePrompt --> ValidatePrompt{âœ… Validate Final Prompt?}
    
    ValidatePrompt -->|âŒ Invalid| HandlePromptError[ğŸš¨ Handle Prompt Error]
    ValidatePrompt -->|âœ… Valid| EnrichMetadata[ğŸ·ï¸ Enrich Metadata]
    
    HandlePromptError --> RetryAttempt{ğŸ”„ Retry Available?}
    
    RetryAttempt -->|âœ… Yes| RetryCount[ğŸ“Š Increment Retry Counter]
    RetryAttempt -->|âŒ No| GenerateFinalFallback[ğŸ”„ Generate Final Fallback]
    
    RetryCount --> SelectStrategy
    GenerateFinalFallback --> ReturnFallback3[ğŸ”„ Return Fallback Response]
    
    EnrichMetadata --> LogSuccess[ğŸ“ Log Success Metrics]
    LogSuccess --> ReturnSuccess[âœ… Return Synthesized Prompt]
    
    %% Error Return Points
    ReturnError1 --> End([ğŸ End Process])
    ReturnFallback1 --> End
    ReturnFallback2 --> End  
    ReturnFallback3 --> End
    ReturnSuccess --> End
    
    %% Styling
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    classDef process fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef error fill:#ffebee,stroke:#c62828,stroke-width:2px
    classDef fallback fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef success fill:#e0f2f1,stroke:#00796b,stroke-width:2px
    
    class Start,End startEnd
    class ScoreDocuments,OptimizeContext,TruncateContext,LoadTemplates,RenderTemplate,AssemblePrompt,EnrichMetadata,LogSuccess,RetryCount process
    class ValidateInput,HasDocuments,SelectStrategy,TokenCheck,TemplateExists,RenderSuccess,ValidatePrompt,RetryAttempt decision
    class HandleInputError,HandleTemplateError,HandleRenderError,HandlePromptError error
    class GenerateNoResultsFallback,GenerateBasicFallback,GenerateFinalFallback,UseDefaultTemplate,ReturnFallback1,ReturnFallback2,ReturnFallback3 fallback
    class ReturnSuccess success
```

### **Failure Recovery Points**

```mermaid
graph TB
    subgraph "ğŸ”„ RECOVERY STRATEGIES"
        subgraph "Level 1: Input Failures"
            InputFail[âŒ Input Validation Failed]
            InputRecover[ğŸ”§ Sanitize & Retry]
            InputFallback[ğŸ“‹ Request Clarification]
        end
        
        subgraph "Level 2: Context Failures" 
            ContextFail[âŒ Context Building Failed]
            ContextRecover[ğŸ”§ Reduce Context Size]
            ContextFallback[ğŸ“š Use Cached Context]
        end
        
        subgraph "Level 3: Template Failures"
            TemplateFail[âŒ Template Loading Failed]
            TemplateRecover[ğŸ”§ Load Default Template]  
            TemplateFallback[ğŸ“ Use Minimal Template]
        end
        
        subgraph "Level 4: System Failures"
            SystemFail[âŒ System Error]
            SystemRecover[ğŸ”§ Circuit Breaker]
            SystemFallback[ğŸš¨ Emergency Response]
        end
    end
    
    subgraph "ğŸ“Š MONITORING & ALERTS"
        MetricsCollector[ğŸ“ˆ Metrics Collector]
        AlertManager[ğŸš¨ Alert Manager]
        HealthChecker[â¤ï¸ Health Checker]
    end
    
    %% Recovery Flows
    InputFail --> InputRecover
    InputRecover -->|Success| Normal[âœ… Continue Normal Flow]
    InputRecover -->|Fail| InputFallback
    
    ContextFail --> ContextRecover
    ContextRecover -->|Success| Normal
    ContextRecover -->|Fail| ContextFallback
    
    TemplateFail --> TemplateRecover
    TemplateRecover -->|Success| Normal  
    TemplateRecover -->|Fail| TemplateFallback
    
    SystemFail --> SystemRecover
    SystemRecover -->|Success| Normal
    SystemRecover -->|Fail| SystemFallback
    
    %% Monitoring Connections
    InputFail -.-> MetricsCollector
    ContextFail -.-> MetricsCollector
    TemplateFail -.-> MetricsCollector
    SystemFail -.-> AlertManager
    
    MetricsCollector --> HealthChecker
    AlertManager --> HealthChecker
```
---
---

## ğŸ§ª **TESTING STRATEGY & IMPLEMENTATION**

### **Phase 5: Comprehensive Testing (Week 5)**

#### **Step 5.1: Unit Testing Implementation**

**ğŸ¯ Checklist:**
- [ ] Test all core components independently
- [ ] Mock external dependencies (LLM APIs, databases)
- [ ] Achieve 90%+ code coverage
- [ ] Test error conditions vÃ  edge cases
- [ ] Performance benchmarking

```python
# File: tests/unit/test_context_builder.py
import pytest
from unittest.mock import Mock, patch
from src.synthesis.core.context_builder import TopKStrategy, DiversityStrategy
from src.synthesis.models import DocumentInput, QueryInput

class TestTopKStrategy:
    def test_select_top_k_documents(self, mock_documents, mock_config):
        """Test selecting top K documents by relevance score"""
        strategy = TopKStrategy(k=3)
        
        # Sort mock documents by score
        sorted_docs = sorted(mock_documents, key=lambda x: x.relevance_score, reverse=True)
        
        selected = strategy.select_documents(
            documents=mock_documents,
            query=QueryInput(query="test query", user_id="test"),
            max_tokens=1000
        )
        
        assert len(selected) == 3
        assert selected[0].relevance_score >= selected[1].relevance_score
        
    def test_token_limit_respected(self, mock_documents):
        """Test that token limits are respected"""
        strategy = TopKStrategy(k=10)  # Request more than available
        
        selected = strategy.select_documents(
            documents=mock_documents,
            query=QueryInput(query="test", user_id="test"), 
            max_tokens=500  # Restrictive limit
        )
        
        total_tokens = sum(len(doc.content.split()) for doc in selected)
        assert total_tokens <= 500
        
    @pytest.mark.parametrize("k,expected_count", [
        (1, 1),
        (5, 5),
        (100, 10)  # More than available documents
    ])
    def test_various_k_values(self, mock_documents, k, expected_count):
        """Test strategy vá»›i different K values"""
        strategy = TopKStrategy(k=k)
        selected = strategy.select_documents(mock_documents, Mock(), 10000)
        assert len(selected) <= min(k, len(mock_documents))

# File: tests/unit/test_template_manager.py  
class TestTemplateManager:
    def test_template_loading(self, tmp_path):
        """Test template loading tá»« filesystem"""
        # Create temporary template
        template_dir = tmp_path / "templates"
        template_dir.mkdir()
        (template_dir / "test.j2").write_text("Hello {{ name }}!")
        
        manager = TemplateManager(str(template_dir))
        template = manager.load_template("test")
        
        assert template == "Hello {{ name }}!"
        
    def test_template_rendering(self, tmp_path):
        """Test template rendering vá»›i context"""
        template_dir = tmp_path / "templates"  
        template_dir.mkdir()
        (template_dir / "context.j2").write_text("""
        Query: {{ query }}
        Documents:
        {% for doc in documents %}
        - {{ doc.content }}
        {% endfor %}
        """)
        
        manager = TemplateManager(str(template_dir))
        rendered = manager.render_template("context", {
            "query": "What is AI?",
            "documents": [{"content": "AI is intelligence"}]
        })
        
        assert "What is AI?" in rendered
        assert "AI is intelligence" in rendered
        
    def test_missing_template_handling(self):
        """Test handling cá»§a missing templates"""
        manager = TemplateManager("/nonexistent/path")
        
        with pytest.raises(TemplateNotFoundError):
            manager.load_template("nonexistent")
```

#### **Step 5.2: Integration Testing**

**ğŸ¯ Checklist:**
- [ ] Test end-to-end synthesis pipeline
- [ ] Test integration vá»›i external services
- [ ] Test database interactions
- [ ] Validate performance under load
- [ ] Test fallback mechanisms

```python
# File: tests/integration/test_synthesis_pipeline.py
import pytest
from unittest.mock import AsyncMock, patch
from src.synthesis.core.synthesis_engine import SynthesisEngine
from src.synthesis.models import SynthesisInput, QueryInput, DocumentInput

class TestSynthesisPipeline:
    @pytest.fixture
    def synthesis_engine(self, mock_config):
        """Create synthesis engine vá»›i mocked dependencies"""
        return SynthesisEngine(config=mock_config)
        
    async def test_full_synthesis_pipeline(self, synthesis_engine):
        """Test complete synthesis tá»« input Ä‘áº¿n output"""
        # Prepare input
        synthesis_input = SynthesisInput(
            documents=[
                DocumentInput(
                    content="Python is a programming language",
                    metadata={"source": "python_guide.pdf"},
                    chunk_id="chunk_1",
                    relevance_score=0.95
                )
            ],
            query=QueryInput(
                query="What is Python?",
                user_id="test_user",
                department="engineering"
            )
        )
        
        # Mock external LLM API
        with patch('openai.ChatCompletion.create') as mock_llm:
            mock_llm.return_value = AsyncMock()
            
            result = await synthesis_engine.synthesize(synthesis_input)
            
            assert result.system_prompt is not None
            assert result.user_prompt is not None
            assert "Python" in result.user_prompt
            assert len(result.context_documents) > 0
            
    async def test_no_documents_fallback(self, synthesis_engine):
        """Test fallback khi khÃ´ng cÃ³ documents"""
        synthesis_input = SynthesisInput(
            documents=[],  # No documents
            query=QueryInput(query="What is AI?", user_id="test")
        )
        
        result = await synthesis_engine.synthesize(synthesis_input)
        
        assert result.is_fallback is True
        assert "khÃ´ng tÃ¬m tháº¥y thÃ´ng tin" in result.user_prompt.lower()
        
    async def test_token_limit_optimization(self, synthesis_engine):
        """Test token limit optimization"""
        # Create documents that exceed token limit
        large_documents = [
            DocumentInput(
                content="Very long content " * 1000,  # Exceed token limit
                metadata={},
                chunk_id=f"chunk_{i}",
                relevance_score=0.8
            ) for i in range(10)
        ]
        
        synthesis_input = SynthesisInput(
            documents=large_documents,
            query=QueryInput(query="Test query", user_id="test")
        )
        
        result = await synthesis_engine.synthesize(synthesis_input)
        
        # Should be within token limits
        assert result.total_tokens <= synthesis_engine.config.max_tokens
        assert len(result.context_documents) < len(large_documents)  # Some truncated
```

#### **Step 5.3: Performance Testing**

```python
# File: tests/performance/test_synthesis_performance.py
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor

class TestSynthesisPerformance:
    @pytest.mark.performance
    async def test_synthesis_latency(self, synthesis_engine, mock_documents):
        """Test synthesis latency requirements"""
        synthesis_input = SynthesisInput(
            documents=mock_documents,
            query=QueryInput(query="Performance test", user_id="test")
        )
        
        start_time = time.time()
        result = await synthesis_engine.synthesize(synthesis_input)
        end_time = time.time()
        
        latency = end_time - start_time
        assert latency < 2.0  # Should complete within 2 seconds
        assert result.total_tokens > 0
        
    @pytest.mark.performance  
    async def test_concurrent_synthesis(self, synthesis_engine):
        """Test concurrent synthesis requests"""
        async def single_synthesis():
            synthesis_input = SynthesisInput(
                documents=mock_documents[:5],
                query=QueryInput(query=f"Test query {time.time()}", user_id="test")
            )
            return await synthesis_engine.synthesize(synthesis_input)
            
        # Run 10 concurrent requests
        tasks = [single_synthesis() for _ in range(10)]
        start_time = time.time()
        results = await asyncio.gather(*tasks)
        total_time = time.time() - start_time
        
        assert len(results) == 10
        assert all(r.total_tokens > 0 for r in results)
        assert total_time < 10.0  # All requests within 10 seconds
        
    def test_memory_usage(self, synthesis_engine):
        """Test memory usage under load"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # Process many documents
        for i in range(100):
            large_input = SynthesisInput(
                documents=[DocumentInput(
                    content=f"Large content block {j}" * 100,
                    metadata={},
                    chunk_id=f"chunk_{i}_{j}",
                    relevance_score=0.5
                ) for j in range(50)],
                query=QueryInput(query=f"Query {i}", user_id="test")
            )
            
            # Force synchronous processing for memory test
            asyncio.run(synthesis_engine.synthesize(large_input))
            
        final_memory = process.memory_info().rss
        memory_growth = (final_memory - initial_memory) / (1024 * 1024)  # MB
        
        assert memory_growth < 500  # Less than 500MB growth
```

---

## ğŸ“Š **MONITORING & OBSERVABILITY**

### **Step 6: Production Monitoring Setup**

#### **Step 6.1: Metrics Collection**

```python
# File: src/synthesis/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, CollectorRegistry
from typing import Dict, Any
import time
import functools

class SynthesisMetrics:
    def __init__(self, registry: CollectorRegistry = None):
        self.registry = registry or CollectorRegistry()
        
        # Counter metrics
        self.synthesis_requests_total = Counter(
            'synthesis_requests_total',
            'Total number of synthesis requests',
            ['status', 'user_department', 'fallback_type'],
            registry=self.registry
        )
        
        # Histogram metrics  
        self.synthesis_duration = Histogram(
            'synthesis_duration_seconds',
            'Time spent on synthesis processing',
            ['stage'],
            registry=self.registry
        )
        
        self.context_documents_count = Histogram(
            'synthesis_context_documents_count',
            'Number of documents in context',
            registry=self.registry
        )
        
        self.prompt_tokens = Histogram(
            'synthesis_prompt_tokens',
            'Number of tokens in generated prompt',
            registry=self.registry
        )
        
        # Gauge metrics
        self.active_synthesis_requests = Gauge(
            'synthesis_active_requests',
            'Number of active synthesis requests',
            registry=self.registry
        )
        
    def record_request(self, status: str, department: str = "", fallback_type: str = ""):
        """Record synthesis request"""
        self.synthesis_requests_total.labels(
            status=status,
            user_department=department, 
            fallback_type=fallback_type
        ).inc()
        
    def record_duration(self, stage: str, duration: float):
        """Record processing duration"""
        self.synthesis_duration.labels(stage=stage).observe(duration)
        
    def record_context_size(self, document_count: int):
        """Record context size"""
        self.context_documents_count.observe(document_count)
        
    def record_prompt_tokens(self, token_count: int):
        """Record prompt token count"""  
        self.prompt_tokens.observe(token_count)

# Decorator for automatic metrics collection
def track_synthesis_metrics(metrics: SynthesisMetrics):
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            metrics.active_synthesis_requests.inc()
            
            try:
                result = await func(*args, **kwargs)
                duration = time.time() - start_time
                
                metrics.record_duration("total", duration)
                metrics.record_request("success")
                
                if hasattr(result, 'context_documents'):
                    metrics.record_context_size(len(result.context_documents))
                if hasattr(result, 'total_tokens'):
                    metrics.record_prompt_tokens(result.total_tokens)
                    
                return result
                
            except Exception as e:
                duration = time.time() - start_time
                metrics.record_duration("error", duration)
                metrics.record_request("error")
                raise
                
            finally:
                metrics.active_synthesis_requests.dec()
                
        return wrapper
    return decorator
```

#### **Step 6.2: Structured Logging**

```python
# File: src/synthesis/monitoring/logging.py
import structlog
import logging.config
from typing import Dict, Any, Optional
import json
from datetime import datetime

def configure_logging(log_level: str = "INFO", log_format: str = "json"):
    """Configure structured logging for synthesis module"""
    
    logging.config.dictConfig({
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "json": {
                "()": structlog.stdlib.ProcessorFormatter,
                "processor": structlog.dev.ConsoleRenderer(colors=False),
                "foreign_pre_chain": [
                    structlog.stdlib.add_log_level,
                    structlog.stdlib.add_logger_name,
                    structlog.stdlib.ExtraAdder(),
                    structlog.processors.TimeStamper(fmt="ISO"),
                ],
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json",
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "filename": "logs/synthesis.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
                "formatter": "json",
            },
        },
        "loggers": {
            "synthesis": {
                "handlers": ["console", "file"],
                "level": log_level,
                "propagate": False,
            },
        },
    })
    
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.stdlib.ProcessorFormatter.wrap_for_formatter,
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )

class SynthesisLogger:
    def __init__(self, component_name: str):
        self.logger = structlog.get_logger("synthesis").bind(component=component_name)
        
    def log_synthesis_start(self, query: str, user_id: str, document_count: int):
        """Log synthesis process start"""
        self.logger.info(
            "synthesis_started",
            query_length=len(query),
            user_id=user_id,
            document_count=document_count,
            timestamp=datetime.utcnow().isoformat()
        )
        
    def log_context_building(self, strategy: str, selected_docs: int, total_tokens: int):
        """Log context building details"""
        self.logger.info(
            "context_built",
            strategy=strategy,
            selected_documents=selected_docs,
            total_tokens=total_tokens
        )
        
    def log_template_processing(self, template_type: str, render_time: float):
        """Log template processing"""
        self.logger.info(
            "template_processed", 
            template_type=template_type,
            render_time_ms=render_time * 1000
        )
        
    def log_synthesis_complete(self, total_time: float, final_tokens: int, is_fallback: bool):
        """Log successful synthesis completion"""
        self.logger.info(
            "synthesis_completed",
            total_time_ms=total_time * 1000,
            final_tokens=final_tokens,
            is_fallback=is_fallback
        )
        
    def log_error(self, error_type: str, error_msg: str, context: Dict[str, Any] = None):
        """Log errors vá»›i context"""
        self.logger.error(
            "synthesis_error",
            error_type=error_type,
            error_message=error_msg,
            context=context or {}
        )
        
    def log_fallback_triggered(self, fallback_type: str, reason: str):
        """Log fallback mechanism activation"""
        self.logger.warning(
            "fallback_triggered",
            fallback_type=fallback_type,
            reason=reason
        )
```

#### **Step 6.3: Health Checks & Alerting**

```python
# File: src/synthesis/monitoring/health.py
from typing import Dict, List, Optional
import asyncio
import time
from enum import Enum
from dataclasses import dataclass

class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"  
    UNHEALTHY = "unhealthy"

@dataclass
class HealthCheck:
    name: str
    status: HealthStatus
    message: str
    duration_ms: float
    timestamp: str

class SynthesisHealthChecker:
    def __init__(self, synthesis_engine):
        self.synthesis_engine = synthesis_engine
        self.health_checks: List[HealthCheck] = []
        
    async def check_template_loading(self) -> HealthCheck:
        """Check if templates can be loaded"""
        start_time = time.time()
        
        try:
            template = self.synthesis_engine.template_manager.load_template(
                "system/vi/default"
            )
            
            if template:
                status = HealthStatus.HEALTHY
                message = "Templates loading successfully"
            else:
                status = HealthStatus.DEGRADED
                message = "Template loaded but empty"
                
        except Exception as e:
            status = HealthStatus.UNHEALTHY
            message = f"Template loading failed: {str(e)}"
            
        duration = (time.time() - start_time) * 1000
        
        return HealthCheck(
            name="template_loading",
            status=status,
            message=message,
            duration_ms=duration,
            timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
        )
        
    async def check_context_building(self) -> HealthCheck:
        """Check context building performance"""
        start_time = time.time()
        
        try:
            # Test vá»›i mock documents
            mock_docs = [
                DocumentInput(
                    content="Test document for health check",
                    metadata={"source": "health_check"},
                    chunk_id="health_check_1",
                    relevance_score=0.8
                )
            ]
            
            context_builder = self.synthesis_engine.context_builder
            selected = context_builder.select_documents(
                documents=mock_docs,
                query=QueryInput(query="health check", user_id="system"),
                max_tokens=1000
            )
            
            if selected:
                status = HealthStatus.HEALTHY
                message = f"Context building working, selected {len(selected)} documents"
            else:
                status = HealthStatus.DEGRADED  
                message = "Context building returned no documents"
                
        except Exception as e:
            status = HealthStatus.UNHEALTHY
            message = f"Context building failed: {str(e)}"
            
        duration = (time.time() - start_time) * 1000
        
        return HealthCheck(
            name="context_building",
            status=status,
            message=message, 
            duration_ms=duration,
            timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
        )
        
    async def check_overall_health(self) -> Dict[str, any]:
        """Run all health checks"""
        checks = await asyncio.gather(
            self.check_template_loading(),
            self.check_context_building(),
            return_exceptions=True
        )
        
        # Determine overall status
        statuses = [check.status for check in checks if isinstance(check, HealthCheck)]
        
        if HealthStatus.UNHEALTHY in statuses:
            overall_status = HealthStatus.UNHEALTHY
        elif HealthStatus.DEGRADED in statuses:
            overall_status = HealthStatus.DEGRADED
        else:
            overall_status = HealthStatus.HEALTHY
            
        return {
            "status": overall_status.value,
            "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
            "checks": [
                {
                    "name": check.name,
                    "status": check.status.value,
                    "message": check.message,
                    "duration_ms": check.duration_ms
                }
                for check in checks if isinstance(check, HealthCheck)
            ]
        }
```

---

## ğŸš€ **DEPLOYMENT & PRODUCTION SETUP**

### **Phase 6: Production Deployment (Week 6)**

#### **Step 6.1: Docker Configuration**

```dockerfile
# File: Dockerfile
FROM python:3.11-slim as builder

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy dependency files
COPY pyproject.toml poetry.lock ./

# Install poetry vÃ  dependencies
RUN pip install poetry==1.5.1 \
    && poetry config virtualenvs.create false \
    && poetry install --no-dev --no-interaction --no-ansi

# Production stage  
FROM python:3.11-slim as production

WORKDIR /app

# Copy installed packages from builder
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy application code
COPY src/ ./src/
COPY templates/ ./templates/
COPY config/ ./config/

# Create logs directory
RUN mkdir -p logs

# Create non-root user
RUN adduser --disabled-password --gecos '' synthesisuser \
    && chown -R synthesisuser:synthesisuser /app

USER synthesisuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Expose port
EXPOSE 8000

# Start application
CMD ["python", "-m", "uvicorn", "src.synthesis.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# File: docker-compose.yml
version: '3.8'

services:
  synthesis-service:
    build: .
    ports:
      - "8000:8000"
    environment:
      - SYNTHESIS_OPENAI_API_KEY=${OPENAI_API_KEY}
      - SYNTHESIS_MAX_TOKENS=4000
      - SYNTHESIS_CACHE_TTL=3600
      - REDIS_URL=redis://redis:6379
      - POSTGRES_URL=postgresql://user:pass@postgres:5432/synthesis
    depends_on:
      - redis
      - postgres
    volumes:
      - ./logs:/app/logs
      - ./config:/app/config
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=synthesis
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped
    
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
  prometheus_data:
  grafana_data:
```

#### **Step 6.2: Kubernetes Deployment**

```yaml
# File: k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: synthesis-service
  labels:
    app: synthesis-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: synthesis-service
  template:
    metadata:
      labels:
        app: synthesis-service
    spec:
      containers:
      - name: synthesis
        image: synthesis-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: SYNTHESIS_OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: synthesis-secrets
              key: openai-api-key
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        - name: POSTGRES_URL
          valueFrom:
            secretKeyRef:
              name: synthesis-secrets
              key: postgres-url
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: config
        configMap:
          name: synthesis-config
      - name: logs
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: synthesis-service
spec:
  selector:
    app: synthesis-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: synthesis-config
data:
  production.yaml: |
    max_tokens: 4000
    max_context_documents: 10
    similarity_threshold: 0.7
    cache_ttl: 3600
    request_timeout: 30
    max_retries: 3

---
apiVersion: v1
kind: Secret
metadata:
  name: synthesis-secrets
type: Opaque
data:
  openai-api-key: <base64-encoded-api-key>
  postgres-url: <base64-encoded-postgres-url>
```

#### **Step 6.3: Production Configuration & Environment Variables**

```python
# File: config/production.py
from src.synthesis.config.base import SynthesisConfig
import os

class ProductionConfig(SynthesisConfig):
    """Production configuration vá»›i security & performance optimizations"""
    
    # API Configuration
    openai_api_key: str = os.getenv("SYNTHESIS_OPENAI_API_KEY", "")
    anthropic_api_key: str = os.getenv("SYNTHESIS_ANTHROPIC_API_KEY", "")
    
    # Performance Settings
    max_tokens: int = int(os.getenv("SYNTHESIS_MAX_TOKENS", "4000"))
    max_context_documents: int = int(os.getenv("SYNTHESIS_MAX_CONTEXT_DOCS", "10"))
    max_concurrent_requests: int = int(os.getenv("SYNTHESIS_MAX_CONCURRENT", "100"))
    
    # Cache Configuration  
    redis_url: str = os.getenv("REDIS_URL", "redis://localhost:6379")
    cache_ttl: int = int(os.getenv("SYNTHESIS_CACHE_TTL", "3600"))
    
    # Database Configuration
    postgres_url: str = os.getenv("POSTGRES_URL", "")
    
    # Security Settings
    api_rate_limit: str = os.getenv("SYNTHESIS_RATE_LIMIT", "100/hour")
    cors_origins: list = os.getenv("SYNTHESIS_CORS_ORIGINS", "*").split(",")
    
    # Monitoring & Logging
    log_level: str = os.getenv("LOG_LEVEL", "INFO")
    metrics_enabled: bool = os.getenv("METRICS_ENABLED", "true").lower() == "true"
    
    # Health Check Configuration
    health_check_timeout: int = int(os.getenv("HEALTH_CHECK_TIMEOUT", "5"))
    
    class Config:
        env_file = ".env.production"
        case_sensitive = True
```

---

## ğŸ“š **DOCUMENTATION & HANDOVER**

### **Step 7: Complete Documentation Package**

#### **Step 7.1: API Documentation**

```python
# File: src/synthesis/api/main.py
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import structlog

app = FastAPI(
    title="RAG Synthesis Service",
    description="Context synthesis vÃ  prompt generation cho RAG system",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure properly in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class SynthesisRequest(BaseModel):
    """Request model cho synthesis endpoint"""
    documents: List[Dict[str, Any]]
    query: Dict[str, Any]
    options: Optional[Dict[str, Any]] = None
    
    class Config:
        schema_extra = {
            "example": {
                "documents": [
                    {
                        "content": "Python is a programming language...",
                        "metadata": {"source": "python_guide.pdf", "page": 1},
                        "chunk_id": "chunk_001",
                        "relevance_score": 0.95
                    }
                ],
                "query": {
                    "query": "What is Python programming language

PageIndex
---

## üß© 1. Hi·ªÉu c√°ch **LLM ƒë·ªçc ‚Äì chia ‚Äì l·∫≠p ch·ªâ m·ª•c t√†i li·ªáu**

- PageIndex cho th·∫•y c√°ch **t√°ch t√†i li·ªáu** th√†nh c√°c ƒë∆°n v·ªã nh·ªè (chunk/node) d·ª±a tr√™n **c·∫•u tr√∫c n·ªôi dung** ch·ª© kh√¥ng ph·∫£i c·∫Øt theo s·ªë token c·ªë ƒë·ªãnh.

- V·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n ho√° th√†nh MD, b·∫°n s·∫Ω h·ªçc ƒë∆∞·ª£c c√°ch:
  
  - D√πng heading (`#`, `##`, `###`) l√†m c√¢y m·ª•c l·ª•c.
  
  - T·∫°o metadata (title, heading path, section id).
  
  - Gi·ªØ ng·ªØ c·∫£nh ch∆∞∆°ng/m·ª•c khi ƒë∆∞a v√†o RAG.

üëâ ƒê√¢y l√† **core skill** khi x√¢y chatbot n·ªôi b·ªô: d·ªØ li·ªáu ph·∫£i chia nh·ªè nh∆∞ng v·∫´n ‚Äúhi·ªÉu‚Äù m·ªëi quan h·ªá n·ªôi dung.

---

## ‚öôÔ∏è 2. Tr·∫£i nghi·ªám c√°c k·ªπ thu·∫≠t **ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu cho RAG**

- PageIndex c√≥ pipeline:
  
  - detect TOC ‚Üí t·∫°o index tree ‚Üí t√≥m t·∫Øt node ‚Üí verify consistency.

- V·ªõi MD b·∫°n s·∫Ω kh√¥ng c·∫ßn detect TOC, nh∆∞ng b·∫°n s·∫Ω h·ªçc c√°ch:
  
  - Chu·∫©n ho√° text th√†nh vector-friendly format.
  
  - L∆∞u metadata (heading, file path, line number) ƒë·ªÉ tr·∫£ k·∫øt qu·∫£ c√≥ ng·ªØ c·∫£nh.
  
  - T·∫°o t√≥m t·∫Øt ng·∫Øn cho t·ª´ng node ƒë·ªÉ tƒÉng recall.

üëâ Gi√∫p b·∫°n hi·ªÉu r√µ **data preprocessing** l√† b∆∞·ªõc quy·∫øt ƒë·ªãnh ch·∫•t l∆∞·ª£ng RAG, kh√¥ng ch·ªâ embedding.

---

## üõ†Ô∏è 3. K·ªπ thu·∫≠t **tokenization & cost management**

- B·∫°n ƒë√£ th·∫•y v·∫•n ƒë·ªÅ v·ªõi `tiktoken`.

- B·∫°n s·∫Ω h·ªçc ƒë∆∞·ª£c:
  
  - C√°ch ∆∞·ªõc l∆∞·ª£ng token ƒë·ªÉ chia chunk h·ª£p l√Ω.
  
  - Gi·∫£m s·ªë l·∫ßn g·ªçi LLM b·∫±ng c√°ch batch / gom nhi·ªÅu ƒëo·∫°n.
  
  - Ch·ªçn model ph√π h·ª£p (JSON mode, chi ph√≠ th·∫•p).

üëâ R·∫•t quan tr·ªçng khi l√†m chatbot n·ªôi b·ªô tr√™n kho d·ªØ li·ªáu l·ªõn (t·ªëi ∆∞u chi ph√≠ & t·ªëc ƒë·ªô).

---

## üîå 4. T√≠ch h·ª£p **multi-model / multi-backend**

- PageIndex c√≥ th·ªÉ ch·∫°y v·ªõi nhi·ªÅu model (OpenAI, OpenRouter, Anthropic, Mistral).

- B·∫°n s·∫Ω h·ªçc c√°ch vi·∫øt code ƒë·ªÉ **kh√¥ng kh√≥a ch·∫∑t v√†o 1 vendor**:
  
  - S·ª≠ d·ª•ng `.env` cho API key & base URL.
  
  - T√°ch abstraction cho `ChatGPT_API_with_finish_reason`.
  
  - Fallback sang model kh√°c khi l·ªói.

üëâ ƒê√¢y l√† t∆∞ duy quan tr·ªçng khi x√¢y chatbot doanh nghi·ªáp (tr√°nh vendor lock-in).

---

## üìÇ 5. Qu·∫£n l√Ω **output structured data t·ª´ LLM**

- PageIndex bu·ªôc LLM tr·∫£ JSON, sau ƒë√≥ parse v√† build index tree.

- B·∫°n h·ªçc ƒë∆∞·ª£c c√°ch:
  
  - Y√™u c·∫ßu LLM tr·∫£ d·ªØ li·ªáu c√≥ c·∫•u tr√∫c.
  
  - X·ª≠ l√Ω khi JSON h·ªèng (retry, cleanup, guardrail).
  
  - D√πng structured output l√†m input cho pipeline ti·∫øp theo.

üëâ ƒê√¢y l√† k·ªπ nƒÉng c·∫ßn thi·∫øt n·∫øu b·∫°n mu·ªën chatbot kh√¥ng ch·ªâ ‚Äún√≥i chuy·ªán‚Äù m√† c√≤n ‚Äúh√†nh ƒë·ªông‚Äù tr√™n d·ªØ li·ªáu (tool use, agent).

---

## üîç 6. Ki·ªÉm th·ª≠ & ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng h·ªá th·ªëng

- PageIndex cho th·∫•y: n·∫øu kh√¥ng c√≥ TOC, pipeline s·∫Ω fallback ‚Üí k√©m ch√≠nh x√°c.

- B·∫°n s·∫Ω h·ªçc c√°ch:
  
  - ƒê·∫∑t ti√™u ch√≠ ƒë√°nh gi√° (ƒë·ªô ph·ªß n·ªôi dung, t√≠nh ch√≠nh x√°c, t·ªëc ƒë·ªô).
  
  - Log l·ªói & trace ƒë·ªÉ debug pipeline RAG.
  
  - So s√°nh output c·ªßa c√°c model kh√°c nhau.

üëâ ƒê√¢y ch√≠nh l√† **Evaluation & Monitoring** ‚Äì b·∫Øt bu·ªôc khi tri·ªÉn khai chatbot n·ªôi b·ªô.

---

# üéØ T√≥m l·∫°i

N·∫øu b·∫°n √°p d·ª•ng kinh nghi·ªám t·ª´ PageIndex v√†o chatbot n·ªôi b·ªô v·ªõi d·ªØ li·ªáu **ƒë√£ chu·∫©n MD**, b·∫°n s·∫Ω h·ªçc ƒë∆∞·ª£c:

1. **Indexing theo c·∫•u tr√∫c** thay v√¨ c·∫Øt token m√π qu√°ng.

2. **Data preprocessing cho RAG** (t√°ch ƒëo·∫°n, g·∫Øn metadata, t√≥m t·∫Øt node).

3. **Tokenization & cost management** ƒë·ªÉ t·ªëi ∆∞u chi ph√≠.

4. **Multi-model integration** (OpenAI, Anthropic, Mistral‚Ä¶).

5. **Structured output t·ª´ LLM** (JSON mode, guardrails).

6. **Evaluation & Monitoring** pipeline chatbot.

üëâ Nghƒ©a l√† b·∫°n s·∫Ω n·∫Øm ƒë∆∞·ª£c **to√†n b·ªô v√≤ng ƒë·ªùi d·ªØ li·ªáu trong RAG**: t·ª´ raw file ‚Üí index ‚Üí vector DB ‚Üí query ‚Üí tr·∫£ l·ªùi c√≥ ng·ªØ c·∫£nh.

---

B·∫°n c√≥ mu·ªën m√¨nh ph√°c th·∫£o lu√¥n **pipeline t·ªëi ∆∞u cho chatbot n·ªôi b·ªô d√πng MD files** (b·ªè TOC detection, thay b·∫±ng heading-based index) ƒë·ªÉ b·∫°n th·∫•y r√µ s·ª± kh√°c bi·ªát v·ªõi PageIndex kh√¥ng?

---
H·ªçc t·ª´ FlashRAG
**FlashRAG** l√† m·ªôt b·ªô c√¥ng c·ª• nghi√™n c·ª©u RAG (Retrieval-Augmented Generation) ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω t√†i li·ªáu m·ªôt c√°ch linh ho·∫°t, h·ªó tr·ª£ nhi·ªÅu lo·∫°i d·ªØ li·ªáu v√† t√°c v·ª• kh√°c nhau. D·ª±a tr√™n t√†i li·ªáu b·∫°n cung c·∫•p v√† th√¥ng tin v·ªÅ FlashRAG, d∆∞·ªõi ƒë√¢y l√† ph√¢n t√≠ch chi ti·∫øt v·ªÅ c√°c k·ªπ thu·∫≠t x·ª≠ l√Ω t√†i li·ªáu m√† FlashRAG s·ª≠ d·ª•ng, ƒë·∫∑c bi·ªát t·∫≠p trung v√†o c√°ch n√≥ chu·∫©n b·ªã, ph√¢n ƒëo·∫°n, t·∫°o ch·ªâ m·ª•c, v√† tinh ch·ªânh t√†i li·ªáu ƒë·ªÉ h·ªó tr·ª£ 17 thu·∫≠t to√°n RAG v√† c√°c t√°c v·ª• ƒëa d·∫°ng (nh∆∞ QA, multi-hop QA, fact verification).

---

### **1. T·ªïng quan v·ªÅ x·ª≠ l√Ω t√†i li·ªáu trong FlashRAG**

FlashRAG x·ª≠ l√Ω t√†i li·ªáu theo m·ªôt quy tr√¨nh c√≥ h·ªá th·ªëng, bao g·ªìm c√°c b∆∞·ªõc t·ª´ nh·∫≠p li·ªáu (ingestion), ph√¢n ƒëo·∫°n (chunking), t·∫°o ch·ªâ m·ª•c (indexing), ƒë·∫øn tinh ch·ªânh ng·ªØ c·∫£nh (context refinement). C√°c k·ªπ thu·∫≠t n√†y ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·ªÉ:
- **H·ªó tr·ª£ ƒëa d·∫°ng t√†i li·ªáu**: T·ª´ Wikipedia, MS MARCO, ƒë·∫øn c√°c t√†i li·ªáu t√πy ch·ªânh nh∆∞ quy ch·∫ø, quy ƒë·ªãnh.
- **TƒÉng hi·ªáu qu·∫£ t√¨m ki·∫øm**: K·∫øt h·ª£p c·∫£ t√¨m ki·∫øm ng·ªØ nghƒ©a (dense retrieval) v√† t·ª´ kh√≥a (sparse retrieval).
- **T∆∞∆°ng th√≠ch v·ªõi nhi·ªÅu thu·∫≠t to√°n RAG**: T·ª´ ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n (Standard RAG) ƒë·∫øn ph·ª©c t·∫°p (R1-Searcher, IRCoT).
- **D·ªÖ d√†ng t√°i hi·ªán v√† m·ªü r·ªông**: Cung c·∫•p c√°c c√¥ng c·ª• nh∆∞ **Chunkie**, **index_builder**, v√† **FlashRAG-UI** ƒë·ªÉ x·ª≠ l√Ω linh ho·∫°t.

D∆∞·ªõi ƒë√¢y l√† c√°c k·ªπ thu·∫≠t ch√≠nh m√† FlashRAG s·ª≠ d·ª•ng ƒë·ªÉ x·ª≠ l√Ω t√†i li·ªáu:

---

### **2. C√°c k·ªπ thu·∫≠t x·ª≠ l√Ω t√†i li·ªáu c·ªßa FlashRAG**

#### **a. Chu·∫©n h√≥a d·ªØ li·ªáu (Data Standardization)**
- **ƒê·ªãnh d·∫°ng JSONL**:
  - FlashRAG s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng **JSON Lines (JSONL)** ƒë·ªÉ l∆∞u tr·ªØ c·∫£ **corpus** (t·∫≠p t√†i li·ªáu) v√† **datasets** (t·∫≠p truy v·∫•n). C·∫•u tr√∫c n√†y ƒë∆°n gi·∫£n v√† linh ho·∫°t, ph√π h·ª£p v·ªõi m·ªçi lo·∫°i t√†i li·ªáu:
    - **Corpus**:
      ```json
      {"id": "0", "contents": "N·ªôi dung t√†i li·ªáu..."}
      ```
    - **Dataset**:
      ```json
      {"id": "query_1", "question": "C√¢u h·ªèi...", "golden_answers": ["C√¢u tr·∫£ l·ªùi..."], "metadata": {...}}
      ```
  - **L·ª£i √≠ch**:
    - ƒê·ªãnh d·∫°ng JSONL d·ªÖ ƒë·ªçc, d·ªÖ x·ª≠ l√Ω, v√† t∆∞∆°ng th√≠ch v·ªõi nhi·ªÅu c√¥ng c·ª• (nh∆∞ pandas, Hugging Face Datasets).
    - Cho ph√©p th√™m metadata t√πy ch·ªânh (nh∆∞ `regulation_type`, `effective_date` cho t√†i li·ªáu quy ch·∫ø) m√† kh√¥ng ph√° v·ª° c·∫•u tr√∫c.
  - **·ª®ng d·ª•ng ƒëa nƒÉng**:
    - FlashRAG h·ªó tr·ª£ 36 b·ªô d·ªØ li·ªáu (Natural Questions, HotpotQA, v.v.), ch·ª©ng minh kh·∫£ nƒÉng x·ª≠ l√Ω c√°c lo·∫°i t√†i li·ªáu t·ª´ b√†i vi·∫øt Wikipedia ƒë·∫øn t√†i li·ªáu ph√°p l√Ω ho·∫∑c k·ªπ thu·∫≠t.

- **X·ª≠ l√Ω tr∆∞·ªõc (Preprocessing)**:
  - FlashRAG cung c·∫•p c√°c script ƒë·ªÉ x·ª≠ l√Ω tr∆∞·ªõc t√†i li·ªáu, v√≠ d·ª• nh∆∞ chuy·ªÉn ƒë·ªïi Wikipedia dump th√†nh ƒë·ªãnh d·∫°ng JSONL:
    ```bash
    python -m flashrag.dataset.preprocess_wiki --wiki_dump_path wiki_dump.xml --output_path wiki_corpus.jsonl
    ```
  - C√°c b∆∞·ªõc x·ª≠ l√Ω tr∆∞·ªõc bao g·ªìm:
    - **Lo·∫°i b·ªè ƒë·ªãnh d·∫°ng kh√¥ng c·∫ßn thi·∫øt**: X√≥a c√°c th·∫ª HTML, k√Ω t·ª± ƒë·∫∑c bi·ªát.
    - **Chu·∫©n h√≥a vƒÉn b·∫£n**: Chuy·ªÉn ƒë·ªïi v·ªÅ ƒë·ªãnh d·∫°ng UTF-8, lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a.
    - **T√°ch n·ªôi dung**: Chia t√†i li·ªáu th√†nh c√°c ƒëo·∫°n (paragraphs) ho·∫∑c m·ª•c (sections) n·∫øu c·∫ßn.

#### **b. Ph√¢n ƒëo·∫°n t√†i li·ªáu (Document Chunking)**
- **Th∆∞ vi·ªán Chunkie**:
  - FlashRAG s·ª≠ d·ª•ng **Chunkie**, m·ªôt th∆∞ vi·ªán ph√¢n ƒëo·∫°n t√†i li·ªáu linh ho·∫°t, ƒë·ªÉ chia t√†i li·ªáu th√†nh c√°c ƒëo·∫°n nh·ªè (chunks) ph√π h·ª£p v·ªõi t√¨m ki·∫øm v√† sinh ph·∫£n h·ªìi.
  - C√°c ph∆∞∆°ng ph√°p ph√¢n ƒëo·∫°n:
    - **Token-based**: Chia theo s·ªë token c·ªë ƒë·ªãnh (v√≠ d·ª•: 512 token m·ªói chunk).
    - **Sentence-based**: Chia theo c√¢u ƒë·ªÉ gi·ªØ ng·ªØ c·∫£nh ho√†n ch·ªânh.
    - **Semantic-based**: Chia theo √Ω nghƒ©a ng·ªØ nghƒ©a, s·ª≠ d·ª•ng c√°c m√¥ h√¨nh nh∆∞ sentence-transformers ƒë·ªÉ x√°c ƒë·ªãnh ranh gi·ªõi ng·ªØ nghƒ©a.
  - **Tham s·ªë t√πy ch·ªânh**:
    - `max_chunk_size`: Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc m·ªói chunk (v√≠ d·ª•: 300 token).
    - `overlap_size`: ƒê·ªô ch·ªìng l·∫•n gi·ªØa c√°c chunk (v√≠ d·ª•: 30 token) ƒë·ªÉ gi·ªØ ng·ªØ c·∫£nh li√™n t·ª•c.
  - **V√≠ d·ª• s·ª≠ d·ª•ng Chunkie**:
    ```python
    from flashrag.utils import Chunkie

    def chunk_document(content: str, method: str = "semantic", max_size: int = 300, overlap: int = 30):
        chunker = Chunkie(method=method, max_size=max_size, overlap=overlap)
        chunks = chunker.chunk(content)
        return chunks
    ```
- **·ª®ng d·ª•ng v·ªõi t√†i li·ªáu quy ch·∫ø**:
  - T√†i li·ªáu quy ch·∫ø th∆∞·ªùng c√≥ c·∫•u tr√∫c ph·ª©c t·∫°p (ƒëi·ªÅu kho·∫£n, ti·ªÉu m·ª•c). **Chunkie** c√≥ th·ªÉ chia c√°c ƒëi·ªÅu kho·∫£n th√†nh c√°c ƒëo·∫°n nh·ªè theo ng·ªØ nghƒ©a, ƒë·∫£m b·∫£o m·ªói chunk ch·ª©a m·ªôt √Ω nghƒ©a ho√†n ch·ªânh (v√≠ d·ª•: m·ªôt ƒëi·ªÅu kho·∫£n GDPR v·ªÅ b·∫£o v·ªá d·ªØ li·ªáu).
  - ƒê·ªô ch·ªìng l·∫•n (overlap) gi√∫p gi·ªØ ng·ªØ c·∫£nh khi c√°c ƒëi·ªÅu kho·∫£n c√≥ tham chi·∫øu ch√©o.

#### **c. T·∫°o ch·ªâ m·ª•c (Index Creation)**
- **Ch·ªâ m·ª•c FAISS (Dense Retrieval)**:
  - FlashRAG s·ª≠ d·ª•ng **Faiss** ƒë·ªÉ t·∫°o ch·ªâ m·ª•c vector cho t√¨m ki·∫øm ng·ªØ nghƒ©a:
    - **M√¥ h√¨nh embedding**: E5, BGE, DPR (d·ª±a tr√™n sentence-transformers).
    - **Lo·∫°i ch·ªâ m·ª•c**: H·ªó tr·ª£ **Flat** (ƒë·ªô ch√≠nh x√°c cao) ho·∫∑c **HNSW** (t·ªëi ∆∞u t·ªëc ƒë·ªô).
    - **Tham s·ªë c·∫•u h√¨nh**: `max_length` (ƒë·ªô d√†i t·ªëi ƒëa c·ªßa vƒÉn b·∫£n), `batch_size` (x·ª≠ l√Ω h√†ng lo·∫°t), `use_fp16` (tƒÉng t·ªëc tr√™n GPU).
  - Script t·∫°o ch·ªâ m·ª•c:
    ```bash
    python -m flashrag.retriever.index_builder \
        --retrieval_method e5 \
        --model_path /model/e5-base-v2/ \
        --corpus_path corpus.jsonl \
        --save_dir indexes/ \
        --use_fp16 \
        --max_length 512 \
        --batch_size 256 \
        --pooling_method mean \
        --faiss_type HNSW
    ```
  - **Ch·ªâ m·ª•c x·ª≠ l√Ω s·∫µn**: FlashRAG cung c·∫•p c√°c ch·ªâ m·ª•c nh∆∞ `wiki18_100w_e5_index` tr√™n ModelScope, gi√∫p ti·∫øt ki·ªám th·ªùi gian x·ª≠ l√Ω tr∆∞·ªõc.

- **Ch·ªâ m·ª•c BM25s/Pyserini (Sparse Retrieval)**:
  - S·ª≠ d·ª•ng **BM25s** (nh·∫π, d·ªÖ c√†i ƒë·∫∑t) ho·∫∑c **Pyserini** (d·ª±a tr√™n Lucene) ƒë·ªÉ t·∫°o ch·ªâ m·ª•c ng∆∞·ª£c (inverted index) cho t√¨m ki·∫øm d·ª±a tr√™n t·ª´ kh√≥a.
  - **BM25s** l√† l·ª±a ch·ªçn m·∫∑c ƒë·ªãnh, ph√π h·ª£p v·ªõi c√°c truy v·∫•n y√™u c·∫ßu kh·ªõp t·ª´ kh√≥a ch√≠nh x√°c (nh∆∞ t√¨m s·ªë ƒëi·ªÅu kho·∫£n trong quy ch·∫ø).
  - V√≠ d·ª•:
    ```bash
    python -m flashrag.retriever.index_builder \
        --retrieval_method bm25 \
        --bm25_backend bm25s \
        --corpus_path corpus.jsonl \
        --save_dir indexes/
    ```

- **Multi-retriever Aggregation** (t·ª´ 07/01/25):
  - K·∫øt h·ª£p c·∫£ **dense** v√† **sparse retrieval** ƒë·ªÉ tƒÉng ƒë·ªô bao ph·ªß:
    - Dense retrieval (Faiss) t√¨m ki·∫øm theo ng·ªØ nghƒ©a.
    - Sparse retrieval (BM25s) t√¨m ki·∫øm theo t·ª´ kh√≥a.
    - K·∫øt qu·∫£ ƒë∆∞·ª£c t·ªïng h·ª£p v√† x·∫øp h·∫°ng l·∫°i ƒë·ªÉ ch·ªçn t√†i li·ªáu ph√π h·ª£p nh·∫•t.
  - V√≠ d·ª•:
    ```python
    from flashrag.retriever import DenseRetriever, BM25Retriever

    def hybrid_search(query: str, collection: str, top_k: int = 5):
        dense_retriever = DenseRetriever(retrieval_method="e5")
        sparse_retriever = BM25Retriever(bm25_backend="bm25s")
        dense_results = dense_retriever.search(query, collection=collection, top_k=top_k)
        sparse_results = sparse_retriever.search(query, collection=collection, top_k=top_k)
        combined_results = aggregate_results(dense_results, sparse_results)
        return combined_results
    ```

#### **d. Tinh ch·ªânh ng·ªØ c·∫£nh (Context Refinement)**
- **Refiner**:
  - FlashRAG cung c·∫•p c√°c c√¥ng c·ª• tinh ch·ªânh ng·ªØ c·∫£nh ƒë·ªÉ lo·∫°i b·ªè th√¥ng tin kh√¥ng li√™n quan v√† c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ƒë·∫ßu v√†o cho LLM:
    - **LongLLMLingua**: N√©n ng·ªØ c·∫£nh b·∫±ng c√°ch lo·∫°i b·ªè c√°c token kh√¥ng quan tr·ªçng, gi·ªØ l·∫°i th√¥ng tin c·ªët l√µi (t·ª∑ l·ªá n√©n c√≥ th·ªÉ t√πy ch·ªânh, v√≠ d·ª•: 0.5).
    - **Selective-Context**: Ch·ªçn l·ªçc c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan nh·∫•t d·ª±a tr√™n ng·ªØ nghƒ©a.
    - **Trace**: X√¢y d·ª±ng ƒë·ªì th·ªã tri th·ª©c (knowledge graph) ƒë·ªÉ li√™n k·∫øt c√°c ƒëo·∫°n t√†i li·ªáu, ƒë·∫∑c bi·ªát h·ªØu √≠ch cho t√†i li·ªáu quy ch·∫ø c√≥ tham chi·∫øu ch√©o.
  - **V√≠ d·ª• s·ª≠ d·ª•ng LongLLMLingua**:
    ```python
    from flashrag.refiner import LongLLMLinguaRefiner

    def refine_context(documents: list, compress_ratio: float = 0.5):
        refiner = LongLLMLinguaRefiner(compress_ratio=compress_ratio)
        refined_docs = refiner.refine(documents)
        return refined_docs
    ```
- **·ª®ng d·ª•ng v·ªõi quy ch·∫ø**:
  - **LongLLMLingua** c√≥ th·ªÉ n√©n m·ªôt ƒëi·ªÅu kho·∫£n d√†i th√†nh c√°c c√¢u ng·∫Øn g·ªçn, t·∫≠p trung v√†o n·ªôi dung ch√≠nh (v√≠ d·ª•: "Quy ƒë·ªãnh v·ªÅ b·∫£o v·ªá d·ªØ li·ªáu" ƒë∆∞·ª£c n√©n c√≤n c√°c ƒëi·ªÉm ch√≠nh nh∆∞ "y√™u c·∫ßu ƒë·ªìng √Ω", "x·ª≠ l√Ω vi ph·∫°m").
  - **Trace** t·∫°o ƒë·ªì th·ªã tri th·ª©c ƒë·ªÉ li√™n k·∫øt c√°c ƒëi·ªÅu kho·∫£n li√™n quan (v√≠ d·ª•: ƒêi·ªÅu 5 GDPR tham chi·∫øu ƒë·∫øn ƒêi·ªÅu 7), gi√∫p x·ª≠ l√Ω c√°c truy v·∫•n multi-hop.

#### **e. T√≠ch h·ª£p v·ªõi Pipeline RAG**
- FlashRAG t·ªï ch·ª©c x·ª≠ l√Ω t√†i li·ªáu trong c√°c **pipeline** (Sequential, Conditional, Branching, Loop, Reasoning) ƒë·ªÉ h·ªó tr·ª£ 17 thu·∫≠t to√°n RAG:
  - **Sequential**: X·ª≠ l√Ω t√†i li·ªáu m·ªôt l·∫ßn (Standard RAG, Spring).
  - **Conditional**: Ch·ªçn collection ho·∫∑c ph∆∞∆°ng ph√°p d·ª±a tr√™n lo·∫°i truy v·∫•n (SKR, Adaptive-RAG).
  - **Branching**: T√¨m ki·∫øm song song t·ª´ nhi·ªÅu ngu·ªìn v√† t·ªïng h·ª£p (SuRe, REPLUG).
  - **Loop**: L·∫∑p l·∫°i t√¨m ki·∫øm v√† tinh ch·ªânh (Ret-Robust, IRCoT, RQRAG).
  - **Reasoning**: K·∫øt h·ª£p suy lu·∫≠n (R1-Searcher).
- **T√≠ch h·ª£p v·ªõi t√†i li·ªáu**:
  - M·ªói pipeline s·ª≠ d·ª•ng c√πng ƒë·ªãnh d·∫°ng JSONL v√† ch·ªâ m·ª•c FAISS/BM25s, ƒë·∫£m b·∫£o x·ª≠ l√Ω t√†i li·ªáu ƒë·ªìng nh·∫•t.
  - C√°c pipeline nh∆∞ **R1-Searcher** ho·∫∑c **IRCoT** t·∫≠n d·ª•ng **Trace** ƒë·ªÉ x·ª≠ l√Ω c√°c t√†i li·ªáu c√≥ m·ªëi quan h·ªá ph·ª©c t·∫°p, nh∆∞ quy ch·∫ø.

#### **f. T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t**
- **TƒÉng t·ªëc suy lu·∫≠n**:
  - S·ª≠ d·ª•ng **vLLM** v√† **FastChat** ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô t·∫°o embeddings v√† suy lu·∫≠n LLM.
  - V√≠ d·ª•:
    ```python
    from vllm import LLM

    llm = LLM(model="qwen2.5-7b", gpu_memory_utilization=0.9)
    embeddings = llm.generate_embeddings(texts)
    ```
- **T·ªëi ∆∞u ch·ªâ m·ª•c**:
  - Ch·ªâ m·ª•c **HNSW** c·ªßa Faiss gi·∫£m ƒë·ªô tr·ªÖ t√¨m ki·∫øm so v·ªõi **Flat**.
  - **BM25s** nh·∫π h∆°n Pyserini, ph√π h·ª£p v·ªõi c√°c h·ªá th·ªëng c√≥ t√†i nguy√™n h·∫°n ch·∫ø.
- **X·ª≠ l√Ω h√†ng lo·∫°t**:
  - FlashRAG h·ªó tr·ª£ x·ª≠ l√Ω h√†ng lo·∫°t (batch processing) khi t·∫°o embeddings ho·∫∑c ch·ªâ m·ª•c, gi·∫£m th·ªùi gian x·ª≠ l√Ω tr∆∞·ªõc:
    ```bash
    python -m flashrag.retriever.index_builder \
        --batch_size 256 \
        --corpus_path large_corpus.jsonl
    ```

#### **g. FlashRAG-UI**
- **Giao di·ªán ng∆∞·ªùi d√πng**:
  - FlashRAG-UI cho ph√©p c·∫•u h√¨nh pipeline, retriever, v√† collection, gi√∫p d·ªÖ d√†ng th·ª≠ nghi·ªám x·ª≠ l√Ω t√†i li·ªáu m√† kh√¥ng c·∫ßn thay ƒë·ªïi m√£ ngu·ªìn.
  - H·ªó tr·ª£ t·∫£i corpus, ch·ªâ m·ª•c, v√† ch·∫°y c√°c ph∆∞∆°ng ph√°p RAG, r·∫•t h·ªØu √≠ch khi x·ª≠ l√Ω c√°c lo·∫°i t√†i li·ªáu m·ªõi (nh∆∞ quy ch·∫ø).

---

### **3. ·ª®ng d·ª•ng v·ªõi t√†i li·ªáu quy ch·∫ø, quy ƒë·ªãnh**

D·ª±a tr√™n c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ vi·ªác m·ªü r·ªông h·ªá th·ªëng ƒë·ªÉ x·ª≠ l√Ω t√†i li·ªáu quy ch·∫ø, d∆∞·ªõi ƒë√¢y l√† c√°ch c√°c k·ªπ thu·∫≠t c·ªßa FlashRAG c√≥ th·ªÉ ƒë∆∞·ª£c √°p d·ª•ng:

- **Chu·∫©n h√≥a d·ªØ li·ªáu**:
  - Chuy·ªÉn ƒë·ªïi t√†i li·ªáu quy ch·∫ø (PDF, DOCX) th√†nh JSONL v·ªõi c√°c tr∆∞·ªùng metadata nh∆∞ `regulation_type`, `effective_date`, `clause_number`:
    ```json
    {"id": "REG_COMPL_001", "contents": "ƒêi·ªÅu 5 GDPR: Nguy√™n t·∫Øc b·∫£o v·ªá d·ªØ li·ªáu...", "metadata": {"regulation_type": "legal", "effective_date": "2025-01-01"}}
    ```
- **Ph√¢n ƒëo·∫°n v·ªõi Chunkie**:
  - S·ª≠ d·ª•ng **semantic-based chunking** ƒë·ªÉ chia c√°c ƒëi·ªÅu kho·∫£n th√†nh c√°c ƒëo·∫°n c√≥ √Ω nghƒ©a:
    ```python
    chunker = Chunkie(method="semantic", max_size=300, overlap=30)
    chunks = chunker.chunk(regulation_text)
    ```
- **T·∫°o ch·ªâ m·ª•c**:
  - T·∫°o ch·ªâ m·ª•c FAISS cho t√¨m ki·∫øm ng·ªØ nghƒ©a:
    ```bash
    python -m flashrag.retriever.index_builder \
        --retrieval_method e5 \
        --corpus_path regulations_compliance.jsonl \
        --save_dir indexes/
    ```
  - T·∫°o ch·ªâ m·ª•c BM25s cho t√¨m ki·∫øm t·ª´ kh√≥a (nh∆∞ "ƒêi·ªÅu 5 GDPR"):
    ```bash
    python -m flashrag.retriever.index_builder \
        --retrieval_method bm25 \
        --corpus_path regulations_compliance.jsonl \
        --save_dir indexes/
    ```
- **Tinh ch·ªânh ng·ªØ c·∫£nh**:
  - S·ª≠ d·ª•ng **Trace** ƒë·ªÉ x√¢y d·ª±ng ƒë·ªì th·ªã tri th·ª©c, li√™n k·∫øt c√°c ƒëi·ªÅu kho·∫£n:
    ```python
    from flashrag.refiner import TraceRefiner

    refiner = TraceRefiner()
    knowledge_graph = refiner.build_knowledge_graph(regulation_documents)
    ```
  - S·ª≠ d·ª•ng **LongLLMLingua** ƒë·ªÉ n√©n c√°c ƒëi·ªÅu kho·∫£n d√†i:
    ```python
    refiner = LongLLMLinguaRefiner(compress_ratio=0.5)
    refined_context = refiner.refine(regulation_documents)
    ```
- **T√≠ch h·ª£p pipeline**:
  - S·ª≠ d·ª•ng **R1-Searcher** ho·∫∑c **IRCoT** ƒë·ªÉ x·ª≠ l√Ω c√°c truy v·∫•n multi-hop:
    ```python
    from flashrag.pipeline import ReasoningPipeline

    config_dict = {
        "pipeline": "reasoning",
        "method": "r1_searcher",
        "retrieval_method": "e5",
        "collection": "regulations_compliance"
    }
    pipeline = ReasoningPipeline(Config(config_dict=config_dict))
    results = pipeline.run({"question": "Quy ƒë·ªãnh n√†o √°p d·ª•ng cho vi ph·∫°m GDPR?"})
    ```

---

### **4. So s√°nh v·ªõi thi·∫øt k·∫ø c·ªßa b·∫°n**

D·ª±a tr√™n thi·∫øt k·∫ø **Data Ingestion Tool** (`architectManageDB.md`) v√† **Enterprise Chatbot System** (`hdsd.md`), h·ªá th·ªëng c·ªßa b·∫°n c√≥ c√°c ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng v√† kh√°c bi·ªát v·ªõi FlashRAG:

#### **a. T∆∞∆°ng ƒë·ªìng**
- **Chu·∫©n h√≥a d·ªØ li·ªáu**:
  - B·∫°n s·ª≠ d·ª•ng JSON-like metadata trong PostgreSQL, t∆∞∆°ng t·ª± JSONL c·ªßa FlashRAG. C√≥ th·ªÉ √°nh x·∫° metadata c·ªßa b·∫°n sang ƒë·ªãnh d·∫°ng JSONL ƒë·ªÉ s·ª≠ d·ª•ng v·ªõi FlashRAG.
- **Ph√¢n ƒëo·∫°n t√†i li·ªáu**:
  - **Content Chunker** c·ªßa b·∫°n (smart splitting, size control, context keep) t∆∞∆°ng t·ª± **Chunkie** c·ªßa FlashRAG. B·∫°n c√≥ th·ªÉ t√≠ch h·ª£p Chunkie ƒë·ªÉ tƒÉng t√≠nh linh ho·∫°t.
- **Ch·ªâ m·ª•c FAISS**:
  - C·∫£ hai h·ªá th·ªëng s·ª≠ d·ª•ng FAISS cho dense retrieval, ƒë·∫£m b·∫£o kh·∫£ nƒÉng t√≠ch h·ª£p d·ªÖ d√†ng.
- **Tinh ch·ªânh ng·ªØ c·∫£nh**:
  - **Quality Control** c·ªßa b·∫°n (content validation, duplicate detection) c√≥ th·ªÉ ƒë∆∞·ª£c b·ªï sung b·∫±ng **LongLLMLingua** ho·∫∑c **Selective-Context** c·ªßa FlashRAG.

#### **b. Kh√°c bi·ªát**
- **Sparse Retrieval**:
  - FlashRAG h·ªó tr·ª£ **BM25s/Pyserini** cho t√¨m ki·∫øm t·ª´ kh√≥a, trong khi b·∫°n ch·ªâ s·ª≠ d·ª•ng FAISS. ƒêi·ªÅu n√†y r·∫•t h·ªØu √≠ch cho t√†i li·ªáu quy ch·∫ø, n∆°i ng∆∞·ªùi d√πng th∆∞·ªùng t√¨m ki·∫øm theo s·ªë ƒëi·ªÅu kho·∫£n ho·∫∑c t·ª´ kh√≥a c·ª• th·ªÉ.
- **Pipeline ƒëa d·∫°ng**:
  - FlashRAG c√≥ 17 thu·∫≠t to√°n RAG v·ªõi c√°c pipeline nh∆∞ Loop v√† Reasoning, ph√π h·ª£p h∆°n cho c√°c truy v·∫•n ph·ª©c t·∫°p (nh∆∞ multi-hop QA trong quy ch·∫ø). H·ªá th·ªëng c·ªßa b·∫°n hi·ªán ch·ªâ h·ªó tr·ª£ t√¨m ki·∫øm c∆° b·∫£n d·ª±a tr√™n intent.
- **Tinh ch·ªânh ng·ªØ c·∫£nh**:
  - FlashRAG c√≥ c√°c c√¥ng c·ª• chuy√™n d·ª•ng nh∆∞ **Trace** (ƒë·ªì th·ªã tri th·ª©c) v√† **LongLLMLingua** (n√©n ng·ªØ c·∫£nh), trong khi b·∫°n d·ª±a v√†o **Quality Control** v√† **Metadata Engine**. B·∫°n c√≥ th·ªÉ t√≠ch h·ª£p c√°c refiner n√†y ƒë·ªÉ c·∫£i thi·ªán x·ª≠ l√Ω quy ch·∫ø.
- **C∆° s·ªü d·ªØ li·ªáu**:
  - B·∫°n s·ª≠ d·ª•ng **PostgreSQL** v√† **Redis**, trong khi FlashRAG ch·ªâ d√πng t·ªáp JSONL v√† ch·ªâ m·ª•c tr√™n ƒëƒ©a. B·∫°n c·∫ßn vi·∫øt adapter ƒë·ªÉ √°nh x·∫° d·ªØ li·ªáu t·ª´ JSONL sang PostgreSQL.

#### **c. C√°ch t√≠ch h·ª£p FlashRAG v√†o h·ªá th·ªëng c·ªßa b·∫°n**
ƒê·ªÉ h·ªó tr·ª£ t√†i li·ªáu quy ch·∫ø m√† kh√¥ng c·∫ßn l√†m l·∫°i c∆° s·ªü d·ªØ li·ªáu ho·∫∑c ch·ªâ m·ª•c, b·∫°n c√≥ th·ªÉ:
1. **Chu·∫©n h√≥a t√†i li·ªáu quy ch·∫ø**:
   - Chuy·ªÉn ƒë·ªïi t√†i li·ªáu quy ch·∫ø th√†nh JSONL:
     ```python
     def convert_regulation_to_jsonl(document: dict, output_file: str):
         with open(output_file, 'w', encoding='utf-8') as f:
             json.dump({"id": document["doc_id"], "contents": document["content"], "metadata": document}, f)
             f.write('\n')
     ```
2. **Ph√¢n ƒëo·∫°n v·ªõi Chunkie**:
   - T√≠ch h·ª£p **Chunkie** v√†o `content_processor.py`:
     ```python
     from flashrag.utils import Chunkie

     def process_content(content: str, collection: str):
         chunker = Chunkie(method="semantic", max_size=300, overlap=30)
         chunks = chunker.chunk(content)
         return [{"id": f"{collection}_{i}", "contents": chunk} for i, chunk in enumerate(chunks)]
     ```
3. **T·∫°o ch·ªâ m·ª•c**:
   - S·ª≠ d·ª•ng `index_builder` c·ªßa FlashRAG ƒë·ªÉ t·∫°o ch·ªâ m·ª•c FAISS v√† BM25s cho collection `regulations_compliance`.
4. **Tinh ch·ªânh ng·ªØ c·∫£nh**:
   - T√≠ch h·ª£p **Trace** ho·∫∑c **LongLLMLingua** v√†o `metadata_engine.py` ƒë·ªÉ x·ª≠ l√Ω tham chi·∫øu ch√©o ho·∫∑c n√©n ng·ªØ c·∫£nh:
     ```python
     from flashrag.refiner import TraceRefiner

     def enrich_metadata(documents):
         refiner = TraceRefiner()
         knowledge_graph = refiner.build_knowledge_graph(documents)
         return knowledge_graph
     ```
5. **T√≠ch h·ª£p pipeline RAG**:
   - S·ª≠ d·ª•ng **R1-Searcher** ho·∫∑c **IRCoT** trong `faiss_manager.py` ƒë·ªÉ x·ª≠ l√Ω c√°c truy v·∫•n ph·ª©c t·∫°p:
     ```python
     from flashrag.pipeline import ReasoningPipeline

     def search_regulation(query: str, collection: str):
         config_dict = {
             "pipeline": "reasoning",
             "method": "r1_searcher",
             "retrieval_method": "e5",
             "collection": collection
         }
         pipeline = ReasoningPipeline(Config(config_dict=config_dict))
         results = pipeline.run({"question": query})
         return results
     ```

---

### **5. K·∫øt lu·∫≠n**

**FlashRAG** s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t x·ª≠ l√Ω t√†i li·ªáu ti√™n ti·∫øn ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh ƒëa nƒÉng:
- **Chu·∫©n h√≥a JSONL**: ƒê·ªãnh d·∫°ng linh ho·∫°t, d·ªÖ m·ªü r·ªông.
- **Chunkie**: Ph√¢n ƒëo·∫°n th√¥ng minh theo token, c√¢u, ho·∫∑c ng·ªØ nghƒ©a.
- **FAISS/BM25s**: H·ªó tr·ª£ c·∫£ t√¨m ki·∫øm ng·ªØ nghƒ©a v√† t·ª´ kh√≥a.
- **Refiner**: **LongLLMLingua**, **Selective-Context**, v√† **Trace** ƒë·ªÉ n√©n v√† tinh ch·ªânh ng·ªØ c·∫£nh.
- **Pipeline linh ho·∫°t**: 17 thu·∫≠t to√°n RAG (Sequential, Conditional, Loop, Reasoning) ƒë·ªÉ x·ª≠ l√Ω c√°c lo·∫°i truy v·∫•n kh√°c nhau.
- **T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t**: S·ª≠ d·ª•ng **vLLM**, **FastChat**, v√† ch·ªâ m·ª•c **HNSW** ƒë·ªÉ tƒÉng t·ªëc.

Khi √°p d·ª•ng v√†o h·ªá th·ªëng c·ªßa b·∫°n ƒë·ªÉ h·ªó tr·ª£ t√†i li·ªáu quy ch·∫ø:
- B·∫°n **kh√¥ng c·∫ßn l√†m l·∫°i ho√†n to√†n** c∆° s·ªü d·ªØ li·ªáu ho·∫∑c ch·ªâ m·ª•c, m√† ch·ªâ c·∫ßn m·ªü r·ªông schema PostgreSQL (th√™m tr∆∞·ªùng nh∆∞ `regulation_type`, `clause_number`) v√† t·∫°o collection m·ªõi (`regulations_compliance`) v·ªõi ch·ªâ m·ª•c FAISS/BM25s.
- T√≠ch h·ª£p **Chunkie**, **Trace**, v√† **R1-Searcher** c·ªßa FlashRAG s·∫Ω gi√∫p x·ª≠ l√Ω t√†i li·ªáu quy ch·∫ø hi·ªáu qu·∫£ h∆°n, ƒë·∫∑c bi·ªát v·ªõi c√°c truy v·∫•n multi-hop ho·∫∑c tham chi·∫øu ch√©o.
- **FlashRAG-UI** c√≥ th·ªÉ ƒë∆∞·ª£c t√≠ch h·ª£p v√†o giao di·ªán web c·ªßa b·∫°n ƒë·ªÉ th·ª≠ nghi·ªám v√† c·∫•u h√¨nh c√°c pipeline.

N·∫øu b·∫°n mu·ªën m√¨nh ƒëi s√¢u h∆°n v√†o m·ªôt k·ªπ thu·∫≠t c·ª• th·ªÉ (nh∆∞ c√°ch s·ª≠ d·ª•ng **Trace** ƒë·ªÉ x·ª≠ l√Ω tham chi·∫øu ch√©o trong quy ch·∫ø ho·∫∑c m·∫´u code t√≠ch h·ª£p **R1-Searcher**), h√£y cho m√¨nh bi·∫øt nh√©!

### C√°c k·ªπ thu·∫≠t c·∫ßn h·ªçc h·ªèi t·ª´ FlashRAG cho h·ªá th·ªëng chatbot t√†i li·ªáu n·ªôi b·ªô

1. **Chu·∫©n h√≥a d·ªØ li·ªáu JSONL**: L∆∞u t√†i li·ªáu n·ªôi b·ªô (quy ch·∫ø, PDF) d∆∞·ªõi d·∫°ng JSONL ({id, contents, metadata}) ƒë·ªÉ d·ªÖ x·ª≠ l√Ω l·ªõn, t√≠ch h·ª£p v·ªõi pipeline RAG. √Åp d·ª•ng: Chuy·ªÉn PDF/DOCX sang JSONL, ƒë·ªìng b·ªô metadata v·ªõi PostgreSQL ƒë·ªÉ gi·ªØ analytics.

2. **Ph√¢n ƒëo·∫°n t√†i li·ªáu v·ªõi Chunkie**: S·ª≠ d·ª•ng ph√¢n ƒëo·∫°n semantic-based (ng·ªØ nghƒ©a) ƒë·ªÉ chia t√†i li·ªáu quy ch·∫ø th√†nh chunk gi·ªØ ng·ªØ c·∫£nh, v·ªõi overlap ƒë·ªÉ tr√°nh m·∫•t th√¥ng tin. √Åp d·ª•ng: Thay Content Chunker, tokenize ti·∫øng Vi·ªát b·∫±ng pyvi tr∆∞·ªõc chunking cho embedding t·ªët h∆°n.

3. **T·∫°o ch·ªâ m·ª•c k√©p (FAISS + BM25s)**: FAISS cho t√¨m ki·∫øm ng·ªØ nghƒ©a (dense) v·ªõi Vietnamese Embedding/Qwen3-Embedding-0.6B; BM25s cho t√¨m ki·∫øm t·ª´ kh√≥a (sparse) kh√¥ng c·∫ßn embedding. √Åp d·ª•ng: X√¢y d·ª±ng ch·ªâ m·ª•c t·ª´ JSONL, k·∫øt h·ª£p trong faiss_manager.py ƒë·ªÉ h·ªó tr·ª£ truy v·∫•n quy ch·∫ø (ng·ªØ nghƒ©a + t·ª´ kh√≥a nh∆∞ "ƒêi·ªÅu 5").

4. **Tinh ch·ªânh ng·ªØ c·∫£nh v·ªõi Refiner**: S·ª≠ d·ª•ng LongLLMLingua ƒë·ªÉ n√©n chunk, Trace x√¢y ƒë·ªì th·ªã tri th·ª©c li√™n k·∫øt ƒëi·ªÅu kho·∫£n quy ch·∫ø. √Åp d·ª•ng: T√≠ch h·ª£p v√†o response_generator.py ƒë·ªÉ l·ªçc n·ªôi dung kh√¥ng li√™n quan, gi·∫£m hallucination trong c√¢u tr·∫£ l·ªùi.

5. **Pipeline RAG linh ho·∫°t**: H·ªçc c√°c pipeline nh∆∞ Reasoning (R1-Searcher) cho truy v·∫•n multi-hop quy ch·∫ø, Conditional (Adaptive-RAG) ƒë·ªÉ ch·ªçn collection d·ª±a tr√™n intent. √Åp d·ª•ng: T√≠ch h·ª£p v√†o intent_classifier.py ƒë·ªÉ x·ª≠ l√Ω truy v·∫•n ph·ª©c t·∫°p, k·∫øt h·ª£p v·ªõi vLLM ƒë·ªÉ tƒÉng t·ªëc LLM.

6. **T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t**: S·ª≠ d·ª•ng HNSW cho FAISS nhanh h∆°n, vLLM/FastChat ƒë·ªÉ tƒÉng t·ªëc suy lu·∫≠n. √Åp d·ª•ng: C·∫≠p nh·∫≠t llm_provider.py ƒë·ªÉ gi·∫£m ƒë·ªô tr·ªÖ, ƒë·∫∑c bi·ªát v·ªõi t√†i li·ªáu n·ªôi b·ªô l·ªõn.

7. **Giao di·ªán UI (FlashRAG-UI)**: C·∫•u h√¨nh pipeline tr·ª±c quan. √Åp d·ª•ng: T√≠ch h·ª£p v√†o web interface ƒë·ªÉ qu·∫£n l√Ω t√†i li·ªáu n·ªôi b·ªô m√† kh√¥ng c·∫ßn code.

√Åp d·ª•ng d·∫ßn ƒë·ªÉ gi·ªØ PostgreSQL/Redis cho metadata/analytics, t·∫≠p trung ti·∫øng Vi·ªát v·ªõi pyvi v√† embedding ph√π h·ª£p.

---
D·ª±a tr√™n t√†i li·ªáu thi·∫øt k·∫ø hi·ªán t·∫°i v√† b√°o c√°o PageIndex/FlashRAG b·∫°n ƒë√£ l·∫≠p, t√¥i th·∫•y c√≥ **7 c√¥ng ngh·ªá hi·ªán ƒë·∫°i** t·ª´ FlashRAG r·∫•t ƒë√°ng h·ªçc h·ªèi ƒë·ªÉ n√¢ng c·∫•p h·ªá th·ªëng:

## üéØ **Nh·ªØng c√¥ng ngh·ªá hi·ªán ƒë·∫°i n√™n √°p d·ª•ng ngay**

### 1. **Hybrid Retrieval (Dense + Sparse)**
**Hi·ªán t·∫°i c·ªßa b·∫°n**: Ch·ªâ c√≥ FAISS (dense retrieval)  
**N√¢ng c·∫•p**: Th√™m BM25s ƒë·ªÉ t·∫°o **hybrid search**
```python
# T√≠ch h·ª£p v√†o faiss_manager.py
class HybridRetriever:
    def __init__(self):
        self.dense_retriever = FAISRetriever()  # Existing
        self.sparse_retriever = BM25Retriever()  # New
    
    def search(self, query, top_k=5):
        dense_results = self.dense_retriever.search(query, top_k)
        sparse_results = self.sparse_retriever.search(query, top_k) 
        return self.merge_results(dense_results, sparse_results)
```
**L√Ω do**: T√†i li·ªáu quy ch·∫ø c·∫ßn c·∫£ t√¨m ki·∫øm ng·ªØ nghƒ©a v√† t·ª´ kh√≥a ch√≠nh x√°c (nh∆∞ "ƒêi·ªÅu 5")

### 2. **Semantic-based Chunking v·ªõi Chunkie**
**Hi·ªán t·∫°i c·ªßa b·∫°n**: Token-based chunking (500-1000 tokens)  
**N√¢ng c·∫•p**: Chunkie semantic chunking v·ªõi overlap
```python
# Thay th·∫ø trong content_processor.py
from flashrag.utils import Chunkie

def smart_chunk_vietnamese(content: str):
    # Ti·ªÅn x·ª≠ l√Ω ti·∫øng Vi·ªát v·ªõi pyvi
    segmented = segment_vietnamese(content)
    
    chunker = Chunkie(
        method="semantic", 
        max_size=300,  # Nh·ªè h∆°n ƒë·ªÉ ph√π h·ª£p ti·∫øng Vi·ªát
        overlap=50     # Gi·ªØ ng·ªØ c·∫£nh
    )
    return chunker.chunk(segmented)
```
**L√Ω do**: Gi·ªØ ng·ªØ c·∫£nh t·ªët h∆°n cho t√†i li·ªáu c√≥ c·∫•u tr√∫c ph·ª©c t·∫°p

### 3. **Context Refinement v·ªõi LongLLMLingua**
**Hi·ªán t·∫°i c·ªßa b·∫°n**: Kh√¥ng c√≥ context refinement  
**N√¢ng c·∫•p**: N√©n ng·ªØ c·∫£nh tr∆∞·ªõc khi g·ª≠i LLM
```python
# Th√™m v√†o response_generator.py
from flashrag.refiner import LongLLMLinguaRefiner

class EnhancedResponseGenerator:
    def __init__(self):
        self.refiner = LongLLMLinguaRefiner(compress_ratio=0.6)
    
    def generate_response(self, query, raw_documents):
        # N√©n ng·ªØ c·∫£nh gi·∫£m cost + tƒÉng accuracy
        refined_context = self.refiner.refine(raw_documents)
        return self.llm.generate(query, refined_context)
```
**L√Ω do**: Gi·∫£m cost LLM API v√† tƒÉng ƒë·ªô ch√≠nh x√°c

### 4. **Multi-Pipeline RAG**
**Hi·ªán t·∫°i c·ªßa b·∫°n**: Single pipeline (retrieve ‚Üí generate)  
**N√¢ng c·∫•p**: Conditional/Reasoning pipeline cho truy v·∫•n ph·ª©c t·∫°p
```python
# M·ªü r·ªông intent_classifier.py
class AdvancedPipelineRouter:
    def route_query(self, query, intent):
        if intent == "multi_hop":
            return ReasoningPipeline()  # R1-Searcher
        elif intent == "regulation_lookup":
            return ConditionalPipeline()  # Collection selector  
        else:
            return StandardPipeline()
```
**L√Ω do**: X·ª≠ l√Ω t·ªët h∆°n c√°c c√¢u h·ªèi ph·ª©c t·∫°p v·ªÅ quy ch·∫ø/quy tr√¨nh

### 5. **JSONL Data Format cho Scalability**
**Hi·ªán t·∫°i c·ªßa b·∫°n**: PostgreSQL primary storage  
**N√¢ng c·∫•p**: JSONL + PostgreSQL hybrid
```python
# Th√™m export function trong database_manager.py
def export_to_jsonl(collection_name: str):
    """Export ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi FlashRAG tools"""
    docs = get_documents_by_collection(collection_name)
    return [{"id": doc.id, "contents": doc.content, "metadata": doc.metadata} 
            for doc in docs]
```
**L√Ω do**: T∆∞∆°ng th√≠ch v·ªõi FlashRAG tools v√† d·ªÖ scale

### 6. **Vietnamese Embedding Optimization**
**Hi·ªán t·∫°i c·ªßa b·∫°n**: text-embedding-ada-002 (EN-focused)  
**N√¢ng c·∫•p**: Vietnamese-optimized models
```python
# C·∫≠p nh·∫≠t llm_provider.py
VIETNAMESE_MODELS = {
    "vietnamese_e5": "intfloat/multilingual-e5-base",  # T·ªët cho ti·∫øng Vi·ªát
    "qwen_embedding": "Qwen/Qwen2.5-Coder-7B",       # Multilingual
    "bge_m3": "BAAI/bge-m3"                           # Multilingual
}
```
**L√Ω do**: C·∫£i thi·ªán accuracy cho n·ªôi dung ti·∫øng Vi·ªát

### 7. **FlashRAG-UI Integration**
**Hi·ªán t·∫°i c·ªßa b·∫°n**: Custom web interface  
**N√¢ng c·∫•p**: T√≠ch h·ª£p FlashRAG-UI cho admin features
```python
# Th√™m admin dashboard v·ªõi FlashRAG-UI
# - C·∫•u h√¨nh pipeline tr·ª±c quan
# - Test c√°c embedding models
# - Monitor performance metrics
```
**L√Ω do**: Gi·∫£m th·ªùi gian development v√† c√≥ s·∫µn advanced features

## üöÄ **Roadmap tri·ªÉn khai (4 tu·∫ßn)**

**Tu·∫ßn 1**: Hybrid Retrieval + BM25s  
**Tu·∫ßn 2**: Semantic Chunking + Vietnamese preprocessing  
**Tu·∫ßn 3**: Context Refinement + Multi-pipeline  
**Tu·∫ßn 4**: Vietnamese Embedding + Performance optimization  

## üéØ **Impact d·ª± ki·∫øn**

- **Accuracy**: +15-20% v·ªõi hybrid search
- **Cost**: -30-40% v·ªõi context compression  
- **Speed**: +2x v·ªõi optimized embeddings
- **Scalability**: +5x v·ªõi JSONL compatibility
- **Maintainability**: +50% v·ªõi FlashRAG tools

B·∫°n mu·ªën t√¥i chi ti·∫øt h∆°n v·ªÅ vi·ªác implement c√¥ng ngh·ªá n√†o tr∆∞·ªõc kh√¥ng? T√¥i recommend b·∫Øt ƒë·∫ßu v·ªõi **Hybrid Retrieval** v√¨ impact ngay l·∫≠p t·ª©c v√† d·ªÖ t√≠ch h·ª£p nh·∫•t.
---
D·ª±a tr√™n thi·∫øt k·∫ø c∆° s·ªü d·ªØ li·ªáu hi·ªán t·∫°i v√† c√°c c·∫£i ti·∫øn t·ª´ FlashRAG, ƒë√¢y s·∫Ω l√† **7 thay ƒë·ªïi quan tr·ªçng** c·∫ßn th·ª±c hi·ªán:

## üóÑÔ∏è **Impact l√™n Database Design**

### 1. **M·ªü r·ªông Schema PostgreSQL cho Hybrid Retrieval**

**Hi·ªán t·∫°i**: Ch·ªâ h·ªó tr·ª£ vector embeddings  
**C·∫ßn th√™m**: B·∫£ng cho BM25s indexing

```sql
-- Th√™m v√†o documents_metadata table
ALTER TABLE documents_metadata ADD COLUMN IF NOT EXISTS (
    -- BM25 indexing support
    search_tokens TSVECTOR,  -- Full-text search tokens
    keyword_density JSONB,   -- Keyword frequency analysis
    
    -- Document structure metadata
    heading_structure JSONB,  -- Document outline (H1, H2, H3)
    chunk_strategy VARCHAR(20) DEFAULT 'semantic',  -- chunking method used
    
    -- FlashRAG compatibility  
    flashrag_collection VARCHAR(100),  -- Collection name for FlashRAG
    jsonl_export_ready BOOLEAN DEFAULT false  -- Ready for JSONL export
);

-- Create full-text search index
CREATE INDEX idx_documents_search_tokens ON documents_metadata 
USING GIN(search_tokens);

-- Create BM25 supporting table
CREATE TABLE document_chunks_bm25 (
    chunk_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID REFERENCES documents_metadata(document_id),
    chunk_content TEXT NOT NULL,
    chunk_position INTEGER,
    bm25_tokens TSVECTOR,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_chunks_bm25_tokens ON document_chunks_bm25 
USING GIN(bm25_tokens);
```

### 2. **Dual Storage Strategy: PostgreSQL + JSONL**

**M·ªü r·ªông**: Th√™m export/import functions ƒë·ªÉ t∆∞∆°ng th√≠ch FlashRAG

```sql
-- Add export metadata tracking
CREATE TABLE jsonl_exports (
    export_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    collection_name VARCHAR(100) NOT NULL,
    export_path TEXT,
    document_count INTEGER,
    total_chunks INTEGER,
    exported_at TIMESTAMP DEFAULT NOW(),
    flashrag_compatible BOOLEAN DEFAULT true
);

-- Function to prepare JSONL export
CREATE OR REPLACE FUNCTION prepare_jsonl_export(collection_name TEXT)
RETURNS TABLE(
    id TEXT,
    contents TEXT,
    metadata JSONB
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        dm.document_id::TEXT as id,
        dm.content as contents,
        jsonb_build_object(
            'title', dm.title,
            'document_type', dm.document_type,
            'access_level', dm.access_level,
            'department_owner', dm.department_owner,
            'heading_structure', dm.heading_structure,
            'tags', array_agg(dt.tag_name)
        ) as metadata
    FROM documents_metadata dm
    LEFT JOIN document_tag_relations dtr ON dm.document_id = dtr.document_id  
    LEFT JOIN document_tags dt ON dtr.tag_id = dt.tag_id
    WHERE dm.flashrag_collection = collection_name
    GROUP BY dm.document_id, dm.content, dm.title, dm.document_type, 
             dm.access_level, dm.department_owner, dm.heading_structure;
END;
$$ LANGUAGE plpgsql;
```

### 3. **Enhanced Chunking Metadata**

**M·ªü r·ªông**: Support semantic chunking v·ªõi overlap tracking

```sql
-- Modify existing chunks table or create new one
CREATE TABLE document_chunks_enhanced (
    chunk_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID REFERENCES documents_metadata(document_id),
    
    -- Content data
    chunk_content TEXT NOT NULL,
    chunk_position INTEGER,
    chunk_size_tokens INTEGER,
    
    -- Semantic chunking metadata  
    semantic_boundary BOOLEAN DEFAULT false,  -- Is this a semantic boundary?
    overlap_with_prev INTEGER DEFAULT 0,      -- Overlap with previous chunk
    overlap_with_next INTEGER DEFAULT 0,      -- Overlap with next chunk
    heading_context TEXT,                     -- Which heading this belongs to
    
    -- FlashRAG compatibility
    chunk_method VARCHAR(20) DEFAULT 'semantic',  -- token/sentence/semantic
    chunk_quality_score DECIMAL(3,2),            -- Quality assessment
    
    -- Vector storage references
    faiss_index_id INTEGER,                   -- FAISS index reference
    embedding_model VARCHAR(100),             -- Which model created embedding
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_chunks_enhanced_document ON document_chunks_enhanced(document_id);
CREATE INDEX idx_chunks_enhanced_position ON document_chunks_enhanced(chunk_position);
CREATE INDEX idx_chunks_enhanced_boundary ON document_chunks_enhanced(semantic_boundary);
```

### 4. **Context Refinement Tracking**

**M·ªõi**: B·∫£ng tracking cho LongLLMLingua v√† context compression

```sql
-- Track context refinement operations
CREATE TABLE context_refinement_log (
    refinement_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    query_session_id UUID,
    
    -- Original context
    original_chunks UUID[], -- Array of chunk IDs
    original_token_count INTEGER,
    
    -- Refined context  
    refined_content TEXT,
    refined_token_count INTEGER,
    compression_ratio DECIMAL(3,2),
    
    -- Refinement metadata
    refinement_method VARCHAR(50), -- 'longlmllingua', 'selective_context' 
    quality_score DECIMAL(3,2),
    processing_time_ms INTEGER,
    
    created_at TIMESTAMP DEFAULT NOW()
);

-- Track knowledge graph relationships (for Trace refiner)
CREATE TABLE knowledge_graph_edges (
    edge_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    source_chunk_id UUID REFERENCES document_chunks_enhanced(chunk_id),
    target_chunk_id UUID REFERENCES document_chunks_enhanced(chunk_id),
    
    relationship_type VARCHAR(50), -- 'references', 'contradicts', 'supports'
    confidence_score DECIMAL(3,2),
    extraction_method VARCHAR(50), -- 'trace', 'manual', 'llm_extracted'
    
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_kg_edges_source ON knowledge_graph_edges(source_chunk_id);
CREATE INDEX idx_kg_edges_target ON knowledge_graph_edges(target_chunk_id);
```

### 5. **Multi-Pipeline Query Tracking**

**M·ªü r·ªông**: Track different RAG pipelines usage

```sql
-- Extend existing query logs or create new table
CREATE TABLE rag_pipeline_sessions (
    session_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID,
    
    -- Query information
    original_query TEXT NOT NULL,
    intent_detected VARCHAR(50),
    
    -- Pipeline metadata
    pipeline_type VARCHAR(50), -- 'standard', 'reasoning', 'conditional'
    pipeline_method VARCHAR(50), -- 'r1_searcher', 'ircot', 'adaptive_rag'
    
    -- Processing steps
    retrieval_method VARCHAR(50), -- 'hybrid', 'dense', 'sparse'
    chunks_retrieved INTEGER,
    context_refined BOOLEAN DEFAULT false,
    
    -- Results
    response_generated BOOLEAN,
    response_quality_score DECIMAL(3,2),
    processing_time_ms INTEGER,
    
    -- Performance metrics
    tokens_used INTEGER,
    api_calls_count INTEGER,
    total_cost_usd DECIMAL(8,4),
    
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_pipeline_sessions_user ON rag_pipeline_sessions(user_id);
CREATE INDEX idx_pipeline_sessions_pipeline ON rag_pipeline_sessions(pipeline_type, pipeline_method);
CREATE INDEX idx_pipeline_sessions_created ON rag_pipeline_sessions(created_at);
```

### 6. **Vietnamese Language Support**

**M·ªü r·ªông**: Th√™m metadata cho Vietnamese processing

```sql
-- Add Vietnamese language processing metadata
ALTER TABLE documents_metadata ADD COLUMN IF NOT EXISTS (
    -- Language processing
    language_detected VARCHAR(10) DEFAULT 'vi',
    vietnamese_segmented BOOLEAN DEFAULT false,  -- Processed with pyvi
    
    -- Vietnamese-specific metadata
    diacritics_normalized BOOLEAN DEFAULT false,
    tone_marks_preserved BOOLEAN DEFAULT true,
    
    -- Embedding model used (Vietnamese-optimized)
    embedding_model_primary VARCHAR(100),    -- e.g., 'multilingual-e5-base'
    embedding_model_fallback VARCHAR(100),   -- e.g., 'text-embedding-ada-002'
    embedding_quality_vi DECIMAL(3,2)       -- Vietnamese embedding quality score
);

-- Vietnamese text analysis results
CREATE TABLE vietnamese_text_analysis (
    analysis_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID REFERENCES documents_metadata(document_id),
    
    -- Pyvi segmentation results
    word_segmentation JSONB,        -- Segmented words
    pos_tagging JSONB,              -- Part-of-speech tags
    
    -- Vietnamese-specific features
    compound_words TEXT[],          -- Detected compound words  
    technical_terms TEXT[],         -- Domain-specific terminology
    proper_nouns TEXT[],            -- Vietnamese proper nouns
    
    processed_at TIMESTAMP DEFAULT NOW()
);
```

### 7. **Performance Optimization Tables**

**M·ªõi**: Tracking performance cho optimization

```sql
-- Embedding model performance comparison
CREATE TABLE embedding_model_benchmarks (
    benchmark_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    model_name VARCHAR(100),
    model_type VARCHAR(50), -- 'vietnamese', 'multilingual', 'english'
    
    -- Performance metrics
    hit_rate DECIMAL(5,4),          -- Hit rate at k=5
    mrr DECIMAL(5,4),               -- Mean Reciprocal Rank
    processing_time_avg_ms INTEGER,  -- Average processing time
    
    -- Test dataset info
    test_dataset VARCHAR(100),
    test_queries_count INTEGER,
    language VARCHAR(10),
    
    -- Hardware/config info
    hardware_config JSONB,
    tested_at TIMESTAMP DEFAULT NOW()
);

-- Query performance tracking
CREATE TABLE query_performance_metrics (
    metric_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    session_id UUID REFERENCES rag_pipeline_sessions(session_id),
    
    -- Timing breakdown
    retrieval_time_ms INTEGER,
    embedding_time_ms INTEGER,  
    llm_processing_time_ms INTEGER,
    context_refinement_time_ms INTEGER,
    
    -- Resource usage
    memory_usage_mb INTEGER,
    cpu_usage_percent DECIMAL(5,2),
    
    -- Quality metrics
    relevance_score DECIMAL(3,2),
    user_satisfaction INTEGER CHECK (user_satisfaction BETWEEN 1 AND 5),
    
    recorded_at TIMESTAMP DEFAULT NOW()
);

-- Indexes for analytics queries
CREATE INDEX idx_performance_session ON query_performance_metrics(session_id);
CREATE INDEX idx_performance_recorded ON query_performance_metrics(recorded_at);
```

## üîÑ **Database Migration Strategy**

### Phase 1: Schema Extensions (1 tu·∫ßn)
```bash
# 1. Run schema migrations
python scripts/migrate_database.py --add-flashrag-support

# 2. Update existing documents with new fields
python scripts/update_existing_documents.py --add-vietnamese-metadata

# 3. Create new indexes
python scripts/create_performance_indexes.py
```

### Phase 2: Data Migration (1 tu·∫ßn)  
```bash
# 1. Re-process existing documents with semantic chunking
python scripts/rechunk_documents.py --method=semantic --batch-size=100

# 2. Generate BM25 indexes for existing content
python scripts/generate_bm25_indexes.py --collection=all

# 3. Export to JSONL format for FlashRAG compatibility
python scripts/export_to_jsonl.py --collections=all --output-dir=./flashrag_data/
```

### Phase 3: Performance Testing (1 tu·∫ßn)
```bash
# 1. Run benchmark tests with new schema
python scripts/benchmark_new_schema.py --test-queries=1000

# 2. Compare old vs new performance 
python scripts/compare_performance.py --old-schema --new-schema

# 3. Optimize based on results
python scripts/optimize_indexes.py --auto-tune
```

## üíæ **Storage Impact**

**D·ª± ki·∫øn tƒÉng storage**:
- **PostgreSQL**: +40% (metadata m·ªü r·ªông, tracking tables)
- **Vector Storage**: +20% (multiple embeddings, BM25 indexes)  
- **File Storage**: +60% (JSONL exports, backup copies)

**T·ªïng impact**: TƒÉng ~45% storage requirement, nh∆∞ng c√≥:
- ‚úÖ Hybrid search accuracy tƒÉng 15-20%
- ‚úÖ Query performance tƒÉng 2x v·ªõi caching
- ‚úÖ FlashRAG compatibility cho advanced features
- ‚úÖ Better Vietnamese language support

B·∫°n c√≥ mu·ªën t√¥i chi ti·∫øt migration script cho t·ª´ng phase kh√¥ng?


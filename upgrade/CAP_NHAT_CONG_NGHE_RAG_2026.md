# üìä B√ÅO C√ÅO C·∫¨P NH·∫¨T C√îNG NGH·ªÜ CHO H·ªÜ TH·ªêNG RAG ATTECH

**Phi√™n b·∫£n:** 1.0  
**Ng√†y:** 07/02/2026  
**Ng∆∞·ªùi th·ª±c hi·ªán:** Senior Software Architect & LLM Training Specialist  
**D·ª± √°n:** H·ªá th·ªëng Tr·ª£ l√Ω Tri th·ª©c VƒÉn b·∫£n Ph√°p lu·∫≠t Vi·ªát Nam - ATTECH  
**M·ª•c ƒë√≠ch:** ƒê√°nh gi√° v√† khuy·∫øn ngh·ªã c·∫≠p nh·∫≠t c√¥ng ngh·ªá m·ªõi nh·∫•t cho h·ªá th·ªëng chatbot Artificial Intelligence t√†i li·ªáu n·ªôi b·ªô

---

## üìã M·ª§C L·ª§C

1. [T·ªïng quan Stack Hi·ªán t·∫°i vs Xu h∆∞·ªõng 2026](#1-t·ªïng-quan)
2. [Embedding Models ‚Äî N√¢ng c·∫•p quan tr·ªçng nh·∫•t](#2-embedding-models)
3. [Vector Database ‚Äî ƒê√°nh gi√° ChromaDB v√† c√°c l·ª±a ch·ªçn thay th·∫ø](#3-vector-database)
4. [Reranking ‚Äî T·∫ßng thi·∫øu v·∫Øng trong Pipeline hi·ªán t·∫°i](#4-reranking)
5. [RAG Framework ‚Äî Orchestration th·∫ø h·ªá m·ªõi](#5-rag-framework)
6. [Graph RAG ‚Äî Xu h∆∞·ªõng ch·ªß ƒë·∫°o 2026](#6-graph-rag)
7. [Agentic RAG ‚Äî Ki·∫øn tr√∫c th·∫ø h·ªá ti·∫øp theo](#7-agentic-rag)
8. [X·ª≠ l√Ω Ng√¥n ng·ªØ Ti·∫øng Vi·ªát ‚Äî C√¥ng c·ª• v√† m√¥ h√¨nh m·ªõi](#8-xu-ly-tieng-viet)
9. [Large Language Model Gateway ‚Äî Qu·∫£n l√Ω ƒëa nh√† cung c·∫•p](#9-llm-gateway)
10. [ƒê√°nh gi√° Ch·∫•t l∆∞·ª£ng RAG ‚Äî C√¥ng c·ª• v√† Benchmark](#10-danh-gia-chat-luong)
11. [Ma tr·∫≠n So s√°nh T·ªïng h·ª£p](#11-ma-tran-so-sanh)
12. [L·ªô tr√¨nh N√¢ng c·∫•p ƒê·ªÅ xu·∫•t](#12-lo-trinh-nang-cap)

---

## 1. T·ªîNG QUAN

### 1.1 Stack C√¥ng ngh·ªá Hi·ªán t·∫°i c·ªßa ATTECH

```mermaid
graph TB
    subgraph "üîµ STACK HI·ªÜN T·∫†I - ATTECH Phase 1"
        E1[Qwen3-Embedding-0.6B<br/>1024-dim]
        VDB1[ChromaDB 1.0.0<br/>HNSW + Cosine]
        DB1[PostgreSQL 15<br/>BM25 + Metadata]
        F1[FastAPI 0.115.9<br/>REST API]
        UI1[Streamlit<br/>Chat Interface]
        C1[Redis 7<br/>Cache + Session]
        GPU1[RTX 2080 Ti<br/>CUDA 11.8]
        NLP1[underthesea + pyvi<br/>Vietnamese NLP]
    end
    
    E1 --> VDB1
    E1 --> DB1
    VDB1 --> F1
    DB1 --> F1
    F1 --> UI1
    C1 --> F1
    GPU1 --> E1
    NLP1 --> E1
```

### 1.2 Xu h∆∞·ªõng C√¥ng ngh·ªá RAG 2026

```mermaid
graph TB
    subgraph "üü¢ XU H∆Ø·ªöNG CH√çNH 2026"
        T1[üîÑ Hybrid Search + Reranking<br/>C·∫£i thi·ªán 33-47% ƒë·ªô ch√≠nh x√°c]
        T2[üï∏Ô∏è Graph RAG<br/>V∆∞·ª£t tr·ªôi Vector-only cho reasoning ph·ª©c t·∫°p]
        T3[ü§ñ Agentic RAG<br/>LLM-powered query planning]
        T4[üìê Matryoshka Embeddings<br/>Linh ho·∫°t chi·ªÅu vector]
        T5[‚ö° Cross-Encoder Reranking<br/>Ti√™u chu·∫©n m·∫∑c ƒë·ªãnh 2026]
        T6[üìä RAG Evaluation T·ª± ƒë·ªông<br/>RAGAS + BEIR metrics]
    end
    
    T1 --> T5
    T2 --> T3
    T4 --> T1
    T5 --> T6
```

### 1.3 ƒê√°nh gi√° T·ªïng quan: Hi·ªán t·∫°i vs Xu h∆∞·ªõng

| Kh√≠a c·∫°nh | ATTECH Hi·ªán t·∫°i | Xu h∆∞·ªõng 2026 | Kho·∫£ng c√°ch | ∆Øu ti√™n |
|-----------|----------------|---------------|-------------|---------|
| **Embedding Model** | Qwen3-Embedding-0.6B (1024-dim) | Qwen3-Embedding 4B/8B, BGE-M3, Vietnamese-specific | Trung b√¨nh | üü° P1 |
| **Vector Database** | ChromaDB 1.0.0 | pgvector + ChromaDB hybrid, ho·∫∑c Qdrant/Milvus | Th·∫•p | üü¢ P2 |
| **Reranking** | ‚ùå Kh√¥ng c√≥ | Cross-encoder reranking (ti√™u chu·∫©n 2026) | **Cao** | üî¥ P0 |
| **Search** | Hybrid (0.7 semantic + 0.3 BM25) | Hybrid + Graph + Reranking 3 t·∫ßng | Trung b√¨nh | üü° P1 |
| **Graph RAG** | PostgreSQL tables (ch∆∞a populated) | Neo4j/ArangoDB ho·∫∑c PostgreSQL graph ƒë·∫ßy ƒë·ªß | Trung b√¨nh | üü° P1 |
| **Agentic RAG** | ‚ùå Kh√¥ng c√≥ | LangGraph/CrewAI multi-agent orchestration | Th·∫•p | üü¢ P3 |
| **ƒê√°nh gi√°** | 100 query-document pairs (th·ªß c√¥ng) | RAGAS t·ª± ƒë·ªông + continuous evaluation | **Cao** | üî¥ P0 |
| **LLM Gateway** | Multi-provider (OpenAI, Claude) | LiteLLM/AI Gateway chu·∫©n h√≥a | Trung b√¨nh | üü° P2 |

---

## 2. EMBEDDING MODELS

### 2.1 ƒê√°nh gi√° M√¥ h√¨nh Hi·ªán t·∫°i

**M√¥ h√¨nh ƒëang d√πng:** `Qwen/Qwen3-Embedding-0.6B`
- K√≠ch th∆∞·ªõc: 0.6 t·ª∑ tham s·ªë
- Chi·ªÅu vector: 1024
- Ng·ªØ c·∫£nh t·ªëi ƒëa: 8.192 tokens
- H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ: 100+ ng√¥n ng·ªØ (bao g·ªìm ti·∫øng Vi·ªát)
- Gi·∫•y ph√©p: Apache 2.0

**ƒê√°nh gi√°:** M√¥ h√¨nh ph√π h·ª£p t·ªët cho quy m√¥ hi·ªán t·∫°i (~42 t√†i li·ªáu, 100 ng∆∞·ªùi d√πng ƒë·ªìng th·ªùi). Tuy nhi√™n, v·ªõi y√™u c·∫ßu x·ª≠ l√Ω t√†i li·ªáu ph√°p lu·∫≠t ti·∫øng Vi·ªát chuy√™n s√¢u, c√≥ nh·ªØng l·ª±a ch·ªçn t·ªët h∆°n ƒë·ªÉ c√¢n nh·∫Øc.

### 2.2 C√°c M√¥ h√¨nh Embedding ƒê√°ng Ch√∫ √Ω 2026

```mermaid
graph LR
    subgraph "üèÜ TOP EMBEDDING MODELS 2026"
        subgraph "ƒêa ng√¥n ng·ªØ T·ªïng h·ª£p"
            Q4[Qwen3-Embedding-4B<br/>‚≠ê Khuy·∫øn ngh·ªã n√¢ng c·∫•p]
            BGE[BGE-M3<br/>Dense+Sparse+Multi-vector]
            JN[Jina Embeddings v4<br/>Multimodal + 89 ng√¥n ng·ªØ]
        end
        subgraph "Chuy√™n bi·ªát Ti·∫øng Vi·ªát"
            VE[vietnamese-embedding<br/>PhoBERT 768-dim]
            VDE[vietnamese-document-embedding<br/>8096 tokens Matryoshka]
        end
        subgraph "Doanh nghi·ªáp"
            CO[Cohere Embed v4.0<br/>100+ ng√¥n ng·ªØ MRL]
            NV[NV-Embed-v2<br/>7.85B params 32K tokens]
        end
    end
```

### 2.3 So s√°nh Chi ti·∫øt

| M√¥ h√¨nh | Params | Chi·ªÅu | Context | Ti·∫øng Vi·ªát | GPU VRAM | Gi·∫•y ph√©p | Ph√π h·ª£p ATTECH |
|---------|--------|-------|---------|-----------|----------|-----------|----------------|
| **Qwen3-Embedding-0.6B** (hi·ªán t·∫°i) | 0.6B | 1024 | 8K | T·ªët | ~2.2GB | Apache 2.0 | ‚úÖ ƒêang d√πng |
| **Qwen3-Embedding-4B** | 4B | 1024 | 32K | R·∫•t t·ªët | ~8GB | Apache 2.0 | ‚≠ê **Khuy·∫øn ngh·ªã** |
| **BGE-M3** | 0.6B | 1024 | 8K | T·ªët | ~2.5GB | MIT | ‚úÖ Thay th·∫ø t·ªët |
| **vietnamese-document-embedding** | ~0.3B | 768 | 8K | Xu·∫•t s·∫Øc | ~1.5GB | Apache 2.0 | ‚≠ê **B·ªï sung cho VN** |
| **Jina Embeddings v4** | ~1B | 2048 | 8K | T·ªët | ~4GB | CC-BY-NC-4.0 | ‚ö†Ô∏è Kh√¥ng th∆∞∆°ng m·∫°i |
| **Cohere Embed v4.0** | N/A | 1024 | 512 | T·ªët | API-only | Th∆∞∆°ng m·∫°i | üü° Fallback API |
| **NV-Embed-v2** | 7.85B | 4096 | 32K | Trung b√¨nh | ~16GB+ | CC-BY-NC-4.0 | ‚ùå Qu√° l·ªõn cho RTX 2080 Ti |

### 2.4 Khuy·∫øn ngh·ªã cho ATTECH

**üèÜ Ph∆∞∆°ng √°n t·ªëi ∆∞u: Dual Embedding Strategy**

```mermaid
graph TD
    Q[Truy v·∫•n ng∆∞·ªùi d√πng] --> Classify{Ph√¢n lo·∫°i<br/>Ng√¥n ng·ªØ v√† Lo·∫°i}
    
    Classify -->|Ti·∫øng Vi·ªát chuy√™n s√¢u| VN[vietnamese-document-embedding<br/>768-dim t·ªëi ∆∞u ti·∫øng Vi·ªát]
    Classify -->|ƒêa ng√¥n ng·ªØ ho·∫∑c K·ªπ thu·∫≠t| QW[Qwen3-Embedding-4B<br/>1024-dim 32K context]
    
    VN --> Merge[Merge v√† Normalize Results]
    QW --> Merge
    Merge --> Rerank[Cross-Encoder Reranking]
    Rerank --> LLM[LLM Generation]
```

**L√Ω do:**
1. **Qwen3-Embedding-4B** (n√¢ng t·ª´ 0.6B l√™n 4B): C√πng ki·∫øn tr√∫c n√™n migration d·ªÖ d√†ng, context window tƒÉng t·ª´ 8K l√™n 32K tokens (quan tr·ªçng cho t√†i li·ªáu ph√°p lu·∫≠t d√†i), ch·∫•t l∆∞·ª£ng embedding t·ªët h∆°n ƒë√°ng k·ªÉ, v·∫´n ch·∫°y ƒë∆∞·ª£c tr√™n RTX 2080 Ti (11GB VRAM, model kho·∫£ng 8GB).
2. **vietnamese-document-embedding** (b·ªï sung): ƒê∆∞·ª£c hu·∫•n luy·ªán chuy√™n bi·ªát cho ti·∫øng Vi·ªát tr√™n PhoBERT/gte-multilingual, h·ªó tr·ª£ Matryoshka (linh ho·∫°t chi·ªÅu vector), s·ª≠ d·ª•ng c√πng `pyvi` tokenizer m√† ATTECH ƒë√£ t√≠ch h·ª£p.

**‚ö†Ô∏è L∆∞u √Ω VRAM:** RTX 2080 Ti c√≥ 11GB VRAM. Ch·∫°y ƒë·ªìng th·ªùi c·∫£ 2 model s·∫Ω c·∫ßn kho·∫£ng 10GB. N√™n c√¢n nh·∫Øc ch·∫°y tu·∫ßn t·ª± (load/unload model theo lo·∫°i truy v·∫•n) ho·∫∑c ch·ªçn duy nh·∫•t **Qwen3-Embedding-4B** n·∫øu VRAM h·∫°n ch·∫ø.

---

## 3. VECTOR DATABASE

### 3.1 ƒê√°nh gi√° ChromaDB 1.0.0 Hi·ªán t·∫°i

**∆Øu ƒëi·ªÉm v·∫´n gi·ªØ:**
- API ƒë∆°n gi·∫£n, developer-friendly
- T√≠ch h·ª£p t·ªët v·ªõi Python ecosystem
- ƒê·ªß cho quy m√¥ d∆∞·ªõi 1 tri·ªáu vectors
- HNSW indexing cho similarity search

**H·∫°n ch·∫ø c·∫ßn l∆∞u √Ω:**
- Gi·ªõi h·∫°n kho·∫£ng 1 tri·ªáu vector points tr√™n single node
- Kh√¥ng h·ªó tr·ª£ distributed/sharding
- Kh√¥ng c√≥ Role-Based Access Control (RBAC) t√≠ch h·ª£p
- Kh√¥ng c√≥ hybrid search native (c·∫ßn k·∫øt h·ª£p v·ªõi PostgreSQL BM25)
- Community nh·ªè h∆°n Milvus (6K vs 35K GitHub stars)

### 3.2 C√°c L·ª±a ch·ªçn Vector Database 2026

```mermaid
graph TB
    subgraph "üìä SO S√ÅNH VECTOR DATABASE 2026"
        subgraph "Purpose-Built"
            M[üèÜ Milvus/Zilliz<br/>35K+ stars GitHub<br/>Billions vectors<br/>GPU + Distributed]
            QD[Qdrant<br/>9K+ stars GitHub<br/>Rust-based nhanh<br/>Multi-tenant]
            WV[Weaviate<br/>8K+ stars GitHub<br/>GraphQL API<br/>Hybrid native]
        end
        subgraph "Extension"
            PG[pgvector<br/>PostgreSQL extension<br/>471 QPS @ 99% recall<br/>T√≠ch h·ª£p s·∫µn DB]
            CHR[ChromaDB 1.0.0<br/>6K+ stars GitHub<br/>Developer-friendly<br/>Prototyping]
        end
    end
```

### 3.3 Khuy·∫øn ngh·ªã cho ATTECH

**üèÜ Ph∆∞∆°ng √°n t·ªëi ∆∞u: pgvector + ChromaDB Hybrid (Gi·ªØ nguy√™n + B·ªï sung)**

| Th√†nh ph·∫ßn | Vai tr√≤ | L√Ω do |
|-----------|---------|-------|
| **pgvector** (th√™m m·ªõi) | Vector search ch√≠nh trong PostgreSQL | ATTECH ƒë√£ c√≥ PostgreSQL 15, th√™m extension kh√¥ng c·∫ßn qu·∫£n l√Ω th√™m database m·ªõi. T√≠ch h·ª£p RBAC s·∫µn c√≥. Hybrid search (BM25 + vector) trong c√πng 1 query. 471 QPS @ 99% recall cho 50M vectors. |
| **ChromaDB 1.0.0** (gi·ªØ) | Prototyping, embedding cache, fast lookup | Gi·ªØ l·∫°i cho development/testing. D·ªØ li·ªáu 42 t√†i li·ªáu hi·ªán t·∫°i v·∫´n ho·∫°t ƒë·ªông t·ªët. |

**L√Ω do KH√îNG chuy·ªÉn sang Milvus/Qdrant:**
- Quy m√¥ ATTECH (42 t√†i li·ªáu, kho·∫£ng 100 ng∆∞·ªùi d√πng) ch∆∞a c·∫ßn database chuy√™n bi·ªát x·ª≠ l√Ω h√†ng t·ª∑ vectors
- Th√™m infrastructure m·ªõi tƒÉng complexity kh√¥ng c·∫ßn thi·∫øt cho team
- pgvector gi·∫£i quy·∫øt ƒë∆∞·ª£c t·∫•t c·∫£ nhu c·∫ßu hi·ªán t·∫°i v√† t∆∞∆°ng lai g·∫ßn trong c√πng PostgreSQL stack

**C√†i ƒë·∫∑t pgvector:**
```sql
-- Tr√™n PostgreSQL 15 ƒë√£ c√≥ s·∫µn
CREATE EXTENSION IF NOT EXISTS vector;

-- T·∫°o b·∫£ng v·ªõi vector column
CREATE TABLE document_embeddings (
    id SERIAL PRIMARY KEY,
    chunk_id INTEGER REFERENCES document_chunks_enhanced(id),
    embedding vector(1024),
    created_at TIMESTAMP DEFAULT NOW()
);

-- HNSW index cho cosine similarity
CREATE INDEX ON document_embeddings 
    USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 200);
```

---

## 4. RERANKING ‚Äî T·∫¶NG THI·∫æU V·∫ÆNG QUAN TR·ªåNG NH·∫§T

### 4.1 T·∫°i sao Reranking l√† ∆Øu ti√™n S·ªë 1?

**ƒê√¢y l√† kho·∫£ng c√°ch l·ªõn nh·∫•t trong pipeline ATTECH hi·ªán t·∫°i.** Theo nghi√™n c·ª©u 2026:
- Cross-encoder reranking c·∫£i thi·ªán **33-47% ƒë·ªô ch√≠nh x√°c** retrieval
- ƒê√£ tr·ªü th√†nh **ki·∫øn tr√∫c m·∫∑c ƒë·ªãnh** cho production RAG systems
- ƒê·∫∑c bi·ªát hi·ªáu qu·∫£ cho truy v·∫•n ph·ª©c t·∫°p (t√†i li·ªáu ph√°p lu·∫≠t, so s√°nh, multi-hop)

### 4.2 Ki·∫øn tr√∫c Two-Stage Retrieval

```mermaid
graph LR
    subgraph "HI·ªÜN T·∫†I - ATTECH"
        Q1[Query] --> S1[Semantic Search<br/>ChromaDB] 
        Q1 --> K1[Keyword Search<br/>PostgreSQL BM25]
        S1 --> H1[Hybrid Ranking<br/>0.7 semantic + 0.3 keyword]
        K1 --> H1
        H1 --> LLM1[LLM<br/>Top-K results]
    end
```

```mermaid
graph LR
    subgraph "ƒê·ªÄ XU·∫§T - TWO-STAGE + RERANKING"
        Q2[Query] --> S2[Stage 1: Bi-Encoder<br/>Retrieve top-100 nhanh<br/>kho·∫£ng 50ms]
        S2 --> R2[Stage 2: Cross-Encoder<br/>Rerank top-100 th√†nh top-10<br/>kho·∫£ng 200-400ms]
        R2 --> LLM2[LLM<br/>Top-10 results<br/>Ch√≠nh x√°c h∆°n 40%]
    end
```

### 4.3 C√°c Reranker Models ƒê√°ng Ch√∫ √Ω

| Model | Lo·∫°i | Ng√¥n ng·ªØ | T·ªëc ƒë·ªô | T·ª± host | Ph√π h·ª£p ATTECH |
|-------|------|----------|--------|---------|----------------|
| **cross-encoder/ms-marco-MiniLM-L-12-v2** | Open-source | EN ch√≠nh, multilingual OK | Nhanh | ‚úÖ | ‚≠ê **Kh·ªüi ƒë·∫ßu** |
| **bge-reranker-v2-m3** | Open-source | 100+ ng√¥n ng·ªØ | Trung b√¨nh | ‚úÖ | ‚≠ê **Khuy·∫øn ngh·ªã** |
| **Qwen3-Reranker** | Open-source | 100+ ng√¥n ng·ªØ, instruction-aware | Trung b√¨nh | ‚úÖ | ‚≠ê **T·ªët nh·∫•t** |
| **Cohere Rerank 3** | API | 100+ ng√¥n ng·ªØ | Nhanh | ‚ùå | üü° Fallback |
| **Jina Reranker v2** | Open-source | 100+ ng√¥n ng·ªØ | Nhanh | ‚úÖ | ‚úÖ Thay th·∫ø t·ªët |

### 4.4 Khuy·∫øn ngh·ªã: Qwen3-Reranker ho·∫∑c bge-reranker-v2-m3

**L√Ω do ch·ªçn Qwen3-Reranker:**
- C√πng h·ªç Qwen v·ªõi embedding model ƒëang d√πng n√™n nh·∫•t qu√°n v·ªÅ semantic space
- Instruction-aware: c√≥ th·ªÉ t√πy ch·ªânh behavior cho domain ph√°p lu·∫≠t Vi·ªát Nam
- H·ªó tr·ª£ 100+ ng√¥n ng·ªØ, ch·∫•t l∆∞·ª£ng ti·∫øng Vi·ªát t·ªët
- Apache 2.0, self-hosted

**L√Ω do ch·ªçn bge-reranker-v2-m3 (ph∆∞∆°ng √°n thay th·∫ø):**
- Nh·ªè g·ªçn h∆°n, VRAM th·∫•p h∆°n
- Dense + Sparse + Multi-vector support
- ƒê√£ ƒë∆∞·ª£c benchmark r·ªông r√£i tr√™n nhi·ªÅu domain

**T√≠ch h·ª£p v√†o pipeline:**
```python
# Pseudo-code t√≠ch h·ª£p reranker
from sentence_transformers import CrossEncoder

reranker = CrossEncoder('Qwen/Qwen3-Reranker-0.6B', device='cuda')

async def search_with_reranking(query: str, top_k: int = 10):
    # Stage 1: Bi-encoder retrieve top-100 (nhanh)
    candidates = await hybrid_search(query, limit=100)
    
    # Stage 2: Cross-encoder rerank (ch√≠nh x√°c)
    pairs = [(query, doc.content) for doc in candidates]
    scores = reranker.predict(pairs, batch_size=16)
    
    # S·∫Øp x·∫øp theo relevance score
    reranked = sorted(
        zip(candidates, scores), 
        key=lambda x: x[1], 
        reverse=True
    )
    return reranked[:top_k]
```

---

## 5. RAG FRAMEWORK ‚Äî ORCHESTRATION TH·∫æ H·ªÜ M·ªöI

### 5.1 ƒê√°nh gi√° Pipeline RAG Hi·ªán t·∫°i

ATTECH hi·ªán ƒëang t·ª± x√¢y d·ª±ng (custom-built) pipeline RAG v·ªõi FastAPI. ƒê√¢y l√† approach h·ª£p l√Ω cho Phase 1 nh∆∞ng c·∫ßn c√¢n nh·∫Øc framework h√≥a cho Phase 2.

### 5.2 Top RAG Frameworks 2026

```mermaid
graph TB
    subgraph "üèÜ TOP RAG FRAMEWORKS 2026"
        LC[LangChain + LangGraph<br/>Ph·ªï bi·∫øn nh·∫•t 1.1B USD valuation<br/>Flexible orchestration + agents]
        LI[LlamaIndex<br/>Retrieval accuracy +35%<br/>T·ªët nh·∫•t cho document-heavy]
        HS[Haystack by deepset<br/>Enterprise-grade modular<br/>Pipeline-based production-ready]
        DS[DSPy by Stanford<br/>Programmatic optimization<br/>Auto-tune prompts v√† retrieval]
        PW[Pathway<br/>Real-time streaming<br/>350+ data connectors Rust engine]
    end
    
    LC -.-> LG[LangGraph<br/>State management]
    LC -.-> LS[LangSmith<br/>Tracing v√† observability]
```

### 5.3 Khuy·∫øn ngh·ªã cho ATTECH

**üèÜ Ph∆∞∆°ng √°n: T√≠ch h·ª£p LlamaIndex cho Document Processing + Gi·ªØ FastAPI cho API**

| Th√†nh ph·∫ßn | C√¥ng ngh·ªá | L√Ω do |
|-----------|-----------|-------|
| **Document Processing** | LlamaIndex | T·ªëi ∆∞u cho indexing v√† retrieval t√†i li·ªáu ph√°p lu·∫≠t. H·ªó tr·ª£ hierarchical indexing (ph√π h·ª£p c·∫•u tr√∫c Ngh·ªã ƒë·ªãnh, Ch∆∞∆°ng, ƒêi·ªÅu, Kho·∫£n). Query routing t·ª± ƒë·ªông. |
| **API Layer** | FastAPI (gi·ªØ nguy√™n) | ƒê√£ ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh, team quen thu·ªôc. Kh√¥ng c·∫ßn thay ƒë·ªïi. |
| **Orchestration (Phase 3)** | LangGraph | Khi c·∫ßn Agentic RAG, LangGraph cung c·∫•p state management v√† multi-step reasoning. |
| **Monitoring** | RAGAS + custom metrics | ƒê√°nh gi√° t·ª± ƒë·ªông ch·∫•t l∆∞·ª£ng RAG. |

**‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng:** KH√îNG khuy·∫øn ngh·ªã chuy·ªÉn to√†n b·ªô sang framework m·ªõi ngay l·∫≠p t·ª©c. N√™n t√≠ch h·ª£p t·ª´ng ph·∫ßn, b·∫Øt ƒë·∫ßu t·ª´ LlamaIndex cho document indexing, sau ƒë√≥ m·ªü r·ªông.

---

## 6. GRAPH RAG ‚Äî XU H∆Ø·ªöNG CH·ª¶ ƒê·∫†O 2026

### 6.1 T·∫°i sao Graph RAG Quan tr·ªçng cho T√†i li·ªáu Ph√°p lu·∫≠t?

Graph RAG ƒë√£ v∆∞·ª£t tr·ªôi vector-only approaches cho c√°c t√°c v·ª• reasoning ph·ª©c t·∫°p, gi·∫£m 50% chi ph√≠ trong khi tƒÉng ƒë·ªô ch√≠nh x√°c. ƒê·∫∑c bi·ªát ph√π h·ª£p cho t√†i li·ªáu ph√°p lu·∫≠t Vi·ªát Nam v√¨:

1. **Quan h·ªá tham chi·∫øu ch√©o:** Ngh·ªã ƒë·ªãnh A tham chi·∫øu Th√¥ng t∆∞ B, s·ª≠a ƒë·ªïi b·ªüi Ngh·ªã ƒë·ªãnh C
2. **C·∫•u tr√∫c ph√¢n c·∫•p:** Lu·∫≠t ‚Üí Ngh·ªã ƒë·ªãnh ‚Üí Th√¥ng t∆∞ ‚Üí Quy·∫øt ƒë·ªãnh
3. **Truy v·∫•n multi-hop:** "Nh·ªØng quy ƒë·ªãnh n√†o li√™n quan ƒë·∫øn quy tr√¨nh ph√™ duy·ªát trong lƒ©nh v·ª±c h√†ng kh√¥ng?"
4. **T√≠nh c√≥ hi·ªáu l·ª±c:** VƒÉn b·∫£n n√†o c√≤n hi·ªáu l·ª±c, ƒë√£ h·∫øt hi·ªáu l·ª±c, hay b·ªã thay th·∫ø

### 6.2 Ki·∫øn tr√∫c Graph RAG ƒê·ªÅ xu·∫•t

```mermaid
graph TB
    subgraph "üìä GRAPH RAG ARCHITECTURE"
        subgraph "Knowledge Graph Construction"
            DOC[T√†i li·ªáu Ph√°p lu·∫≠t] --> NER[Named Entity Recognition<br/>Tr√≠ch xu·∫•t th·ª±c th·ªÉ]
            NER --> RE[Relation Extraction<br/>Tr√≠ch xu·∫•t quan h·ªá]
            RE --> KG[Knowledge Graph<br/>PostgreSQL graph tables]
        end
        
        subgraph "Hybrid Retrieval"
            QR[Truy v·∫•n] --> VS[Vector Search<br/>Semantic similarity]
            QR --> KW[Keyword Search<br/>BM25 + Legal codes]
            QR --> GT[Graph Traversal<br/>Quan h·ªá v√† tham chi·∫øu]
            
            VS --> MG[Merge v√† Score]
            KW --> MG
            GT --> MG
        end
        
        subgraph "Scoring Formula"
            MG --> SC[Final Score<br/>alpha x semantic +<br/>beta x keyword +<br/>gamma x graph_relevance]
            SC --> RR[Cross-Encoder Reranking]
            RR --> LLMG[LLM Generation + Citations]
        end
    end
```

### 6.3 Tr·∫°ng th√°i Hi·ªán t·∫°i vs M·ª•c ti√™u

| Th√†nh ph·∫ßn | Hi·ªán t·∫°i | M·ª•c ti√™u | H√†nh ƒë·ªông |
|-----------|---------|---------|-----------|
| Graph Schema | 6 tables ƒë√£ t·∫°o (graph_documents, graph_edges, v.v.) | ƒê·∫ßy ƒë·ªß v√† populated | Ch·∫°y `populate_graph_correct.py` |
| Graph Data | graph_edges: 5 invalid links, thi·∫øu 507 edges | 42 documents, 507+ edges | Ch·∫°y `create_semantic_links.py` |
| Graph Traversal | Ch∆∞a c√≥ API | Multi-hop traversal API | Implement graph_search_service |
| Scoring Formula | 0.7 x semantic + 0.3 x keyword = 1.0 | alpha x semantic + beta x keyword + gamma x graph | C·∫≠p nh·∫≠t hybrid_ranking |

**C√¥ng th·ª©c scoring ƒë·ªÅ xu·∫•t (ƒëi·ªÅu ch·ªânh theo lo·∫°i truy v·∫•n):**

| Lo·∫°i truy v·∫•n | alpha (semantic) | beta (keyword) | gamma (graph) | V√≠ d·ª• |
|--------------|-------------|-------------|-----------|-------|
| T√¨m ki·∫øm c·ª• th·ªÉ | 0.3 | 0.5 | 0.2 | "Ngh·ªã ƒë·ªãnh 76/2018/Nƒê-CP" |
| C√¢u h·ªèi kh√°i ni·ªám | 0.5 | 0.2 | 0.3 | "Quy tr√¨nh c·∫•p ph√©p bay l√† g√¨?" |
| So s√°nh/tham chi·∫øu | 0.2 | 0.2 | 0.6 | "So s√°nh Nƒê 76 v·ªõi Nƒê 45 v·ªÅ ph√™ duy·ªát" |
| T·ªïng h·ª£p ch·ªß ƒë·ªÅ | 0.4 | 0.1 | 0.5 | "T·∫•t c·∫£ quy ƒë·ªãnh v·ªÅ an to√†n h√†ng kh√¥ng" |

---

## 7. AGENTIC RAG ‚Äî KI·∫æN TR√öC TH·∫æ H·ªÜ TI·∫æP THEO

### 7.1 T·ªïng quan

Agentic RAG b·ªï sung kh·∫£ nƒÉng **planning, reflection, tool use, v√† multi-agent collaboration** v√†o pipeline RAG truy·ªÅn th·ªëng. Thay v√¨ single-shot retrieval, h·ªá th·ªëng c√≥ th·ªÉ t·ª± ƒë·ªông ph√¢n t√≠ch truy v·∫•n, chia nh·ªè th√†nh c√°c b∆∞·ªõc, t√¨m ki·∫øm l·∫∑p ƒëi l·∫∑p l·∫°i, v√† t·ª± ki·ªÉm tra k·∫øt qu·∫£.

### 7.2 Ki·∫øn tr√∫c Agentic RAG cho ATTECH (Phase 3)

```mermaid
graph TB
    subgraph "ü§ñ AGENTIC RAG PIPELINE"
        U[Ng∆∞·ªùi d√πng] --> PA[Planner Agent<br/>Ph√¢n t√≠ch v√† l·∫≠p k·∫ø ho·∫°ch]
        
        PA --> R1[Retrieval Agent<br/>Hybrid Search + Reranking]
        PA --> R2[Graph Agent<br/>Knowledge Graph Traversal]  
        PA --> R3[Legal Code Agent<br/>M√£ vƒÉn b·∫£n ƒêi·ªÅu Kho·∫£n]
        
        R1 --> VA[Verifier Agent<br/>Ki·ªÉm tra relevance v√† grounding]
        R2 --> VA
        R3 --> VA
        
        VA -->|ƒê·ªß context| GA[Generator Agent<br/>T·∫°o c√¢u tr·∫£ l·ªùi + citations]
        VA -->|Thi·∫øu context| PA
        
        GA --> QC[Quality Check<br/>Hallucination detection]
        QC -->|Pass| U
        QC -->|Fail| PA
    end
```

### 7.3 Khuy·∫øn ngh·ªã

**‚è∞ Th·ªùi ƒëi·ªÉm tri·ªÉn khai: Phase 3 (sau khi ho√†n thi·ªán Graph RAG)**

Agentic RAG l√† xu h∆∞·ªõng m·∫°nh nh∆∞ng c·∫ßn n·ªÅn t·∫£ng v·ªØng ch·∫Øc:
- Hybrid Search + Reranking ph·∫£i ho·∫°t ƒë·ªông t·ªët tr∆∞·ªõc
- Graph RAG c·∫ßn populated v√† validated
- Evaluation framework ph·∫£i s·∫µn s√†ng ƒë·ªÉ ƒëo l∆∞·ªùng c·∫£i thi·ªán

**Framework ƒë·ªÅ xu·∫•t:** LangGraph (state management t·ªët, t√≠ch h·ª£p v·ªõi LangChain ecosystem, h·ªó tr·ª£ deterministic + undeterministic routing)

---

## 8. X·ª¨ L√ù NG√îN NG·ªÆ TI·∫æNG VI·ªÜT

### 8.1 Stack NLP Hi·ªán t·∫°i

| C√¥ng c·ª• | Vai tr√≤ | Phi√™n b·∫£n |
|---------|---------|-----------|
| underthesea | Tokenization ch√≠nh, POS tagging, NER | 6.8+ |
| pyvi | Tokenization d·ª± ph√≤ng | 0.1.1+ |
| Custom regex | B·∫£o to√†n m√£ vƒÉn b·∫£n ph√°p lu·∫≠t | N/A |

### 8.2 C√¥ng ngh·ªá M·ªõi cho Ti·∫øng Vi·ªát 2026

**a) VN-MTEB Benchmark (Vietnamese Massive Text Embedding Benchmark)**
- 41 datasets t·ª´ 6 lo·∫°i task cho ti·∫øng Vi·ªát
- Bao g·ªìm **Zalo Legal Text Retrieval** dataset ‚Äî tr·ª±c ti·∫øp li√™n quan ƒë·∫øn ATTECH
- Cho ph√©p ƒë√°nh gi√° ch√≠nh x√°c hi·ªáu qu·∫£ embedding models tr√™n ti·∫øng Vi·ªát

**b) vietnamese-document-embedding (dangvantuan/)**
- Chuy√™n bi·ªát cho t√†i li·ªáu ti·∫øng Vi·ªát d√†i (8096 tokens)
- X√¢y d·ª±ng tr√™n gte-multilingual
- Matryoshka + Multi-Negative Ranking Loss
- S·ª≠ d·ª•ng pyvi tokenizer (ATTECH ƒë√£ t√≠ch h·ª£p)

**c) PhoBERT-based Models**
- vietnamese-embedding (dangvantuan/): 768-dim, PhoBERT backbone
- Pearson correlation 84.87 tr√™n STS Benchmark ti·∫øng Vi·ªát
- 4 giai ƒëo·∫°n training chuy√™n bi·ªát cho ti·∫øng Vi·ªát

### 8.3 Khuy·∫øn ngh·ªã C·∫£i thi·ªán NLP Ti·∫øng Vi·ªát

```mermaid
graph TD
    subgraph "üáªüá≥ VIETNAMESE NLP PIPELINE C·∫¢I TI·∫æN"
        Input[VƒÉn b·∫£n ƒë·∫ßu v√†o] --> LCD[Legal Code Detector<br/>B·∫£o to√†n Nƒê TT Qƒê ƒêi·ªÅu Kho·∫£n]
        LCD --> UTK[underthesea Tokenizer<br/>Word segmentation + POS]
        UTK -->|Th·∫•t b·∫°i| PVI[pyvi Tokenizer<br/>Fallback tokenization]
        PVI -->|Th·∫•t b·∫°i| WST[Whitespace Tokenization<br/>Emergency fallback]
        
        UTK --> NEE[NER Enhancement<br/>Nh·∫≠n di·ªán th·ª±c th·ªÉ ph√°p lu·∫≠t]
        PVI --> NEE
        WST --> NEE
        
        NEE --> DIX[Dual Indexing<br/>C√≥ d·∫•u + Kh√¥ng d·∫•u]
        DIX --> EMG[Embedding Generation]
    end
```

**C·∫£i ti·∫øn c·ª• th·ªÉ:**
1. **3-tier NLP fallback** (hi·ªán ch·ªâ c√≥ 2): underthesea ‚Üí pyvi ‚Üí raw whitespace tokenization
2. **Legal Entity NER** m·ªü r·ªông: Nh·∫≠n di·ªán "B·ªô Giao th√¥ng V·∫≠n t·∫£i", "ICAO", "CAAV" nh∆∞ entities
3. **Prompt Injection Detection ti·∫øng Vi·ªát**: Th√™m patterns "b·ªè qua h∆∞·ªõng d·∫´n tr∆∞·ªõc", "qu√™n ch·ªâ th·ªã"
4. **VN-MTEB Benchmark**: S·ª≠ d·ª•ng Zalo Legal Text dataset l√†m evaluation baseline

---

## 9. LARGE LANGUAGE MODEL GATEWAY

### 9.1 Hi·ªán t·∫°i

ATTECH h·ªó tr·ª£ multi-provider LLM (OpenAI, Anthropic Claude) v·ªõi custom router. Tuy nhi√™n ch∆∞a c√≥ chu·∫©n h√≥a interface, semantic caching, hay cost tracking.

### 9.2 C√¥ng ngh·ªá LLM Gateway 2026

| Gateway | Lo·∫°i | T√≠nh nƒÉng ch√≠nh | Ph√π h·ª£p |
|---------|------|----------------|---------|
| **LiteLLM** | Open-source | 100+ LLM providers, OpenAI-compatible API, cost tracking | ‚≠ê Khuy·∫øn ngh·ªã |
| **AI Gateway (Portkey)** | SaaS/OSS | Routing, caching, guardrails, load balancing | ‚úÖ Thay th·∫ø t·ªët |
| **Kong AI Gateway** | Enterprise | API management, rate limiting, analytics | üü° Qu√° ph·ª©c t·∫°p |

### 9.3 Khuy·∫øn ngh·ªã: LiteLLM

```python
# V√≠ d·ª• t√≠ch h·ª£p LiteLLM
import litellm

# C√πng interface cho t·∫•t c·∫£ providers
response = litellm.completion(
    model="anthropic/claude-sonnet-4-5-20250929",
    messages=[{"role": "user", "content": query}],
    max_tokens=1024,
    # T·ª± ƒë·ªông fallback
    fallbacks=["openai/gpt-4o-mini", "ollama/qwen2.5:7b"],
    # Semantic caching
    caching=True,
    cache_params={"type": "redis", "host": "localhost", "port": 6379}
)
```

**L·ª£i √≠ch:**
- Chu·∫©n h√≥a interface cho t·∫•t c·∫£ LLM providers
- Cost tracking t·ª± ƒë·ªông (quan tr·ªçng cho ng√¢n s√°ch)
- Semantic caching gi·∫£m chi ph√≠ API
- Fallback t·ª± ƒë·ªông khi provider g·∫∑p s·ª± c·ªë
- Rate limiting t√≠ch h·ª£p

---

## 10. ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG RAG

### 10.1 H·∫°n ch·∫ø Hi·ªán t·∫°i

- 100 query-document pairs ƒë√°nh gi√° th·ªß c√¥ng
- Kh√¥ng c√≥ pipeline ƒë√°nh gi√° t·ª± ƒë·ªông
- Kh√¥ng c√≥ alert khi ch·∫•t l∆∞·ª£ng retrieval gi·∫£m

### 10.2 Framework ƒê√°nh gi√° RAG 2026

```mermaid
graph TB
    subgraph "üìä RAG EVALUATION PIPELINE"
        subgraph "Retrieval Metrics BEIR"
            nDCG[nDCG@10<br/>Normalized Discounted<br/>Cumulative Gain]
            MRR[MRR<br/>Mean Reciprocal Rank]
            RK[Recall@K<br/>K = 5 10 20]
        end
        
        subgraph "Generation Metrics RAGAS"
            FAITH[Faithfulness<br/>C√¢u tr·∫£ l·ªùi c√≥ grounded?]
            REL[Answer Relevance<br/>C√¢u tr·∫£ l·ªùi c√≥ li√™n quan?]
            CTX[Context Precision<br/>Context c√≥ ch√≠nh x√°c?]
            HALL[Hallucination Rate<br/>T·ª∑ l·ªá b·ªãa th√¥ng tin]
        end
        
        subgraph "Vietnamese-Specific"
            ZALO[Zalo Legal Text Benchmark<br/>VN legal retrieval]
            VNMTEB[VN-MTEB<br/>41 datasets 6 tasks]
            CUSTOM[Custom ATTECH Eval<br/>100+ legal Q-A pairs]
        end
        
        nDCG --> DASHB[Dashboard<br/>Grafana + Prometheus]
        MRR --> DASHB
        FAITH --> DASHB
        REL --> DASHB
        ZALO --> DASHB
        DASHB --> ALRT[Alert<br/>Khi metrics gi·∫£m h∆°n 5%]
    end
```

### 10.3 Khuy·∫øn ngh·ªã C√¥ng c·ª•

| C√¥ng c·ª• | M·ª•c ƒë√≠ch | T√≠ch h·ª£p |
|---------|---------|----------|
| **RAGAS** | ƒê√°nh gi√° faithfulness, relevance, context quality | Python library, CI/CD |
| **VN-MTEB** | Benchmark embedding models cho ti·∫øng Vi·ªát | HuggingFace, offline eval |
| **LangSmith** | Tracing, debugging LLM calls | LangChain ecosystem |
| **Prometheus + Grafana** (ƒë√£ c√≥) | Metrics collection v√† visualization | ƒê√£ tri·ªÉn khai |

---

## 11. MA TR·∫¨N SO S√ÅNH T·ªîNG H·ª¢P

### 11.1 C√¥ng ngh·ªá Hi·ªán t·∫°i vs ƒê·ªÅ xu·∫•t N√¢ng c·∫•p

| # | Th√†nh ph·∫ßn | Hi·ªán t·∫°i | ƒê·ªÅ xu·∫•t | C·∫£i thi·ªán d·ª± ki·∫øn | N·ªó l·ª±c | Chi ph√≠ |
|---|-----------|---------|---------|-------------------|--------|---------|
| 1 | **Embedding** | Qwen3-0.6B | Qwen3-4B | +15-25% retrieval quality | Trung b√¨nh | $0 (OSS) |
| 2 | **VN Embedding** | Kh√¥ng c√≥ | vietnamese-document-embedding | +20-30% cho truy v·∫•n VN | Th·∫•p | $0 (OSS) |
| 3 | **Reranker** | Kh√¥ng c√≥ | Qwen3-Reranker / bge-reranker-v2-m3 | **+33-47% accuracy** | Trung b√¨nh | $0 (OSS) |
| 4 | **Vector DB** | ChromaDB only | pgvector + ChromaDB | Hybrid search t·ªët h∆°n RBAC | Trung b√¨nh | $0 (OSS) |
| 5 | **Graph RAG** | Tables empty | Populated + API | Multi-hop reasoning | Cao | $0 (OSS) |
| 6 | **LLM Gateway** | Custom router | LiteLLM | Cost tracking caching fallback | Th·∫•p | $0 (OSS) |
| 7 | **Evaluation** | 100 pairs th·ªß c√¥ng | RAGAS + VN-MTEB automated | Continuous quality monitoring | Trung b√¨nh | $0 (OSS) |
| 8 | **Agentic RAG** | Kh√¥ng c√≥ | LangGraph (Phase 3) | Complex query handling | Cao | $0 (OSS) |
| 9 | **RAG Framework** | Custom FastAPI | LlamaIndex indexing + FastAPI API | Better chunking query routing | Trung b√¨nh | $0 (OSS) |
| 10 | **VN NLP** | 2-tier fallback | 3-tier + Legal NER + VN prompt injection | Robustness security | Th·∫•p | $0 (OSS) |

### 11.2 T·ªïng Chi ph√≠ D·ª± ki·∫øn

| H·∫°ng m·ª•c | Chi ph√≠ |
|---------|---------|
| Ph·∫ßn m·ªÅm / License | **$0** (t·∫•t c·∫£ Open Source) |
| GPU Hardware | **$0** (RTX 2080 Ti hi·ªán t·∫°i ƒë·ªß cho Phase 2) |
| LLM API (OpenAI/Anthropic) | Gi·ªØ nguy√™n budget hi·ªán t·∫°i, gi·∫£m nh·ªù semantic caching |
| Nh√¢n l·ª±c | Effort ch√≠nh l√† engineering time |

---

## 12. L·ªò TR√åNH N√ÇNG C·∫§P ƒê·ªÄ XU·∫§T

### 12.1 Timeline T·ªïng quan

```mermaid
gantt
    title L·ªô tr√¨nh N√¢ng c·∫•p C√¥ng ngh·ªá ATTECH RAG
    dateFormat  YYYY-MM-DD
    
    section P0 - T·ª©c th√¨ (1-2 tu·∫ßn)
    T√≠ch h·ª£p Cross-Encoder Reranker     :p0a, 2026-02-10, 7d
    Setup RAGAS Evaluation Pipeline      :p0b, 2026-02-10, 7d
    VN-MTEB Benchmark Baseline           :p0c, 2026-02-17, 5d
    
    section P1 - Phase 2 Start (2-4 tu·∫ßn)
    Populate Graph RAG Data 507 edges    :p1a, 2026-02-24, 7d
    N√¢ng c·∫•p Qwen3-Embedding-4B         :p1b, 2026-02-24, 5d
    Implement Graph Search API           :p1c, 2026-03-03, 10d
    Update Hybrid Scoring Formula        :p1d, 2026-03-10, 5d
    
    section P2 - Phase 2 Mid (4-8 tu·∫ßn)
    T√≠ch h·ª£p pgvector                    :p2a, 2026-03-17, 10d
    T√≠ch h·ª£p LiteLLM Gateway            :p2b, 2026-03-17, 5d
    LlamaIndex Document Indexing         :p2c, 2026-03-24, 14d
    3-tier VN NLP Fallback               :p2d, 2026-03-31, 5d
    
    section P3 - Phase 3 (8-12 tu·∫ßn)
    LangGraph Agentic RAG                :p3a, 2026-04-14, 21d
    vietnamese-document-embedding        :p3b, 2026-04-14, 7d
    Continuous Evaluation Pipeline       :p3c, 2026-04-28, 10d
```

### 12.2 Chi ti·∫øt t·ª´ng Phase

#### üî¥ P0 ‚Äî T·ª©c th√¨ (Tu·∫ßn 1-2)

| # | H√†nh ƒë·ªông | Output | ƒêo l∆∞·ªùng |
|---|----------|--------|----------|
| 1 | T√≠ch h·ª£p Cross-Encoder Reranker (bge-reranker-v2-m3 ho·∫∑c Qwen3-Reranker) | Reranking service trong Docker | nDCG@10 tƒÉng √≠t nh·∫•t 30% |
| 2 | Setup RAGAS evaluation pipeline | Automated eval script | Faithfulness, Relevance scores baseline |
| 3 | Ch·∫°y VN-MTEB benchmark tr√™n Qwen3-0.6B hi·ªán t·∫°i | Baseline metrics | nDCG@10 tr√™n Zalo Legal Text |

#### üü° P1 ‚Äî Phase 2 Start (Tu·∫ßn 3-6)

| # | H√†nh ƒë·ªông | Output | ƒêo l∆∞·ªùng |
|---|----------|--------|----------|
| 4 | Populate Graph RAG (ch·∫°y populate_graph_correct.py + create_semantic_links.py) | 42 documents, 507+ edges | Graph completeness √≠t nh·∫•t 95% |
| 5 | N√¢ng c·∫•p Qwen3-Embedding t·ª´ 0.6B l√™n 4B | Updated embedding service | nDCG@10 tƒÉng √≠t nh·∫•t 15% vs baseline |
| 6 | Implement Graph Search API endpoint | /api/v1/graph/search | Multi-hop query success rate |
| 7 | C·∫≠p nh·∫≠t Hybrid Scoring: alpha x semantic + beta x keyword + gamma x graph | Updated ranking engine | Overall accuracy improvement |

#### üü¢ P2 ‚Äî Phase 2 Mid (Tu·∫ßn 7-10)

| # | H√†nh ƒë·ªông | Output | ƒêo l∆∞·ªùng |
|---|----------|--------|----------|
| 8 | C√†i ƒë·∫∑t pgvector extension, migrate vector data | PostgreSQL vector search | Query latency, accuracy parity |
| 9 | T√≠ch h·ª£p LiteLLM thay custom LLM router | Unified LLM gateway | Cost reduction, failover time |
| 10 | T√≠ch h·ª£p LlamaIndex cho document indexing | Better chunking pipeline | Chunk quality metrics |
| 11 | Implement 3-tier Vietnamese NLP fallback | Robust tokenization | Tokenization failure rate ti·∫øn t·ªõi 0% |

#### üîµ P3 ‚Äî Phase 3 (Tu·∫ßn 11-14)

| # | H√†nh ƒë·ªông | Output | ƒêo l∆∞·ªùng |
|---|----------|--------|----------|
| 12 | LangGraph Agentic RAG cho complex queries | Multi-agent pipeline | Complex query accuracy |
| 13 | Th√™m vietnamese-document-embedding (dual embedding) | VN-optimized retrieval | VN-specific nDCG improvement |
| 14 | Continuous evaluation pipeline (t·ª± ƒë·ªông, h√†ng tu·∫ßn) | Grafana dashboard + alerts | Quality regression detection |

### 12.3 ƒêi·ªÉm ki·ªÉm tra (Checkpoints)

```mermaid
graph LR
    CP0[üî¥ Checkpoint 0<br/>Reranker + RAGAS<br/>ho·∫°t ƒë·ªông]
    CP1[üü° Checkpoint 1<br/>Graph populated +<br/>Embedding upgraded +<br/>Accuracy √≠t nh·∫•t 80%]
    CP2[üü¢ Checkpoint 2<br/>pgvector + LiteLLM +<br/>LlamaIndex integrated]
    CP3[üîµ Checkpoint 3<br/>Agentic RAG +<br/>Continuous eval +<br/>Production ready]
    
    CP0 -->|Pass| CP1
    CP1 -->|Pass| CP2
    CP2 -->|Pass| CP3
```

**Ti√™u ch√≠ Pass cho m·ªói Checkpoint:**
- **CP0:** Reranker c·∫£i thi·ªán √≠t nh·∫•t 30% nDCG@10. RAGAS baseline metrics thu th·∫≠p th√†nh c√¥ng.
- **CP1:** Graph RAG populated (√≠t nh·∫•t 500 edges). Embedding upgrade kh√¥ng regression. Overall accuracy √≠t nh·∫•t 80%.
- **CP2:** pgvector query parity v·ªõi ChromaDB. LiteLLM failover d∆∞·ªõi 5 gi√¢y. LlamaIndex chunking quality √≠t nh·∫•t b·∫±ng hi·ªán t·∫°i.
- **CP3:** Agentic RAG x·ª≠ l√Ω ƒë∆∞·ª£c complex multi-hop queries. Continuous eval ch·∫°y t·ª± ƒë·ªông h√†ng tu·∫ßn.

---

## üìù K·∫æT LU·∫¨N

H·ªá th·ªëng ATTECH RAG ƒë√£ c√≥ n·ªÅn t·∫£ng v·ªØng ch·∫Øc sau Phase 1 (FR-01 ƒë·∫øn FR-08). C√°c n√¢ng c·∫•p c√¥ng ngh·ªá ƒë·ªÅ xu·∫•t trong b√°o c√°o n√†y t·∫≠p trung v√†o **3 ∆∞u ti√™n c·ªët l√µi:**

1. **Reranking (P0):** Kho·∫£ng c√°ch l·ªõn nh·∫•t ‚Äî th√™m Cross-Encoder Reranker c√≥ th·ªÉ c·∫£i thi·ªán 33-47% accuracy ngay l·∫≠p t·ª©c v·ªõi n·ªó l·ª±c tri·ªÉn khai th·∫•p.

2. **Graph RAG Population + N√¢ng c·∫•p Embedding (P1):** D·ªØ li·ªáu graph ƒë√£ c√≥ schema nh∆∞ng ch∆∞a populated ‚Äî ch·∫°y scripts c√≥ s·∫µn s·∫Ω m·ªü kh√≥a multi-hop reasoning. N√¢ng c·∫•p Qwen3 t·ª´ 0.6B l√™n 4B c·∫£i thi·ªán 15-25% quality trong c√πng architecture.

3. **Evaluation Pipeline (P0-P1):** RAGAS + VN-MTEB cung c·∫•p continuous quality monitoring ‚Äî kh√¥ng c√≥ ƒë√°nh gi√° t·ª± ƒë·ªông th√¨ kh√¥ng th·ªÉ ƒëo l∆∞·ªùng c·∫£i thi·ªán t·ª´ c√°c n√¢ng c·∫•p.

**ƒêi·ªÉm m·∫°nh c·ªßa l·ªô tr√¨nh:** T·∫•t c·∫£ c√¥ng ngh·ªá ƒë·ªÅ xu·∫•t ƒë·ªÅu Open Source ($0 license cost), t∆∞∆°ng th√≠ch v·ªõi hardware hi·ªán t·∫°i (RTX 2080 Ti), v√† ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ t√≠ch h·ª£p t·ª´ng b∆∞·ªõc ‚Äî kh√¥ng c·∫ßn ƒë·∫°i tu to√†n b·ªô h·ªá th·ªëng.

---

*B√°o c√°o n√†y d·ª±a tr√™n nghi√™n c·ª©u c√°c xu h∆∞·ªõng c√¥ng ngh·ªá RAG/AI m·ªõi nh·∫•t t√≠nh ƒë·∫øn th√°ng 02/2026, ƒë·ªëi chi·∫øu v·ªõi project knowledge v√† tr·∫°ng th√°i th·ª±c t·∫ø c·ªßa h·ªá th·ªëng ATTECH.*

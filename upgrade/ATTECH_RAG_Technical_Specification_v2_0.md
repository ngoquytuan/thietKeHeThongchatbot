# ƒê·∫∂C T·∫¢ K·ª∏ THU·∫¨T H·ªÜ TH·ªêNG TR·ª¢ L√ù TRI TH·ª®C N·ªòI B·ªò
## VIETNAMESE LEGAL DOCUMENT KNOWLEDGE ASSISTANT SYSTEM

---

**T√™n d·ª± √°n:** Vietnamese Legal Document Knowledge Assistant System  
**M√£ d·ª± √°n:** ATTECH-RAG-KA  
**T·ªï ch·ª©c:** ATTECH - C√¥ng ty K·ªπ thu·∫≠t Qu·∫£n l√Ω Bay (30+ nƒÉm kinh nghi·ªám)  
**Phi√™n b·∫£n:** 2.0  
**Ng√†y:** 07 th√°ng 02 nƒÉm 2026  
**Tr·∫°ng th√°i:** Production Phase 1 Ho√†n th√†nh ‚Äî Phase 2 ƒêang tri·ªÉn khai  
**C·∫≠p nh·∫≠t t·ª´:** v1.0 (29/01/2026)

---

**L·ªúI CAM K·∫æT CH·∫§T L∆Ø·ª¢NG:**
T√†i li·ªáu n√†y ƒë∆∞·ª£c so·∫°n th·∫£o tu√¢n th·ªß nghi√™m ng·∫∑t c√°c nguy√™n t·∫Øc kh√¥ng b·ªãa ƒë·∫∑t s·ªë li·ªáu (Non-Hallucination Rules). M·ªçi s·ªë li·ªáu, metric, v√† th√¥ng s·ªë k·ªπ thu·∫≠t ƒë·ªÅu c√≥ ngu·ªìn g·ªëc t·ª´ c√°c t√†i li·ªáu handover ch√≠nh th·ª©c (FR-01 ƒë·∫øn FR-08), k·∫øt qu·∫£ testing th·ª±c t·∫ø, ho·∫∑c ƒë∆∞·ª£c ƒë√°nh d·∫•u r√µ r√†ng l√† "TBD - C·∫ßn x√°c ƒë·ªãnh" k√®m l√Ω do.

**THAY ƒê·ªîI CH√çNH SO V·ªöI v1.0:**

| # | Thay ƒë·ªïi | M√¥ t·∫£ | M·ª•c |
|---|----------|-------|-----|
| 1 | ‚≠ê **N√¢ng c·∫•p Embedding Model** | Qwen3-Embedding-0.6B ‚Üí Qwen3-Embedding-4B (32K context, ch·∫•t l∆∞·ª£ng cao h∆°n 15-25%) | ¬ß4.3 |
| 2 | üî¥ **Th√™m Cross-Encoder Reranking** | T·∫ßng thi·∫øu v·∫Øng quan tr·ªçng nh·∫•t ‚Äî k·ª≥ v·ªçng c·∫£i thi·ªán +33-47% nDCG@10 | ¬ß4.4.5 |
| 3 | üï∏Ô∏è **Graph Retrieval-Augmented Generation v·∫≠n h√†nh** | T·ª´ "Planned" ‚Üí Operational: 42 t√†i li·ªáu, 507 c·∫°nh, 6 b·∫£ng ƒë√£ tri·ªÉn khai | ¬ß4.4.3 |
| 4 | üìä **Pipeline ƒë√°nh gi√° t·ª± ƒë·ªông RAGAS** | Thay th·∫ø 100 c·∫∑p th·ªß c√¥ng b·∫±ng pipeline t·ª± ƒë·ªông li√™n t·ª•c | ¬ß4.6 |
| 5 | ‚ö° **pgvector trong PostgreSQL** | B·ªï sung vector search native trong PostgreSQL ‚Äî h·ª£p nh·∫•t BM25 + vector + RBAC | ¬ß5.2 |
| 6 | üîÑ **Large Language Model Gateway (LiteLLM)** | Chu·∫©n h√≥a ƒëa nh√† cung c·∫•p Large Language Model v·ªõi semantic caching, failover, cost tracking | ¬ß4.5 |
| 7 | üáªüá≥ **N√¢ng c·∫•p x·ª≠ l√Ω ti·∫øng Vi·ªát** | Fallback 3 t·∫ßng, Legal Entity NER m·ªü r·ªông, b·∫£o v·ªá m√£ ph√°p lu·∫≠t c·∫£i ti·∫øn | ¬ß6 |
| 8 | üìê **C√¥ng th·ª©c Hybrid Scoring 3 chi·ªÅu** | Œ±√ósemantic + Œ≤√ókeyword + Œ≥√ógraph (tr·ªçng s·ªë th√≠ch ·ª©ng theo lo·∫°i truy v·∫•n) | ¬ß4.4.4 |
| 9 | üèóÔ∏è **Ki·∫øn tr√∫c h·∫° t·∫ßng c·∫≠p nh·∫≠t** | Ph·∫£n √°nh th·ª±c t·∫ø production: .70 Debian (13 services) + .88 DietPi (12 services) | ¬ß5.1, ¬ß10 |
| 10 | üìã **Lo·∫°i b·ªè m·ª•c ∆Ø·ªõc t√≠nh Chi ph√≠** | T·∫≠p trung thu·∫ßn k·ªπ thu·∫≠t theo y√™u c·∫ßu; thay b·∫±ng L·ªô tr√¨nh N√¢ng c·∫•p K·ªπ thu·∫≠t | ¬ß11 |

---

## M·ª§C L·ª§C

1. [Executive Summary](#1-executive-summary)
2. [Gi·ªõi thi·ªáu](#2-gi·ªõi-thi·ªáu)
3. [Y√™u c·∫ßu Nghi·ªáp v·ª•](#3-y√™u-c·∫ßu-nghi·ªáp-v·ª•)
4. [Y√™u c·∫ßu Artificial Intelligence/Machine Learning v√† Ki·∫øn tr√∫c Retrieval-Augmented Generation](#4-y√™u-c·∫ßu-aiml-v√†-ki·∫øn-tr√∫c-rag)
5. [Ki·∫øn tr√∫c K·ªπ thu·∫≠t](#5-ki·∫øn-tr√∫c-k·ªπ-thu·∫≠t)
6. [ƒê·∫∑c ƒëi·ªÉm X·ª≠ l√Ω Ti·∫øng Vi·ªát](#6-ƒë·∫∑c-ƒëi·ªÉm-x·ª≠-l√Ω-ti·∫øng-vi·ªát)
7. [An ninh v√† B·∫£o m·∫≠t](#7-an-ninh-v√†-b·∫£o-m·∫≠t)
8. [Y√™u c·∫ßu Phi ch·ª©c nƒÉng](#8-y√™u-c·∫ßu-phi-ch·ª©c-nƒÉng)
9. [Ki·ªÉm th·ª≠ v√† Nghi·ªám thu](#9-ki·ªÉm-th·ª≠-v√†-nghi·ªám-thu)
10. [Tri·ªÉn khai v√† V·∫≠n h√†nh](#10-tri·ªÉn-khai-v√†-v·∫≠n-h√†nh)
11. [L·ªô tr√¨nh N√¢ng c·∫•p K·ªπ thu·∫≠t](#11-l·ªô-tr√¨nh-n√¢ng-c·∫•p-k·ªπ-thu·∫≠t)
12. [Ma tr·∫≠n ƒê√°p ·ª©ng Y√™u c·∫ßu](#12-ma-tr·∫≠n-ƒë√°p-·ª©ng-y√™u-c·∫ßu)
13. [Ph·ª• l·ª•c](#13-ph·ª•-l·ª•c)

---

## 1. EXECUTIVE SUMMARY

### 1.1. T·ªïng quan D·ª± √°n

**Vietnamese Legal Document Knowledge Assistant System** l√† h·ªá th·ªëng tr·ª£ l√Ω tri th·ª©c n·ªôi b·ªô s·ª≠ d·ª•ng c√¥ng ngh·ªá Retrieval-Augmented Generation (RAG) ƒë∆∞·ª£c ph√°t tri·ªÉn cho ATTECH ‚Äî m·ªôt c√¥ng ty k·ªπ thu·∫≠t qu·∫£n l√Ω bay Vi·ªát Nam v·ªõi h∆°n 30 nƒÉm kinh nghi·ªám trong lƒ©nh v·ª±c Communication, Navigation, Surveillance / Air Traffic Management (CNS/ATM).

H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát ƒë·ªÉ x·ª≠ l√Ω t√†i li·ªáu ph√°p lu·∫≠t ti·∫øng Vi·ªát v·ªõi c·∫•u tr√∫c ph√¢n c·∫•p ph·ª©c t·∫°p v√† c√°c m√£ t√†i li·ªáu ƒë·∫∑c th√π (v√≠ d·ª•: 76/2018/Nƒê-CP), ƒë·ªìng th·ªùi h·ªó tr·ª£ 400 nh√¢n vi√™n t·∫°i 15 ph√≤ng ban trong vi·ªác truy c·∫≠p nhanh ch√≥ng c√°c t√†i li·ªáu n·ªôi b·ªô, ch√≠nh s√°ch, quy tr√¨nh v√† h∆∞·ªõng d·∫´n k·ªπ thu·∫≠t.

### 1.2. M·ª•c ti√™u Chi·∫øn l∆∞·ª£c

**M·ª•c ti√™u ch√≠nh:**
X√¢y d·ª±ng h·ªá th·ªëng chatbot Artificial Intelligence c·∫•p doanh nghi·ªáp ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho x·ª≠ l√Ω t√†i li·ªáu ph√°p lu·∫≠t ti·∫øng Vi·ªát v√† qu·∫£n l√Ω tri th·ª©c n·ªôi b·ªô.

**M·ª•c ti√™u ph·ª•:**
- H·ªó tr·ª£ 100 ng∆∞·ªùi d√πng ƒë·ªìng th·ªùi v·ªõi h·ªá th·ªëng ph√¢n quy·ªÅn 5 c·∫•p
- ƒê·∫°t ƒë·ªô ch√≠nh x√°c cao trong x·ª≠ l√Ω ng√¥n ng·ªØ ti·∫øng Vi·ªát (nDCG@10 ‚â• 0.85)
- Truy xu·∫•t hi·ªáu qu·∫£ c√°c m√£ t√†i li·ªáu ph√°p lu·∫≠t v·ªõi Cross-Encoder Reranking
- H·ªó tr·ª£ multi-hop reasoning qua Graph Retrieval-Augmented Generation
- T√≠ch h·ª£p li·ªÅn m·∫°ch v·ªõi h·∫° t·∫ßng hi·ªán c√≥ c·ªßa ATTECH
- Pipeline ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng t·ª± ƒë·ªông h√≥a li√™n t·ª•c

### 1.3. C√°c Ch·ªâ s·ªë Th√†nh c√¥ng (KPIs) ‚Äî v2.0 C·∫≠p nh·∫≠t

| Ch·ªâ s·ªë | M·ª•c ti√™u v1.0 | M·ª•c ti√™u v2.0 | Ph∆∞∆°ng ph√°p ƒêo l∆∞·ªùng |
|--------|---------------|---------------|---------------------|
| **Retrieval nDCG@10** | > 0.85 | **> 0.90** | RAGAS automated pipeline + VN-MTEB benchmark |
| **Retrieval Recall@10** | > 90% | > 90% | ƒê√°nh gi√° tr√™n 100+ c·∫∑p query-document |
| **Answer Faithfulness** | > 85% | **> 90%** | RAGAS faithfulness metric (t·ª± ƒë·ªông) |
| **Context Precision** | N/A (m·ªõi) | **> 0.85** | RAGAS context precision metric |
| **Response Time (p95)** | < 60 gi√¢y | **< 45 gi√¢y** | Load testing + Prometheus metrics |
| **Reranking Improvement** | N/A (m·ªõi) | **+30% nDCG** | A/B test tr∆∞·ªõc/sau khi t√≠ch h·ª£p Cross-Encoder |
| **Graph Completeness** | N/A (m·ªõi) | **‚â• 95%** | graph_edges / expected_edges ratio |
| **Concurrent Users** | 100 users | 100 users | Stress testing, monitoring production |
| **User Satisfaction** | > 4.0/5.0 | > 4.0/5.0 | Post-interaction survey |
| **Cache Hit Rate** | > 60% | **> 70%** | Redis metrics + semantic cache monitoring |

### 1.4. Ki·∫øn tr√∫c T·ªïng th·ªÉ v2.0

```mermaid
graph TB
    subgraph "PRESENTATION LAYER"
        UI["üñ•Ô∏è Streamlit Chat UI<br/>Real-time messaging<br/>Auto-suggestions<br/>File upload"]
    end
    
    subgraph "APPLICATION LAYER"
        API["üîå FastAPI Gateway<br/>JWT Authentication<br/>Rate Limiting<br/>Request Routing"]
        
        subgraph "RAG CORE ENGINE v2.0"
            QueryProc["üîé Query Processing<br/>Intent Classification<br/>Query Expansion<br/>Legal Code Detection"]
            Retrieval["üîç FR-04.1 Retrieval<br/>Hybrid Search 3 chi·ªÅu:<br/>Vector + BM25 + Graph"]
            Reranker["üéØ Cross-Encoder Reranker ‚≠êNEW<br/>Qwen3-Reranker<br/>+33-47% Accuracy"]
            Synthesis["üìã FR-04.2 Synthesis<br/>Context Assembly<br/>Prompt Generation"]
            Generation["‚ú® FR-04.3 Generation<br/>LiteLLM Gateway ‚≠êNEW<br/>Citation & Grounding"]
        end
        
        AuthZ["üõ°Ô∏è FR-06 Auth & AuthZ<br/>5-tier RBAC<br/>Session Management<br/>Audit Logging"]
        Analytics["üìä FR-07 Analytics<br/>Usage Tracking<br/>RAGAS Quality ‚≠êNEW<br/>Dashboards"]
        Admin["‚öôÔ∏è FR-08 Admin Tools<br/>User Management<br/>Document Management<br/>System Config"]
    end
    
    subgraph "DATA LAYER v2.0"
        Postgres[("üêò PostgreSQL 15<br/>+ pgvector ‚≠êNEW<br/>Metadata + BM25<br/>+ Vector Search<br/>+ Graph Tables")]
        Chroma[("üî¢ ChromaDB 1.0.0<br/>1024-dim Embeddings<br/>Semantic Search<br/>Dev/Prototyping")]
        Redis[("‚ö° Redis 7<br/>Query Cache<br/>Semantic Cache ‚≠êNEW<br/>Session + Rate Limit")]
    end
    
    subgraph "PROCESSING LAYER"
        Ingestion["üì• FR-03.3 Data Ingestion<br/>Vietnamese NLP 3-tier ‚≠êNEW<br/>Hierarchical Chunking<br/>Embedding Generation"]
        QualityControl["‚úÖ FR-03.2 Quality Control<br/>Document Validation<br/>Metadata Extraction<br/>Duplicate Detection"]
        EvalPipeline["üìä RAGAS Eval Pipeline ‚≠êNEW<br/>Faithfulness + Relevance<br/>Context Precision<br/>Continuous Monitoring"]
    end
    
    subgraph "AI/ML SERVICES v2.0"
        EmbedModel["üß† Qwen3-Embedding-4B ‚≠êUPGRADED<br/>1024-dimensional<br/>32K context window<br/>GPU-accelerated"]
        RerankerModel["üéØ Cross-Encoder ‚≠êNEW<br/>bge-reranker-v2-m3<br/>ho·∫∑c Qwen3-Reranker"]
        LLMGateway["ü§ñ LiteLLM Gateway ‚≠êNEW<br/>OpenAI / Anthropic / Local<br/>Semantic Caching<br/>Auto-Failover<br/>Cost Tracking"]
    end
    
    UI --> API
    API --> QueryProc
    QueryProc --> Retrieval
    API --> AuthZ
    Retrieval --> Reranker
    Reranker --> Synthesis
    Synthesis --> Generation
    Generation --> LLMGateway
    
    Retrieval --> Postgres
    Retrieval --> Chroma
    Retrieval --> Redis
    
    API --> Admin
    API --> Analytics
    EvalPipeline --> Analytics
    
    Ingestion --> QualityControl
    QualityControl --> Postgres
    QualityControl --> Chroma
    Ingestion --> EmbedModel
    
    classDef presentation fill:#e3f2fd,stroke:#1976d2
    classDef application fill:#f3e5f5,stroke:#7b1fa2
    classDef data fill:#e8f5e9,stroke:#388e3c
    classDef aiml fill:#fff3e0,stroke:#f57c00
    classDef newFeature fill:#ffebee,stroke:#c62828
    
    class UI presentation
    class API,QueryProc,Retrieval,Reranker,Synthesis,Generation,AuthZ,Analytics,Admin application
    class Postgres,Chroma,Redis data
    class EmbedModel,RerankerModel,LLMGateway aiml
```

### 1.5. T√¨nh tr·∫°ng Tri·ªÉn khai Hi·ªán t·∫°i

**Phase 1 ‚Äî HO√ÄN TH√ÄNH (110% completion):**
- ‚úÖ **FR-01:** Embedding Model Selection & Optimization (Qwen3-Embedding-0.6B)
- ‚úÖ **FR-02:** Dual Database System (PostgreSQL + ChromaDB)
- ‚úÖ **FR-03:** Data Ingestion Pipeline & Quality Control
- ‚úÖ **FR-04:** RAG Core Engine (Retrieval, Synthesis, Generation, API)
- ‚úÖ **FR-05:** Chat UI with Interactive Features
- ‚úÖ **FR-06:** Authentication & Authorization (5-tier RBAC)
- ‚úÖ **FR-07:** Analytics & Reporting
- ‚úÖ **FR-08:** Admin & Maintenance Tools

**Phase 2 ‚Äî ƒêANG TRI·ªÇN KHAI (Target: Q1/2026):**
- üî¥ **P0:** Cross-Encoder Reranking integration
- üî¥ **P0:** RAGAS evaluation pipeline setup
- üü° **P1:** Embedding upgrade Qwen3 0.6B ‚Üí 4B
- üü° **P1:** Graph Retrieval-Augmented Generation population & API integration
- üü¢ **P2:** pgvector extension & migration
- üü¢ **P2:** LiteLLM Gateway integration

**Phase 3 ‚Äî L√äN K·∫æ HO·∫†CH (Target: Q2/2026):**
- üîµ Agentic Retrieval-Augmented Generation v·ªõi LangGraph multi-agent
- üîµ vietnamese-document-embedding (dual embedding strategy)
- üîµ Pipeline ƒë√°nh gi√° li√™n t·ª•c t·ª± ƒë·ªông (weekly runs)

### 1.6. C√°c B√™n li√™n quan Ch√≠nh

| Vai tr√≤ | T√™n | Tr√°ch nhi·ªám |
|---------|-----|-------------|
| **Nh√† t√†i tr·ª£** | Ban Gi√°m ƒë·ªëc ATTECH | Ph√™ duy·ªát ng√¢n s√°ch, ƒë·ªãnh h∆∞·ªõng chi·∫øn l∆∞·ª£c |
| **Product Owner** | Tr∆∞·ªüng ph√≤ng IT | Ra quy·∫øt ƒë·ªãnh s·∫£n ph·∫©m, ∆∞u ti√™n t√≠nh nƒÉng |
| **Technical Lead** | Tuan | Ki·∫øn tr√∫c h·ªá th·ªëng, review k·ªπ thu·∫≠t, coordination |
| **Ng∆∞·ªùi d√πng cu·ªëi** | 400 nh√¢n vi√™n (15 ph√≤ng ban) | S·ª≠ d·ª•ng h·ªá th·ªëng h√†ng ng√†y |

### 1.7. Timeline

| Phase | Th·ªùi gian | M·ª•c ti√™u ch√≠nh | Tr·∫°ng th√°i |
|-------|-----------|-----------------|-----------|
| Phase 1 | 08/2025 ‚Äì 12/2025 | FR-01 ‚Üí FR-08 ho√†n th√†nh | ‚úÖ Done |
| Phase 2 | 01/2026 ‚Äì 03/2026 | Reranking + Graph RAG + Eval Pipeline | üîÑ In Progress |
| Phase 3 | 04/2026 ‚Äì 06/2026 | Agentic RAG + Dual Embedding + Continuous Eval | üìã Planned |

---

## 2. GI·ªöI THI·ªÜU

### 2.1. B·ªëi c·∫£nh D·ª± √°n

#### 2.1.1. V·ªÅ T·ªï ch·ª©c ATTECH

ATTECH (Air Traffic Equipment & Technology Company) l√† c√¥ng ty k·ªπ thu·∫≠t qu·∫£n l√Ω bay h√†ng ƒë·∫ßu Vi·ªát Nam v·ªõi h∆°n 30 nƒÉm kinh nghi·ªám trong lƒ©nh v·ª±c:
- **CNS/ATM Systems:** Communication, Navigation, Surveillance / Air Traffic Management
- **Airport Lighting:** H·ªá th·ªëng ƒë√®n s√¢n bay LED hi·ªán ƒë·∫°i
- **Mechanical Manufacturing:** S·∫£n xu·∫•t thi·∫øt b·ªã c∆° kh√≠ ch√≠nh x√°c
- **Aviation Services:** Hi·ªáu chu·∫©n bay, hu·∫•n luy·ªán, ƒë√†o t·∫°o

V·ªõi 400 nh√¢n vi√™n t·∫°i 15 ph√≤ng ban, ATTECH ph·ª•c v·ª• c√°c s√¢n bay qu·ªëc t·∫ø v√† khu v·ª±c tr√™n to√†n Vi·ªát Nam.

#### 2.1.2. V·∫•n ƒë·ªÅ Nghi·ªáp v·ª• C·∫ßn Gi·∫£i quy·∫øt

Nh√¢n vi√™n ATTECH g·∫∑p c√°c kh√≥ khƒÉn nghi√™m tr·ªçng trong vi·ªác truy c·∫≠p th√¥ng tin n·ªôi b·ªô:

**V·∫•n ƒë·ªÅ 1: Kh√≥ truy c·∫≠p T√†i li·ªáu Ph√°p lu·∫≠t** ‚Äî C·∫•u tr√∫c ph√¢n c·∫•p ph·ª©c t·∫°p (Ngh·ªã ƒë·ªãnh ‚Üí Ch∆∞∆°ng ‚Üí ƒêi·ªÅu ‚Üí Kho·∫£n), m√£ t√†i li·ªáu ƒë·∫∑c th√π kh√¥ng ƒë∆∞·ª£c c√¥ng c·ª• t√¨m ki·∫øm th√¥ng th∆∞·ªùng h·ªó tr·ª£. BM25 search fails v·ªõi legal codes do aggressive preprocessing lo·∫°i b·ªè s·ªë.

**V·∫•n ƒë·ªÅ 2: Th√¥ng tin Ph√¢n t√°n** ‚Äî Ch√≠nh s√°ch n·ªôi b·ªô, quy tr√¨nh, h∆∞·ªõng d·∫´n k·ªπ thu·∫≠t n·∫±m r·∫£i r√°c tr√™n nhi·ªÅu h·ªá th·ªëng v√† ƒë·ªãnh d·∫°ng kh√°c nhau.

**V·∫•n ƒë·ªÅ 3: Thi·∫øu Ng·ªØ c·∫£nh Li√™n k·∫øt** ‚Äî T√¨m ki·∫øm truy·ªÅn th·ªëng kh√¥ng th·ªÉ hi·ªán m·ªëi quan h·ªá gi·ªØa c√°c vƒÉn b·∫£n (vƒÉn b·∫£n n√†o thay th·∫ø/b·ªï sung/cƒÉn c·ª© v√†o vƒÉn b·∫£n n√†o).

#### 2.1.3. Gi·∫£i ph√°p ƒê·ªÅ xu·∫•t v2.0

H·ªá th·ªëng RAG v·ªõi ki·∫øn tr√∫c 3 t·∫ßng retrieval (Vector Similarity + BM25 Keyword + Graph Traversal), t√≠ch h·ª£p Cross-Encoder Reranking v√† Large Language Model Gateway th·ªëng nh·∫•t, ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a chuy√™n bi·ªát cho ti·∫øng Vi·ªát.

### 2.2. M·ª•c ti√™u v√† Ph·∫°m vi

#### 2.2.1. M·ª•c ti√™u D·ª± √°n

**B·∫Øt bu·ªôc (Must Have):**
- T√¨m ki·∫øm hybrid 3 chi·ªÅu (semantic + keyword + graph) cho t√†i li·ªáu ph√°p lu·∫≠t ti·∫øng Vi·ªát
- Cross-Encoder Reranking c·∫£i thi·ªán ‚â•30% nDCG@10
- H·ªá th·ªëng ph√¢n quy·ªÅn 5 c·∫•p (Guest, Employee, Manager, Director, System_Admin)
- Tr√≠ch d·∫´n ngu·ªìn ch√≠nh x√°c (ƒêi·ªÅu, Kho·∫£n, Trang) v·ªõi grounding verification
- Pipeline ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng t·ª± ƒë·ªông (RAGAS)
- Graph Retrieval-Augmented Generation cho multi-hop reasoning gi·ªØa c√°c vƒÉn b·∫£n

**N√™n c√≥ (Should Have):**
- Large Language Model Gateway v·ªõi semantic caching v√† auto-failover
- pgvector integration cho unified vector + metadata search
- Vietnamese-specific embedding model (dual embedding strategy)
- Continuous evaluation pipeline ch·∫°y t·ª± ƒë·ªông h√†ng tu·∫ßn

**C√≥ th·ªÉ c√≥ (Could Have):**
- Agentic Retrieval-Augmented Generation v·ªõi LangGraph multi-agent orchestration
- Graph visualization UI (D3.js / Cytoscape.js)
- Mobile Progressive Web App (PWA)

#### 2.2.2. Ph·∫°m vi D·ª± √°n

**Trong ph·∫°m vi:**
- X·ª≠ l√Ω t√†i li·ªáu ph√°p lu·∫≠t ti·∫øng Vi·ªát (Ngh·ªã ƒë·ªãnh, Quy·∫øt ƒë·ªãnh, Th√¥ng t∆∞)
- Ch√≠nh s√°ch n·ªôi b·ªô ATTECH, quy tr√¨nh, h∆∞·ªõng d·∫´n k·ªπ thu·∫≠t
- T√†i li·ªáu k·ªπ thu·∫≠t s·∫£n ph·∫©m (CNS/ATM, ƒë√®n s√¢n bay, c∆° kh√≠)
- H·ªá th·ªëng n·ªôi b·ªô on-premise cho 400 nh√¢n vi√™n
- Hi·ªán t·∫°i: 42 t√†i li·ªáu, 507 quan h·ªá graph, ~100 ng∆∞·ªùi d√πng ƒë·ªìng th·ªùi

**Ngo√†i ph·∫°m vi:**
- D·ªãch v·ª• public-facing cho kh√°ch h√†ng b√™n ngo√†i
- T√≠ch h·ª£p v·ªõi h·ªá th·ªëng ph√°p lu·∫≠t qu·ªëc gia b√™n ngo√†i
- T·∫°o/so·∫°n th·∫£o t√†i li·ªáu ph√°p lu·∫≠t m·ªõi
- Real-time collaboration gi·ªØa ng∆∞·ªùi d√πng

#### 2.2.3. R√†ng bu·ªôc D·ª± √°n

| R√†ng bu·ªôc | Chi ti·∫øt |
|-----------|---------|
| **Ph·∫ßn c·ª©ng** | NVIDIA RTX 2080 Ti (11GB VRAM), CUDA 11.8, PyTorch 2.7.1+cu118 |
| **Ng√¥n ng·ªØ** | Python 3.10.11 (b·∫Øt bu·ªôc cho underthesea, pyvi) |
| **M√£ ngu·ªìn m·ªü** | ∆Øu ti√™n Open Source ($0 license) ‚Äî Apache 2.0, MIT |
| **On-premise** | Tri·ªÉn khai n·ªôi b·ªô, kh√¥ng s·ª≠ d·ª•ng cloud infrastructure |
| **H·∫° t·∫ßng ph√¢n t√°n** | Server .70 Debian + Server .88 DietPi |
| **VRAM Budget** | T·ªïng ~10GB cho Embedding (8GB) + Reranker (2GB) tr√™n RTX 2080 Ti |

### 2.3. Gi·∫£ ƒë·ªãnh v√† Lo·∫°i tr·ª´

#### 2.3.1. Gi·∫£ ƒë·ªãnh
1. Ng∆∞·ªùi d√πng c√≥ k·ªπ nƒÉng c∆° b·∫£n s·ª≠ d·ª•ng giao di·ªán t√¨m ki·∫øm
2. T√†i li·ªáu ch·ªß y·∫øu b·∫±ng ti·∫øng Vi·ªát v√† ti·∫øng Anh
3. Tri·ªÉn khai on-premise ƒë∆∞·ª£c ∆∞u ti√™n v√¨ b·∫£o m·∫≠t d·ªØ li·ªáu
4. GPU available cho embedding generation v√† reranking
5. Internet connectivity cho Large Language Model API access (c√≥ local fallback)
6. PostgreSQL 15 v√† Redis 7 ƒë√£ s·∫µn s√†ng
7. 100 concurrent user licenses ƒë·ªß cho nhu c·∫ßu hi·ªán t·∫°i
8. T√†i li·ªáu ph√°p lu·∫≠t tu√¢n theo ƒë·ªãnh d·∫°ng chu·∫©n Ch√≠nh ph·ªß Vi·ªát Nam
9. Graph Retrieval-Augmented Generation tables ƒë√£ ƒë∆∞·ª£c tri·ªÉn khai (6 b·∫£ng, 29/12/2025)
10. Gi·∫•y ph√©p Apache 2.0 / MIT cho t·∫•t c·∫£ th√†nh ph·∫ßn m·ªõi

#### 2.3.2. Lo·∫°i tr·ª´ (Exclusions)
- Fine-tuning Large Language Model models (∆∞u ti√™n RAG approach)
- Neo4j / dedicated graph database (d√πng PostgreSQL graph tables)
- Milvus / Qdrant (over-engineering cho 42 t√†i li·ªáu, 100 users)
- Mobile native app (s·ª≠ d·ª•ng responsive web thay th·∫ø)
- Real-time document collaboration
- Kubernetes orchestration (Docker Compose ƒë·ªß cho quy m√¥ hi·ªán t·∫°i)

---

## 3. Y√äU C·∫¶U NGHI·ªÜP V·ª§

> **Ghi ch√∫ v2.0:** Ph·∫ßn n√†y gi·ªØ nguy√™n n·ªôi dung v1.0 (7 Use Cases + Business Rules). Xem chi ti·∫øt trong v1.0 ¬ß3.1‚Äì¬ß3.2. D∆∞·ªõi ƒë√¢y t√≥m t·∫Øt c√°c Use Case v√† c·∫≠p nh·∫≠t li√™n quan ƒë·∫øn v2.0.

### 3.1. Use Cases T·ªïng h·ª£p

| UC ID | T√™n | Actor | v2.0 Enhancement |
|-------|-----|-------|-----------------|
| UC-001 | T√¨m ki·∫øm T√†i li·ªáu Ph√°p lu·∫≠t theo M√£ s·ªë | Employee+ | ‚≠ê Graph traversal hi·ªán related/superseding docs |
| UC-002 | Truy v·∫•n Ch√≠nh s√°ch N·ªôi b·ªô | Employee+ | ‚≠ê Reranking c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c k·∫øt qu·∫£ |
| UC-003 | Th√¥ng tin K·ªπ thu·∫≠t S·∫£n ph·∫©m | Employee+ | Gi·ªØ nguy√™n |
| UC-004 | Truy c·∫≠p T√†i li·ªáu Compliance | Manager+ | ‚≠ê Multi-hop reasoning qua graph |
| UC-005 | ƒê√°nh gi√° Analytics H·ªá th·ªëng | Manager+ | ‚≠ê RAGAS quality metrics tr√™n dashboard |
| UC-006 | Qu·∫£n l√Ω Ng∆∞·ªùi d√πng | Admin | Gi·ªØ nguy√™n |
| UC-007 | Upload T√†i li·ªáu H√†ng lo·∫°t | Admin | ‚≠ê Auto-sync graph_documents + regenerate edges |

### 3.2. Business Rules ‚Äî v2.0 B·ªï sung

**B·ªï sung BR-GRAPH-001: Graph Synchronization**
- Khi t√†i li·ªáu m·ªõi ƒë∆∞·ª£c upload, h·ªá th·ªëng PH·∫¢I sync v√†o `graph_documents` table
- Ch·∫°y `create_semantic_links.py` sau m·ªói batch import
- Verify graph completeness ‚â• 95% (zero isolated nodes)

**B·ªï sung BR-RERANK-001: Reranking Quality**
- T·∫•t c·∫£ k·∫øt qu·∫£ search PH·∫¢I qua Cross-Encoder Reranking tr∆∞·ªõc khi tr·∫£ v·ªÅ ng∆∞·ªùi d√πng
- Reranking timeout: 2 gi√¢y ‚Äî fallback v·ªÅ hybrid ranking n·∫øu timeout

**B·ªï sung BR-EVAL-001: Quality Monitoring**
- RAGAS evaluation pipeline PH·∫¢I ch·∫°y t·ªëi thi·ªÉu 1 l·∫ßn/tu·∫ßn
- Alert n·∫øu nDCG@10 gi·∫£m > 5% so v·ªõi baseline

---

## 4. Y√äU C·∫¶U ARTIFICIAL INTELLIGENCE/MACHINE LEARNING V√Ä KI·∫æN TR√öC RETRIEVAL-AUGMENTED GENERATION

### 4.1. T·ªïng quan v·ªÅ Retrieval-Augmented Generation (RAG)

**ƒê·ªãnh nghƒ©a:**
Retrieval-Augmented Generation (RAG) l√† k·ªπ thu·∫≠t k·∫øt h·ª£p t√¨m ki·∫øm th√¥ng tin (Information Retrieval) v·ªõi m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (Large Language Model) ƒë·ªÉ sinh ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c, c√≥ ngu·ªìn g·ªëc, v√† gi·∫£m thi·ªÉu hallucination.

**L√Ω do Ch·ªçn RAG thay v√¨ Fine-tuning:**
1. **C·∫≠p nh·∫≠t D·ªØ li·ªáu D·ªÖ d√†ng:** Th√™m documents m·ªõi kh√¥ng c·∫ßn retrain model
2. **T√≠nh Minh b·∫°ch:** C√≥ th·ªÉ truy v·∫øt ngu·ªìn g·ªëc c√¢u tr·∫£ l·ªùi (citations)
3. **Chi ph√≠ Th·∫•p h∆°n:** Kh√¥ng c·∫ßn GPU clusters ƒë·ªÉ fine-tune Large Language Models
4. **Linh ho·∫°t:** C√≥ th·ªÉ switch Large Language Model providers qua LiteLLM Gateway
5. **Ki·ªÉm so√°t Ch·∫•t l∆∞·ª£ng:** Quality control t·∫°i retrieval stage + reranking stage

**Ti·∫øn h√≥a Ki·∫øn tr√∫c RAG t·∫°i ATTECH:**

```mermaid
graph LR
    subgraph "v1.0 ‚Äî Phase 1"
        A1["Bi-Encoder<br/>Vector + BM25"] --> B1["Hybrid Ranking<br/>0.7 sem + 0.3 kw"]
        B1 --> C1["LLM Direct<br/>OpenAI/Anthropic"]
    end
    
    subgraph "v2.0 ‚Äî Phase 2 ‚≠ê"
        A2["Bi-Encoder<br/>Vector + BM25 + Graph"] --> B2["Cross-Encoder<br/>Reranker ‚≠êNEW"]
        B2 --> C2["LiteLLM Gateway ‚≠êNEW<br/>Multi-provider + Cache"]
    end
    
    subgraph "v3.0 ‚Äî Phase 3"
        A3["Multi-Agent<br/>LangGraph Planning"] --> B3["Specialized<br/>Agent Routing"]
        B3 --> C3["Verified<br/>Generation + Eval"]
    end
    
    A1 -.->|upgrade| A2
    A2 -.->|upgrade| A3
```

### 4.2. RAG Pipeline Architecture v2.0

H·ªá th·ªëng RAG v2.0 s·ª≠ d·ª•ng **Three-Stage Hybrid Approach** v·ªõi Reranking:

```mermaid
graph TD
    subgraph "INPUT LAYER"
        Query["üë§ User Query"]
    end
    
    subgraph "QUERY PROCESSING"
        QueryAnalysis["üîç Query Analysis<br/>- Intent classification<br/>- Entity extraction<br/>- Legal code detection"]
        QueryExpansion["üìù Query Expansion<br/>- Synonym dictionary (200+)<br/>- Legal abbreviations<br/>- Vietnamese variants<br/>- Tone-removed variants"]
    end
    
    subgraph "STAGE 1: RETRIEVAL ‚Äî Parallel Execution ‚ö°~50ms"
        VectorSearch["üî¢ Vector Similarity<br/>ChromaDB + pgvector ‚≠ê<br/>Qwen3-4B Embeddings ‚≠ê<br/>Top 50 results"]
        BM25Search["üìÑ BM25 Full-Text<br/>PostgreSQL<br/>Legal code preserved<br/>Top 50 results"]
        GraphSearch["üï∏Ô∏è Graph Traversal ‚≠êOPERATIONAL<br/>507 edges, 42 documents<br/>Multi-hop reasoning<br/>Confidence decay 0.8^hop"]
    end
    
    subgraph "STAGE 2: FUSION & RERANKING ‚≠êNEW ~200-400ms"
        HybridFusion["‚öñÔ∏è Hybrid Fusion<br/>Œ±√ósemantic + Œ≤√ókeyword + Œ≥√ógraph<br/>Adaptive weights by intent<br/>Top 100 candidates"]
        CrossEncoder["üéØ Cross-Encoder Reranking ‚≠êNEW<br/>bge-reranker-v2-m3<br/>ho·∫∑c Qwen3-Reranker<br/>Top 10 final results"]
    end
    
    subgraph "STAGE 3: SYNTHESIS & GENERATION"
        ContextAssembly["üìã Context Assembly<br/>Chunk selection + token mgmt<br/>Hierarchy context injection<br/>Max 6500 tokens context"]
        LLMGeneration["ü§ñ LLM Generation<br/>LiteLLM Gateway ‚≠êNEW<br/>Citation injection<br/>Grounding verification"]
    end
    
    subgraph "EVALUATION LAYER ‚≠êNEW"
        RAGASEval["üìä RAGAS Evaluation<br/>Faithfulness + Relevance<br/>Context Precision<br/>Continuous monitoring"]
    end
    
    subgraph "OUTPUT LAYER"
        Response["üí¨ Final Response<br/>Answer + Citations<br/>+ Related docs<br/>+ Graph connections"]
    end
    
    Query --> QueryAnalysis
    QueryAnalysis --> QueryExpansion
    QueryExpansion --> VectorSearch
    QueryExpansion --> BM25Search
    QueryExpansion --> GraphSearch
    
    VectorSearch --> HybridFusion
    BM25Search --> HybridFusion
    GraphSearch --> HybridFusion
    
    HybridFusion --> CrossEncoder
    CrossEncoder --> ContextAssembly
    ContextAssembly --> LLMGeneration
    LLMGeneration --> Response
    
    LLMGeneration -.-> RAGASEval
    Response -.-> RAGASEval
```

### 4.3. Embedding Model Specification v2.0

#### 4.3.1. Selected Models

**Primary Model (UPGRADED):** Qwen/Qwen3-Embedding-4B ‚≠ê  
**Fallback Model:** Qwen/Qwen3-Embedding-0.6B (hi·ªán t·∫°i)  
**Future Addition (Phase 3):** vietnamese-document-embedding (PhoBERT-based)

| Thu·ªôc t√≠nh | v1.0 (0.6B) | v2.0 (4B) ‚≠ê | Delta |
|-----------|------------|------------|-------|
| **Parameters** | 0.6 t·ª∑ | 4 t·ª∑ | +566% |
| **Embedding Dimension** | 1024 | 1024 | Kh√¥ng ƒë·ªïi (t∆∞∆°ng th√≠ch ng∆∞·ª£c) |
| **Max Context Window** | 8,192 tokens | **32,768 tokens** | +4x |
| **Vietnamese Quality** | T·ªët | R·∫•t t·ªët | +15-25% nDCG ∆∞·ªõc t√≠nh |
| **GPU VRAM** | ~2.2GB | ~8GB | V·∫´n fit RTX 2080 Ti (11GB) |
| **Gi·∫•y ph√©p** | Apache 2.0 | Apache 2.0 | Kh√¥ng ƒë·ªïi |
| **Inference Speed** | ~0.1s/query | ~0.3s/query | Ch·∫•p nh·∫≠n ƒë∆∞·ª£c |
| **Batch Throughput** | ~100 emb/s | ~30 emb/s | C·∫ßn batch optimization |

**L√Ω do N√¢ng c·∫•p:**
- ‚úÖ Context window 32K tokens: x·ª≠ l√Ω to√†n b·ªô ƒêi·ªÅu/Kho·∫£n d√†i m√† kh√¥ng c·∫Øt c·ª•t
- ‚úÖ C√πng ki·∫øn tr√∫c Qwen3 ‚Üí migration d·ªÖ d√†ng, ChromaDB collection t∆∞∆°ng th√≠ch dimension
- ‚úÖ Ch·∫•t l∆∞·ª£ng embedding t·ªët h∆°n ƒë√°ng k·ªÉ cho t√†i li·ªáu ph√°p lu·∫≠t ph·ª©c t·∫°p
- ‚úÖ V·∫´n fit trong VRAM budget: 8GB model + 2GB reranker = 10GB < 11GB RTX 2080 Ti
- ‚úÖ Apache 2.0, self-hosted

**K·∫ø ho·∫°ch Migration:**
```
Phase 2 (Tu·∫ßn 3-6):
1. T·∫£i Qwen3-Embedding-4B v·ªÅ GPU server
2. Benchmark tr√™n 100 ground truth queries: compare nDCG@10 vs 0.6B
3. N·∫øu improvement ‚â• 10%: re-embed to√†n b·ªô 42 documents
4. T·∫°o ChromaDB collection m·ªõi: knowledge_base_v2 (gi·ªØ v1 l√†m rollback)
5. C·∫≠p nh·∫≠t pgvector table v·ªõi embeddings m·ªõi
6. Smoke test ‚Üí switch traffic ‚Üí monitor
```

#### 4.3.2. Embedding Generation Process v2.0

```python
# Pseudocode for embedding generation v2.0
from sentence_transformers import SentenceTransformer
import torch

class EmbeddingService:
    def __init__(self):
        self.model = SentenceTransformer(
            'Qwen/Qwen3-Embedding-4B',  # v2.0: upgraded from 0.6B
            device='cuda',
            trust_remote_code=True
        )
        self.dimension = 1024
        self.max_length = 32768  # v2.0: 4x increase from 8192
    
    def generate_embedding(self, text: str) -> list[float]:
        """
        Generate 1024-dimensional embedding for Vietnamese text.
        v2.0: Supports up to 32K tokens context.
        """
        # 1. Preprocess text
        text = unicode_normalize(text, form="NFC")
        text = remove_excessive_whitespace(text)
        
        # 2. Generate embedding with instruction prefix (Qwen3 feature)
        with torch.no_grad():
            embedding = self.model.encode(
                text,
                max_length=self.max_length,
                normalize_embeddings=True,  # L2 normalization for cosine
                show_progress_bar=False
            )
        
        return embedding.tolist()
    
    def generate_batch(self, texts: list[str], batch_size: int = 8) -> list[list[float]]:
        """
        Batch embedding generation.
        v2.0: batch_size=8 cho 4B model tr√™n RTX 2080 Ti (VRAM optimization).
        """
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,  # 8 cho 4B model (vs 16 cho 0.6B)
            max_length=self.max_length,
            normalize_embeddings=True,
            show_progress_bar=True
        )
        return embeddings.tolist()
```

**Performance Metrics (∆∞·ªõc t√≠nh cho Qwen3-4B tr√™n RTX 2080 Ti):**

| Metric | v1.0 (0.6B) | v2.0 (4B) | Ghi ch√∫ |
|--------|------------|-----------|---------|
| Single query latency | ~10ms | ~30ms | V·∫´n < 100ms SLA |
| Batch throughput | ~100 emb/s | ~30 emb/s | batch_size=8 |
| GPU VRAM utilized | ~2.2GB | ~8GB | Fit RTX 2080 Ti |
| Re-embedding 42 docs | ~5 ph√∫t | ~15 ph√∫t | One-time migration |

#### 4.3.3. Dual Embedding Strategy ‚Äî Phase 3

```mermaid
graph TD
    Q["Truy v·∫•n ng∆∞·ªùi d√πng"] --> Classify{"Ph√¢n lo·∫°i<br/>Ng√¥n ng·ªØ & Lo·∫°i"}
    
    Classify -->|"Ti·∫øng Vi·ªát ph√°p lu·∫≠t"| VN["vietnamese-document-embedding<br/>768-dim, PhoBERT-based<br/>8096 tokens, Matryoshka"]
    Classify -->|"ƒêa ng√¥n ng·ªØ / K·ªπ thu·∫≠t"| QW["Qwen3-Embedding-4B<br/>1024-dim, 32K context"]
    
    VN --> Norm["Normalize & Align<br/>Dimension Mapping"]
    QW --> Norm
    Norm --> Merge["Weighted Score Merge"]
    Merge --> Rerank["Cross-Encoder Reranking"]
```

**Ghi ch√∫:** Dual embedding s·∫Ω ƒë∆∞·ª£c tri·ªÉn khai ·ªü Phase 3 sau khi validate Qwen3-4B ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh. vietnamese-document-embedding s·ª≠ d·ª•ng c√πng `pyvi` tokenizer m√† ATTECH ƒë√£ t√≠ch h·ª£p.

### 4.4. Search Strategy v2.0

#### 4.4.1. Stage 1A: Vector Similarity Search (ChromaDB + pgvector)

**Thay ƒë·ªïi v2.0:** B·ªï sung pgvector trong PostgreSQL song song v·ªõi ChromaDB.

```python
# v2.0: Dual vector search ‚Äî ChromaDB + pgvector
async def vector_search_v2(
    query_embedding: list[float],
    user_permissions: dict,
    top_k: int = 50,  # v2.0: tƒÉng t·ª´ 20 l√™n 50 (reranker s·∫Ω l·ªçc)
    use_pgvector: bool = True  # v2.0: pgvector primary
) -> list[SearchResult]:
    
    results = []
    
    if use_pgvector:
        # pgvector: unified query v·ªõi permission filter trong c√πng SQL
        pg_results = await pgvector_search(
            query_embedding=query_embedding,
            access_levels=user_permissions["accessible_levels"],
            departments=user_permissions["departments"],
            top_k=top_k
        )
        results.extend(pg_results)
    else:
        # ChromaDB fallback
        chroma_results = chroma_collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where={
                "access_level": {"$in": user_permissions["accessible_levels"]},
            }
        )
        results.extend(chroma_results)
    
    return results
```

**pgvector Query (v2.0 NEW):**
```sql
-- Unified vector search + BM25 + RBAC trong c√πng 1 query
SELECT 
    c.chunk_id,
    c.document_id,
    c.content,
    c.hierarchy_path,
    c.article_number,
    e.embedding <=> query_embedding::vector AS vector_distance,
    1 - (e.embedding <=> query_embedding::vector) AS cosine_similarity
FROM document_chunks_enhanced c
JOIN document_embeddings_v2 e ON e.chunk_id = c.chunk_id
JOIN documents_metadata_v2 d ON d.document_id = c.document_id
WHERE 
    d.access_level = ANY($1)  -- Permission filter
    AND (d.department_owner = ANY($2) OR d.department_owner = 'all_departments')
ORDER BY e.embedding <=> query_embedding::vector ASC
LIMIT 50;
```

**Scoring:**
- **Metric:** Cosine similarity
- **Threshold:** > 0.3 (minimum relevance)
- **v2.0 Change:** Retrieve top-50 (thay v√¨ top-20) ƒë·ªÉ Cross-Encoder reranking c√≥ nhi·ªÅu ·ª©ng vi√™n h∆°n

#### 4.4.2. Stage 1B: BM25 Full-Text Search (PostgreSQL)

**Gi·ªØ nguy√™n ki·∫øn tr√∫c v1.0** v·ªõi c√°c c·∫£i ti·∫øn:

```sql
-- v2.0: BM25 search v·ªõi legal code preservation c·∫£i ti·∫øn
SELECT 
    chunk_id,
    document_id,
    content,
    metadata,
    hierarchy_path,
    ts_rank_cd(
        tsv_content,
        to_tsquery('vietnamese', $1),
        32  -- Cover density ranking
    ) AS bm25_score
FROM document_chunks_enhanced
WHERE 
    tsv_content @@ to_tsquery('vietnamese', $1)
    AND chunk_id IN (
        SELECT chunk_id FROM document_chunks_enhanced c
        JOIN documents_metadata_v2 d ON d.document_id = c.document_id
        WHERE d.access_level = ANY($2)
          AND (d.department_owner = ANY($3) OR d.department_owner = 'all_departments')
    )
ORDER BY bm25_score DESC
LIMIT 50;  -- v2.0: tƒÉng t·ª´ 20 l√™n 50
```

**BM25 Parameters (gi·ªØ nguy√™n v1.0):**
- k1 = 1.5 (term frequency saturation)
- b = 0.75 (length normalization)

#### 4.4.3. Stage 1C: Graph Traversal ‚≠ê OPERATIONAL (v2.0)

**Thay ƒë·ªïi t·ª´ v1.0:** T·ª´ "Phase 2 - Planned" ‚Üí "Operational" v·ªõi 42 documents, 507 edges.

**Graph Statistics (th·ª±c t·∫ø, 31/12/2025):**

| Metric | Gi√° tr·ªã |
|--------|---------|
| Total Documents | 42 |
| Total Edges | 507 |
| Average Connections per Document | 24.1 |
| Max Connections | 35 |
| Min Connections | 10 |
| Isolated Nodes | 0 (100% connected) |

**Edge Types:**

| Lo·∫°i | Subtype | S·ªë l∆∞·ª£ng | Confidence | M√¥ t·∫£ |
|------|---------|---------|-----------|-------|
| semantic_similarity | same_category | 226 | 0.7 | T√†i li·ªáu c√πng danh m·ª•c |
| semantic_similarity | shared_keywords | 137 | 0.85 | Chia s·∫ª ‚â•2 t·ª´ kh√≥a |
| hierarchical | same_level_peers | 144 | 0.6 | C√πng c·∫•p hierarchy |

**Graph Traversal Algorithm:**

```python
async def graph_search_v2(
    seed_document_ids: list[str],  # T·ª´ vector/BM25 results
    max_hops: int = 2,
    confidence_decay: float = 0.8,
    max_results: int = 20
) -> list[GraphResult]:
    """
    Multi-hop graph traversal t·ª´ seed documents.
    v2.0: Operational v·ªõi 507 edges.
    
    Strategy:
    1. B·∫Øt ƒë·∫ßu t·ª´ documents t√¨m ƒë∆∞·ª£c qua vector/BM25
    2. M·ªü r·ªông qua c√°c edge types:
       - same_category (0.7 confidence)
       - shared_keywords (0.85 confidence)  
       - same_level_peers (0.6 confidence)
    3. Confidence decay: 0.8^(hop_distance)
    4. Tr·∫£ v·ªÅ enriched context
    """
    
    query = """
    WITH RECURSIVE graph_traversal AS (
        -- Base: seed documents
        SELECT 
            gd.graph_doc_id,
            gd.source_document_id,
            gd.title,
            0 as hop_distance,
            1.0 as accumulated_confidence
        FROM graph_documents gd
        WHERE gd.source_document_id = ANY($1)
        
        UNION ALL
        
        -- Recursive: follow edges
        SELECT 
            gd2.graph_doc_id,
            gd2.source_document_id,
            gd2.title,
            gt.hop_distance + 1,
            gt.accumulated_confidence * ge.confidence * $2  -- decay
        FROM graph_traversal gt
        JOIN graph_edges ge ON ge.source_graph_doc_id = gt.graph_doc_id
        JOIN graph_documents gd2 ON gd2.graph_doc_id = ge.target_graph_doc_id
        WHERE 
            gt.hop_distance < $3  -- max_hops
            AND ge.is_active = true
            AND gt.accumulated_confidence * ge.confidence * $2 > 0.1  -- minimum threshold
    )
    SELECT DISTINCT ON (source_document_id)
        graph_doc_id,
        source_document_id,
        title,
        hop_distance,
        accumulated_confidence
    FROM graph_traversal
    WHERE source_document_id != ALL($1)  -- Exclude seed documents
    ORDER BY source_document_id, accumulated_confidence DESC
    LIMIT $4;
    """
    
    results = await db.fetch(query, seed_document_ids, confidence_decay, max_hops, max_results)
    return [GraphResult(**r) for r in results]
```

**‚ö†Ô∏è QUAN TR·ªåNG ‚Äî Graph Link Generation:**

Graph links KH√îNG t·ª± ƒë·ªông t·∫°o khi th√™m t√†i li·ªáu m·ªõi. Workflow b·∫Øt bu·ªôc:

```bash
# Sau khi import t√†i li·ªáu m·ªõi:
python IMport_new_exports.py          # Step 1: Import documents
python create_semantic_links.py        # Step 2: CRITICAL - Regenerate graph links
python validate_graph_links.py         # Step 3: Verify (optional)
```

#### 4.4.4. Hybrid Ranking & Fusion v2.0

**Thay ƒë·ªïi ch√≠nh:** C√¥ng th·ª©c 3 chi·ªÅu th√≠ch ·ª©ng (thay v√¨ 2 chi·ªÅu c·ªë ƒë·ªãnh).

```python
# v2.0: Adaptive 3-way hybrid scoring
class HybridScoringV2:
    """
    C√¥ng th·ª©c: final_score = Œ±√ósemantic + Œ≤√ókeyword + Œ≥√ógraph
    
    Tr·ªçng s·ªë th√≠ch ·ª©ng theo lo·∫°i truy v·∫•n (intent):
    - specific_document:  Œ±=0.3, Œ≤=0.6, Œ≥=0.1  (keyword ch·ªß ƒë·∫°o)
    - how_to_procedure:   Œ±=0.6, Œ≤=0.2, Œ≥=0.2  (semantic ch·ªß ƒë·∫°o)
    - comparison:         Œ±=0.4, Œ≤=0.2, Œ≥=0.4  (graph quan tr·ªçng)
    - general:            Œ±=0.5, Œ≤=0.3, Œ≥=0.2  (balanced)
    """
    
    INTENT_WEIGHTS = {
        "specific_document":  {"alpha": 0.3, "beta": 0.6, "gamma": 0.1},
        "how_to_procedure":   {"alpha": 0.6, "beta": 0.2, "gamma": 0.2},
        "what_is_information":{"alpha": 0.5, "beta": 0.3, "gamma": 0.2},
        "comparison":         {"alpha": 0.4, "beta": 0.2, "gamma": 0.4},
        "general":            {"alpha": 0.5, "beta": 0.3, "gamma": 0.2},
    }
    
    def compute_hybrid_score(
        self,
        query_intent: str,
        semantic_score: float,
        keyword_score: float,
        graph_score: float,
        document_id: str,
        seen_documents: set
    ) -> float:
        weights = self.INTENT_WEIGHTS.get(query_intent, self.INTENT_WEIGHTS["general"])
        
        # Weighted combination
        hybrid_score = (
            weights["alpha"] * semantic_score +
            weights["beta"] * keyword_score +
            weights["gamma"] * graph_score
        )
        
        # Diversity penalty: -20% cho duplicate documents
        if document_id in seen_documents:
            hybrid_score *= 0.8
        
        return hybrid_score
```

**So s√°nh v1.0 vs v2.0:**

| Kh√≠a c·∫°nh | v1.0 | v2.0 |
|-----------|------|------|
| C√¥ng th·ª©c | 0.7√ósemantic + 0.3√ókeyword | Œ±√ósemantic + Œ≤√ókeyword + Œ≥√ógraph |
| Tr·ªçng s·ªë | C·ªë ƒë·ªãnh | Th√≠ch ·ª©ng theo intent |
| Graph | Kh√¥ng c√≥ | ‚úÖ T√≠ch h·ª£p (507 edges) |
| Candidates | Top 20 | Top 100 (cho reranker) |
| Diversity | 0.8√ó penalty | 0.8√ó penalty (gi·ªØ nguy√™n) |

#### 4.4.5. Cross-Encoder Reranking ‚≠ê NEW

**ƒê√¢y l√† thay ƒë·ªïi quan tr·ªçng nh·∫•t trong v2.0.** Theo xu h∆∞·ªõng 2026, Cross-Encoder Reranking l√† ki·∫øn tr√∫c m·∫∑c ƒë·ªãnh cho production RAG systems, c·∫£i thi·ªán 33-47% ƒë·ªô ch√≠nh x√°c.

```mermaid
graph LR
    subgraph "BEFORE v1.0"
        Q1["Query"] --> H1["Hybrid Ranking<br/>Top 20"]
        H1 --> L1["LLM<br/>(c√≥ th·ªÉ ch·ª©a noise)"]
    end
    
    subgraph "AFTER v2.0 ‚≠ê"
        Q2["Query"] --> H2["Hybrid Fusion<br/>Top 100 candidates<br/>~50ms"]
        H2 --> RE["Cross-Encoder ‚≠ê<br/>Rerank Top 100 ‚Üí Top 10<br/>~200-400ms"]
        RE --> L2["LLM<br/>(context ch√≠nh x√°c h∆°n)"]
    end
```

**Model Selection:**

| Model | ∆Øu ƒëi·ªÉm | Nh∆∞·ª£c ƒëi·ªÉm | Ph√π h·ª£p |
|-------|---------|-----------|---------|
| **bge-reranker-v2-m3** | Nh·ªè g·ªçn, multilingual, benchmark t·ªët | Generic, ch∆∞a t·ªëi ∆∞u ph√°p lu·∫≠t VN | ‚≠ê **Khuy·∫øn ngh·ªã ch√≠nh** |
| **Qwen3-Reranker** | C√πng h·ªç Qwen, instruction-aware | M·ªõi, √≠t benchmark | ‚≠ê **Thay th·∫ø t·ªët** |
| **Cohere Rerank 3** | Nhanh, API d·ªÖ d√πng | API-only, c·∫ßn internet | üü° Fallback |

**Implementation:**

```python
from sentence_transformers import CrossEncoder

class RerankerService:
    def __init__(self, model_name: str = "BAAI/bge-reranker-v2-m3"):
        self.model = CrossEncoder(
            model_name,
            device='cuda',
            max_length=512  # ƒê·ªß cho query + chunk pair
        )
        self.timeout_seconds = 2.0  # Fallback n·∫øu timeout
    
    async def rerank(
        self,
        query: str,
        candidates: list[SearchResult],
        top_k: int = 10
    ) -> list[SearchResult]:
        """
        Cross-Encoder reranking: ch·∫•m ƒëi·ªÉm (query, document) pairs.
        
        Kh√°c bi·ªát vs Bi-Encoder:
        - Bi-Encoder: encode query v√† document RI√äNG ‚Üí cosine similarity
        - Cross-Encoder: encode (query, document) C√ôNG L√öC ‚Üí relevance score tr·ª±c ti·∫øp
        ‚Üí Ch√≠nh x√°c h∆°n nh∆∞ng ch·∫≠m h∆°n (O(n) thay v√¨ O(1) retrieval)
        
        Args:
            query: User query text
            candidates: Top-100 results t·ª´ hybrid fusion
            top_k: S·ªë k·∫øt qu·∫£ cu·ªëi c√πng (default 10)
        
        Returns:
            Top-K reranked results
        """
        try:
            # T·∫°o (query, document) pairs
            pairs = [(query, candidate.content) for candidate in candidates]
            
            # Cross-Encoder scoring
            scores = self.model.predict(
                pairs,
                batch_size=16,  # Fit in VRAM alongside embedding model
                show_progress_bar=False
            )
            
            # Combine reranker score v·ªõi original hybrid score
            for candidate, reranker_score in zip(candidates, scores):
                candidate.reranker_score = float(reranker_score)
                candidate.final_score = (
                    0.7 * candidate.reranker_score +  # Cross-encoder dominates
                    0.3 * candidate.hybrid_score       # Original score as tiebreaker
                )
            
            # Sort by final_score descending
            candidates.sort(key=lambda x: x.final_score, reverse=True)
            
            return candidates[:top_k]
        
        except TimeoutError:
            # Fallback: tr·∫£ v·ªÅ hybrid ranking results
            logger.warning("Reranker timeout ‚Äî falling back to hybrid ranking")
            candidates.sort(key=lambda x: x.hybrid_score, reverse=True)
            return candidates[:top_k]
```

**Expected Impact:**

| Metric | v1.0 (no reranker) | v2.0 (with reranker) | Improvement |
|--------|-------------------|---------------------|------------|
| nDCG@10 | ~0.70 (baseline) | ~0.90 (target) | **+28-30%** |
| MRR | ~0.65 | ~0.85 | **+30%** |
| Recall@10 | 92% | 92% | Kh√¥ng ƒë·ªïi (retrieval stage) |
| Latency | ~50ms retrieval | +200-400ms reranking | Ch·∫•p nh·∫≠n |

#### 4.4.6. Query Understanding v√† Expansion (C·∫≠p nh·∫≠t)

**Intent Classification (c·∫≠p nh·∫≠t ƒë·ªÉ ph√¢n ph·ªëi tr·ªçng s·ªë hybrid):**

```python
def classify_query_intent(query: str) -> str:
    """
    Classify user query intent.
    v2.0: K·∫øt qu·∫£ ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë hybrid scoring.
    """
    # Legal code pattern detection ‚Äî HIGHEST priority
    if re.search(r'\d+/\d+/(Nƒê-CP|Qƒê-TTg|TT-[A-Z]+)', query):
        return "specific_document"  # Œ±=0.3, Œ≤=0.6, Œ≥=0.1
    
    # Comparison/relationship questions ‚Üí graph-heavy
    if any(kw in query.lower() for kw in ['so s√°nh', 'kh√°c nhau', 'li√™n quan', 'cƒÉn c·ª©', 'thay th·∫ø']):
        return "comparison"  # Œ±=0.4, Œ≤=0.2, Œ≥=0.4
    
    # How-to questions ‚Üí semantic-heavy
    if any(kw in query.lower() for kw in ['l√†m th·∫ø n√†o', 'c√°ch', 'quy tr√¨nh', 'h∆∞·ªõng d·∫´n']):
        return "how_to_procedure"  # Œ±=0.6, Œ≤=0.2, Œ≥=0.2
    
    # What-is questions
    if any(kw in query.lower() for kw in ['l√† g√¨', 'c√≥ nghƒ©a', 'ƒë·ªãnh nghƒ©a']):
        return "what_is_information"  # Œ±=0.5, Œ≤=0.3, Œ≥=0.2
    
    return "general"  # Œ±=0.5, Œ≤=0.3, Œ≥=0.2
```

### 4.5. Large Language Model Generation Configuration v2.0

#### 4.5.1. LiteLLM Gateway ‚≠ê NEW

**Thay ƒë·ªïi t·ª´ v1.0:** Thay th·∫ø custom multi-provider logic b·∫±ng LiteLLM Gateway chu·∫©n h√≥a.

```mermaid
graph LR
    subgraph "v1.0 ‚Äî Custom Router"
        App1["FastAPI"] --> R1["Custom Logic<br/>if/else providers"]
        R1 --> OAI1["OpenAI"]
        R1 --> ANT1["Anthropic"]
        R1 --> LOC1["Local"]
    end
    
    subgraph "v2.0 ‚Äî LiteLLM Gateway ‚≠ê"
        App2["FastAPI"] --> LIT["LiteLLM Proxy<br/>OpenAI-compatible API<br/>+ Semantic Cache<br/>+ Cost Tracking<br/>+ Auto-Failover"]
        LIT --> OAI2["OpenAI GPT-4o"]
        LIT --> ANT2["Claude 3.5 Sonnet"]
        LIT --> LOC2["Local Qwen"]
    end
```

**LiteLLM Configuration:**

```yaml
# litellm_config.yaml
model_list:
  - model_name: "gpt-4o"
    litellm_params:
      model: "openai/gpt-4o"
      api_key: "${OPENAI_API_KEY}"
      timeout: 30
      max_tokens: 2048
      
  - model_name: "claude-sonnet"
    litellm_params:
      model: "anthropic/claude-3-5-sonnet-20241022"
      api_key: "${ANTHROPIC_API_KEY}"
      timeout: 30
      max_tokens: 2048

  - model_name: "qwen-local"
    litellm_params:
      model: "openai/qwen2.5"
      api_base: "http://localhost:11434/v1"
      timeout: 60
      max_tokens: 2048

litellm_settings:
  # Semantic Caching
  cache: true
  cache_params:
    type: "redis"
    host: "192.168.1.70"
    port: 6379
    ttl: 3600  # 1 hour cache
    similarity_threshold: 0.95  # Semantic similarity for cache hit
  
  # Routing Strategy
  router_settings:
    routing_strategy: "latency-based-routing"
    allowed_fails: 2
    cooldown_time: 60
    
  # Fallback Chain
  fallback_models:
    gpt-4o: ["claude-sonnet", "qwen-local"]
    claude-sonnet: ["gpt-4o", "qwen-local"]
    qwen-local: ["gpt-4o"]

  # Cost Tracking
  success_callback: ["prometheus"]
  failure_callback: ["prometheus"]
```

**L·ª£i √≠ch LiteLLM so v·ªõi custom router:**

| Feature | v1.0 Custom | v2.0 LiteLLM |
|---------|------------|--------------|
| Provider support | 3 (manual code) | 100+ (built-in) |
| Failover | Manual if/else | Automatic v·ªõi cooldown |
| Semantic caching | ‚ùå | ‚úÖ Redis-based, similarity 0.95 |
| Cost tracking | ‚ùå | ‚úÖ Per-request, per-provider |
| Rate limiting | Manual | Built-in per-model |
| API compatibility | Custom endpoint | OpenAI-compatible (drop-in) |
| Latency routing | ‚ùå | ‚úÖ Automatic lowest-latency |

#### 4.5.2. Prompt Engineering (Gi·ªØ nguy√™n v1.0)

**System Prompt Template:**
```
B·∫°n l√† tr·ª£ l√Ω AI chuy√™n v·ªÅ t√†i li·ªáu ph√°p lu·∫≠t v√† ch√≠nh s√°ch n·ªôi b·ªô c·ªßa ATTECH.

**Nhi·ªám v·ª•:**
- Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a CH√çNH X√ÅC tr√™n context ƒë∆∞·ª£c cung c·∫•p
- Tr√≠ch d·∫´n ngu·ªìn t√†i li·ªáu (t√™n vƒÉn b·∫£n, ƒëi·ªÅu, kho·∫£n, trang)
- N·∫øu kh√¥ng c√≥ th√¥ng tin trong context, h√£y n√≥i r√µ "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ..."
- KH√îNG t·ª± b·ªãa ƒë·∫∑t ho·∫∑c ƒëo√°n m√≤ th√¥ng tin

**ƒê·ªãnh d·∫°ng Tr√≠ch d·∫´n:**
- VƒÉn b·∫£n ph√°p lu·∫≠t: "Theo Ngh·ªã ƒë·ªãnh s·ªë XX/YYYY/Nƒê-CP ng√†y DD/MM/YYYY, ƒêi·ªÅu X, Kho·∫£n Y..."
- Ch√≠nh s√°ch n·ªôi b·ªô: "Theo [T√™n t√†i li·ªáu], M·ª•c [X], Trang [Y]..."
- T√†i li·ªáu k·ªπ thu·∫≠t: "[T√™n s·∫£n ph·∫©m] Datasheet, Section [X], Page [Y]"

**Ng√¥n ng·ªØ:**
- S·ª≠ d·ª•ng ti·∫øng Vi·ªát chuy√™n nghi·ªáp
- Gi·ªØ nguy√™n thu·∫≠t ng·ªØ ti·∫øng Anh (kh√¥ng d·ªãch) n·∫øu l√† thu·∫≠t ng·ªØ k·ªπ thu·∫≠t

**ƒê·ªô d√†i:**
- C√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn (2-3 ƒëo·∫°n vƒÉn)
- N·∫øu c·∫ßn chi ti·∫øt, chia th√†nh c√°c ƒëi·ªÉm r√µ r√†ng
```

#### 4.5.3. Context Window Management (C·∫≠p nh·∫≠t)

**v2.0 Change:** TƒÉng context budget nh·ªù LLM models m·ªõi h·ªó tr·ª£ context window l·ªõn h∆°n.

**Token Budget Allocation (GPT-4o / Claude 3.5 Sonnet):**
```
System Prompt:      ~500 tokens
User Query:         ~200 tokens (average, including expanded)
Context Chunks:     ~12,000 tokens (v2.0: tƒÉng t·ª´ 6,500)
Graph Context:      ~1,000 tokens (v2.0: related documents info)
Response Budget:    ~2,000 tokens (reserve)
-----------------------------------
Total:              ~15,700 tokens (within 128K context)
```

#### 4.5.4. Citation Extraction v√† Grounding (Gi·ªØ nguy√™n v1.0)

Xem chi ti·∫øt trong v1.0 ¬ß4.5.4. Kh√¥ng c√≥ thay ƒë·ªïi v·ªÅ logic citation/grounding.

### 4.6. Evaluation Framework v2.0 ‚≠ê MAJOR UPGRADE

#### 4.6.1. RAGAS Automated Evaluation Pipeline ‚≠ê NEW

**Thay ƒë·ªïi t·ª´ v1.0:** T·ª´ 100 c·∫∑p ƒë√°nh gi√° th·ªß c√¥ng ‚Üí Pipeline t·ª± ƒë·ªông h√≥a li√™n t·ª•c.

```mermaid
graph TD
    subgraph "DATA LAYER"
        GT["Ground Truth Dataset<br/>100+ query-document pairs<br/>+ expected answers"]
        Prod["Production Queries<br/>(sampled daily)"]
    end
    
    subgraph "RAGAS EVALUATION PIPELINE ‚≠êNEW"
        Collect["Collect Samples<br/>Random 50 queries/week"]
        Run["Run RAG Pipeline<br/>query ‚Üí retrieval ‚Üí generation"]
        
        subgraph "RAGAS Metrics"
            Faith["Faithfulness<br/>Claims in answer vs source"]
            Relevance["Answer Relevance<br/>Query-answer semantic sim"]
            CtxPrec["Context Precision<br/>Relevant chunks in top-K"]
            CtxRecall["Context Recall<br/>Ground truth covered"]
        end
        
        Score["Aggregate Scores<br/>Weekly report"]
        Alert["Alert System<br/>If metric drops > 5%"]
    end
    
    subgraph "REPORTING"
        Grafana["Grafana Dashboard<br/>Time-series trends"]
        Report["Weekly Quality Report<br/>Auto-generated"]
    end
    
    GT --> Collect
    Prod --> Collect
    Collect --> Run
    Run --> Faith
    Run --> Relevance
    Run --> CtxPrec
    Run --> CtxRecall
    Faith --> Score
    Relevance --> Score
    CtxPrec --> Score
    CtxRecall --> Score
    Score --> Grafana
    Score --> Alert
    Score --> Report
```

**RAGAS Metrics Definition:**

| Metric | C√¥ng th·ª©c | M·ª•c ti√™u v2.0 | ƒêo l∆∞·ªùng |
|--------|-----------|---------------|---------|
| **Faithfulness** | % claims in answer verifiable trong source docs | > 0.90 | RAGAS faithfulness scorer |
| **Answer Relevance** | Cosine sim (query embedding, answer embedding) | > 0.85 | RAGAS answer_relevancy |
| **Context Precision** | % retrieved chunks actually relevant | > 0.85 | RAGAS context_precision |
| **Context Recall** | % ground truth info covered by retrieved chunks | > 0.90 | RAGAS context_recall |
| **nDCG@10** | Normalized Discounted Cumulative Gain | > 0.90 | Custom evaluation script |
| **MRR** | Mean Reciprocal Rank | > 0.80 | Custom evaluation script |

**Implementation:**

```python
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)

class RAGASEvaluationPipeline:
    def __init__(self):
        self.metrics = [
            faithfulness,
            answer_relevancy,
            context_precision,
            context_recall
        ]
    
    async def run_weekly_evaluation(self, sample_size: int = 50):
        """
        Run RAGAS evaluation on sampled queries.
        Scheduled: Every Sunday 2:00 AM
        """
        # 1. Sample queries (mix of ground truth + production)
        ground_truth_queries = await self.get_ground_truth_sample(sample_size // 2)
        production_queries = await self.get_production_sample(sample_size // 2)
        
        all_queries = ground_truth_queries + production_queries
        
        # 2. Run RAG pipeline on each query
        results = []
        for query_data in all_queries:
            rag_result = await rag_pipeline.process(query_data["query"])
            results.append({
                "question": query_data["query"],
                "answer": rag_result.answer,
                "contexts": [c.content for c in rag_result.retrieved_chunks],
                "ground_truth": query_data.get("expected_answer", ""),
            })
        
        # 3. Evaluate with RAGAS
        dataset = Dataset.from_list(results)
        scores = evaluate(dataset, metrics=self.metrics)
        
        # 4. Store results
        await self.store_evaluation_results(scores)
        
        # 5. Check alerts
        await self.check_quality_alerts(scores)
        
        return scores
    
    async def check_quality_alerts(self, scores):
        """Alert n·∫øu metric gi·∫£m > 5% so v·ªõi baseline."""
        baseline = await self.get_baseline_scores()
        for metric_name, score in scores.items():
            if baseline.get(metric_name):
                drop = baseline[metric_name] - score
                if drop > 0.05:  # 5% threshold
                    await alert_system.send(
                        severity="WARNING",
                        message=f"RAGAS {metric_name} dropped {drop:.2%}: "
                                f"{baseline[metric_name]:.2f} ‚Üí {score:.2f}"
                    )
```

#### 4.6.2. VN-MTEB Benchmark (v2.0 NEW)

**Vietnamese Massive Text Embedding Benchmark** (41 datasets, 6 tasks) ‚Äî baseline cho embedding quality.

```python
# Run VN-MTEB benchmark on current and new embedding model
from mteb import MTEB

def benchmark_embedding_model(model_name: str):
    """
    Benchmark embedding model tr√™n VN-MTEB.
    So s√°nh Qwen3-0.6B vs Qwen3-4B.
    """
    model = SentenceTransformer(model_name, device='cuda')
    
    # Relevant tasks cho ATTECH
    tasks = [
        "ViRetrieval",        # Document retrieval
        "ViSTS",              # Semantic textual similarity
        "ViClassification",   # Text classification
    ]
    
    evaluation = MTEB(tasks=tasks)
    results = evaluation.run(model, output_folder=f"results/{model_name}")
    
    return results
```

#### 4.6.3. Ground Truth Dataset (C·∫≠p nh·∫≠t)

**Ground Truth Dataset v2.0:**
- **Size:** 100 query-document pairs (maintained from v1.0) + expanding to 200
- **Coverage:**
  - Normal cases: 50% (typical queries)
  - Edge cases: 25% (unusual phrasing, multi-intent, ambiguous)
  - Graph-specific: 15% (multi-hop, relationship queries) ‚≠ê NEW
  - Adversarial: 10% (prompt injection attempts, nonsensical)

---

## 5. KI·∫æN TR√öC K·ª∏ THU·∫¨T

### 5.1. T·ªïng quan Ki·∫øn tr√∫c H·ªá th·ªëng v2.0

ATTECH RAG System v2.0 s·ª≠ d·ª•ng **microservices architecture** v·ªõi c√°c components ƒë∆∞·ª£c containerized b·∫±ng Docker v√† orchestrated b·ªüi Docker Compose tr√™n h·∫° t·∫ßng ph√¢n t√°n 2 server.

```mermaid
graph TB
    subgraph "CLIENT TIER"
        Browser["üåê Web Browser<br/>Chrome, Firefox, Edge"]
        Mobile["üì± Mobile Browser<br/>Responsive Design"]
    end
    
    subgraph "PRESENTATION TIER"
        Streamlit["üñ•Ô∏è Streamlit UI<br/>Port 8501<br/>- Chat interface<br/>- Admin dashboard<br/>- Analytics views<br/>- Graph explorer ‚≠êNEW"]
    end
    
    subgraph "APPLICATION TIER ‚Äî API Gateway"
        FastAPI["üîå FastAPI Server<br/>Port 8000<br/>- Request routing<br/>- JWT validation<br/>- Rate limiting<br/>- CORS handling"]
    end
    
    subgraph "APPLICATION TIER ‚Äî Core Services"
        subgraph "FR-04 RAG Engine v2.0"
            QueryProc2["üîé Query Processing<br/>- Intent classification<br/>- Query expansion<br/>- Legal code detection"]
            Retrieval2["üîç Retrieval Service<br/>- 3-way hybrid search ‚≠ê<br/>- Permission filtering<br/>- Graph traversal ‚≠ê"]
            RerankerSvc["üéØ Reranker Service ‚≠êNEW<br/>- Cross-Encoder scoring<br/>- Top-100 ‚Üí Top-10<br/>- 2s timeout + fallback"]
            Synthesis2["üìã Synthesis Service<br/>- Context assembly<br/>- Graph context injection ‚≠ê<br/>- Token management"]
            Generation2["‚ú® Generation Service<br/>- LiteLLM Gateway ‚≠ê<br/>- Citation extraction<br/>- Grounding check"]
        end
        
        AuthService["üõ°Ô∏è FR-06 Auth Service<br/>- JWT tokens<br/>- Session management<br/>- RBAC enforcement"]
        
        Analytics2["üìä FR-07 Analytics<br/>- Usage tracking<br/>- RAGAS metrics ‚≠ê<br/>- Quality dashboards"]
        
        AdminService["‚öôÔ∏è FR-08 Admin<br/>- User management<br/>- Document management<br/>- Graph management ‚≠ê<br/>- System config"]
        
        IngestionPipeline["üì• FR-03 Data Ingestion<br/>- Vietnamese NLP 3-tier ‚≠ê<br/>- Hierarchical chunking<br/>- Embedding generation<br/>- Graph sync ‚≠ê"]
        
        EvalService["üìä Evaluation Service ‚≠êNEW<br/>- RAGAS pipeline<br/>- VN-MTEB benchmark<br/>- Weekly auto-evaluation"]
    end
    
    subgraph "DATA TIER ‚Äî Server .70 (Debian)"
        PostgreSQL2[("üêò PostgreSQL 15<br/>192.168.1.70:15432<br/>+ pgvector extension ‚≠ê<br/>- Metadata + BM25 + Vector<br/>- Graph tables (6) ‚≠ê<br/>- Users + Audit logs")]
        
        ChromaDB2[("üî¢ ChromaDB 1.0.0<br/>192.168.1.70:8000<br/>- 1024-dim embeddings<br/>- Semantic search<br/>- HNSW index")]
        
        Redis2[("‚ö° Redis 7<br/>192.168.1.70:6379<br/>- Query cache<br/>- Semantic cache ‚≠ê<br/>- Session store<br/>- Rate limiting")]
    end
    
    subgraph "AI/ML TIER ‚Äî Server .88 (DietPi / GPU)"
        EmbeddingService2["üß† Qwen3-Embedding-4B ‚≠ê<br/>GPU-accelerated<br/>- 1024-dim vectors<br/>- 32K context ‚≠ê<br/>- Batch processing"]
        
        RerankerModel2["üéØ Cross-Encoder ‚≠êNEW<br/>bge-reranker-v2-m3<br/>- GPU-accelerated<br/>- ~2GB VRAM"]
        
        LiteLLMProxy["ü§ñ LiteLLM Proxy ‚≠êNEW<br/>Port 4000<br/>- OpenAI/Anthropic/Local<br/>- Semantic caching<br/>- Auto-failover<br/>- Cost tracking"]
    end
    
    subgraph "MONITORING TIER"
        Prometheus2["üìà Prometheus<br/>Port 9090<br/>Metrics collection"]
        Grafana2["üìä Grafana<br/>Port 3000<br/>Dashboards"]
        Loki2["üìú Loki<br/>Port 3100<br/>Log aggregation"]
    end
    
    Browser --> Streamlit
    Mobile --> Streamlit
    Streamlit --> FastAPI
    
    FastAPI --> QueryProc2
    QueryProc2 --> Retrieval2
    FastAPI --> AuthService
    FastAPI --> Analytics2
    FastAPI --> AdminService
    
    Retrieval2 --> RerankerSvc
    RerankerSvc --> Synthesis2
    Synthesis2 --> Generation2
    
    Retrieval2 --> PostgreSQL2
    Retrieval2 --> ChromaDB2
    Retrieval2 --> Redis2
    
    AuthService --> PostgreSQL2
    AuthService --> Redis2
    
    Generation2 --> LiteLLMProxy
    
    IngestionPipeline --> EmbeddingService2
    IngestionPipeline --> PostgreSQL2
    IngestionPipeline --> ChromaDB2
    
    RerankerSvc --> RerankerModel2
    EvalService --> Analytics2
    
    FastAPI -.-> Prometheus2
    Prometheus2 --> Grafana2
    FastAPI -.-> Loki2
    
    classDef client fill:#e1f5ff,stroke:#01579b
    classDef presentation fill:#f3e5f5,stroke:#4a148c
    classDef application fill:#e8f5e9,stroke:#1b5e20
    classDef data fill:#fff3e0,stroke:#e65100
    classDef aiml fill:#fce4ec,stroke:#880e4f
    classDef monitoring fill:#f1f8e9,stroke:#33691e
```

### 5.2. Database Architecture v2.0

#### 5.2.1. PostgreSQL Schema (v2.0 Enhanced + pgvector + Graph)

**Connection Parameters:**
```yaml
Host: 192.168.1.70
Port: 15432
Database: chatbotR4
Username: kb_admin
Password: [REDACTED - see key.md]
Connection String: postgresql://kb_admin:********@192.168.1.70:15432/chatbotR4
```

**Extensions Required (v2.0):**
```sql
-- Existing
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- v2.0 NEW: Vector search trong PostgreSQL
CREATE EXTENSION IF NOT EXISTS vector;
```

**T·ªïng quan Tables v2.0:**

| Nh√≥m | Table | M√¥ t·∫£ | v2.0 Status |
|------|-------|-------|-------------|
| **Core** | `users` | Qu·∫£n l√Ω ng∆∞·ªùi d√πng, 5-tier RBAC | Gi·ªØ nguy√™n |
| **Core** | `documents_metadata_v2` | Metadata t√†i li·ªáu, JSONB | Gi·ªØ nguy√™n |
| **Core** | `document_chunks_enhanced` | Chunks + BM25 + hierarchy | Gi·ªØ nguy√™n |
| **Core** | `audit_logs` | Audit trail | Gi·ªØ nguy√™n |
| **Core** | `search_analytics` | Search tracking | Gi·ªØ nguy√™n |
| **Vector** | `document_embeddings_v2` ‚≠ê | pgvector embeddings | **NEW** |
| **Graph** | `graph_documents` ‚≠ê | Graph nodes (42 docs) | **NEW (deployed)** |
| **Graph** | `graph_edges` ‚≠ê | Graph edges (507) | **NEW (deployed)** |
| **Graph** | `graph_validation_rules` ‚≠ê | Validation constraints | **NEW (deployed)** |
| **Graph** | `graph_validation_log` ‚≠ê | Violation tracking | **NEW (deployed)** |
| **Graph** | `graph_changelog` ‚≠ê | Graph audit trail | **NEW (deployed)** |
| **Graph** | `graph_templates` ‚≠ê | Structure templates | **NEW (deployed)** |
| **Eval** | `evaluation_results` ‚≠ê | RAGAS scores | **NEW** |

> **Ghi ch√∫:** Core tables (users, documents_metadata_v2, document_chunks_enhanced, audit_logs, search_analytics) gi·ªØ nguy√™n schema v1.0. Xem chi ti·∫øt trong v1.0 ¬ß5.2.1. D∆∞·ªõi ƒë√¢y ch·ªâ tr√¨nh b√†y tables M·ªöI.

**NEW ‚Äî document_embeddings_v2 (pgvector):**
```sql
-- v2.0: pgvector table cho unified vector + metadata search
CREATE TABLE document_embeddings_v2 (
    id SERIAL PRIMARY KEY,
    chunk_id UUID NOT NULL REFERENCES document_chunks_enhanced(chunk_id) ON DELETE CASCADE,
    document_id UUID NOT NULL REFERENCES documents_metadata_v2(document_id) ON DELETE CASCADE,
    
    -- Vector data
    embedding vector(1024),  -- pgvector type, 1024 dimensions (Qwen3)
    embedding_model VARCHAR(100) DEFAULT 'Qwen/Qwen3-Embedding-4B',
    
    -- Metadata for filtering
    access_level VARCHAR(50),
    department_owner VARCHAR(100),
    document_type VARCHAR(50),
    
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Constraints
    CONSTRAINT unique_chunk_embedding UNIQUE(chunk_id)
);

-- HNSW index cho cosine similarity search
CREATE INDEX idx_embeddings_hnsw ON document_embeddings_v2 
    USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 200);

-- Composite indexes cho filtered search
CREATE INDEX idx_embeddings_access ON document_embeddings_v2(access_level);
CREATE INDEX idx_embeddings_department ON document_embeddings_v2(department_owner);
CREATE INDEX idx_embeddings_document ON document_embeddings_v2(document_id);
```

**NEW ‚Äî Graph Tables (6 tables, deployed 29/12/2025):**

```sql
-- graph_documents: Document nodes
CREATE TABLE graph_documents (
    graph_doc_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    source_document_id UUID REFERENCES documents_metadata_v2(document_id),
    
    -- Document info (mirrored)
    law_id VARCHAR(100),
    task_code VARCHAR(100),
    document_number VARCHAR(200),
    title TEXT,
    doc_type VARCHAR(50),
    department VARCHAR(100),
    
    -- Graph properties
    hierarchy_level INTEGER,  -- 1-6 (L0-L5)
    parent_count INTEGER DEFAULT 0,
    child_count INTEGER DEFAULT 0,
    is_root_node BOOLEAN DEFAULT false,
    is_leaf_node BOOLEAN DEFAULT true,
    
    -- Metadata
    tags TEXT[],
    keywords TEXT[],
    category VARCHAR(100),
    has_validation_errors BOOLEAN DEFAULT false,
    
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_graph_docs_source ON graph_documents(source_document_id);
CREATE INDEX idx_graph_docs_hierarchy ON graph_documents(hierarchy_level);
CREATE INDEX idx_graph_docs_category ON graph_documents(category);
CREATE INDEX idx_graph_docs_tags ON graph_documents USING gin(tags);

-- graph_edges: Document relationships
CREATE TABLE graph_edges (
    edge_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    source_graph_doc_id UUID NOT NULL REFERENCES graph_documents(graph_doc_id),
    target_graph_doc_id UUID NOT NULL REFERENCES graph_documents(graph_doc_id),
    
    -- Relationship
    relation_type VARCHAR(50) NOT NULL,    -- semantic_similarity, hierarchical
    relation_subtype VARCHAR(50),          -- same_category, shared_keywords, same_level_peers
    confidence FLOAT NOT NULL DEFAULT 0.5, -- 0.0 to 1.0
    edge_weight FLOAT DEFAULT 1.0,
    
    -- Context
    source_task_code VARCHAR(100),
    target_task_code VARCHAR(100),
    level_diff INTEGER DEFAULT 0,
    
    -- Status
    is_active BOOLEAN DEFAULT true,
    is_suggested BOOLEAN DEFAULT false,
    verified BOOLEAN DEFAULT false,
    
    -- Metadata
    metadata JSONB DEFAULT '{}',
    
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Constraints
    CONSTRAINT unique_edge UNIQUE(source_graph_doc_id, target_graph_doc_id, relation_type)
);

CREATE INDEX idx_graph_edges_source ON graph_edges(source_graph_doc_id);
CREATE INDEX idx_graph_edges_target ON graph_edges(target_graph_doc_id);
CREATE INDEX idx_graph_edges_relation_type ON graph_edges(relation_type);
CREATE INDEX idx_graph_edges_active ON graph_edges(is_active) WHERE is_active = true;
CREATE INDEX idx_graph_edges_recursive_lookup ON graph_edges(source_graph_doc_id, target_graph_doc_id, relation_type) 
    WHERE is_active = true;
```

**NEW ‚Äî evaluation_results (RAGAS):**
```sql
-- v2.0: Store RAGAS evaluation results
CREATE TABLE evaluation_results (
    eval_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    -- Evaluation info
    eval_type VARCHAR(50) NOT NULL,   -- 'weekly_ragas', 'benchmark', 'manual'
    eval_date DATE NOT NULL,
    sample_size INTEGER,
    
    -- RAGAS Metrics
    faithfulness FLOAT,
    answer_relevancy FLOAT,
    context_precision FLOAT,
    context_recall FLOAT,
    
    -- Retrieval Metrics
    ndcg_at_10 FLOAT,
    mrr FLOAT,
    recall_at_10 FLOAT,
    
    -- Metadata
    model_config JSONB,    -- embedding model, reranker, LLM used
    notes TEXT,
    
    -- Timestamps
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_eval_date ON evaluation_results(eval_date DESC);
CREATE INDEX idx_eval_type ON evaluation_results(eval_type);
```

#### 5.2.2. ChromaDB Configuration (Gi·ªØ nguy√™n v1.0 + migration path)

**Connection Parameters:**
```yaml
Host: 192.168.1.70
Port: 8000
API Version: v2
```

**Collection Strategy v2.0:**
```python
# v1.0: Gi·ªØ nguy√™n cho backward compatibility
collection_v1 = {
    "name": "knowledge_base_v1",
    "embedding_model": "Qwen/Qwen3-Embedding-0.6B",
    "embedding_dimension": 1024,
}

# v2.0: Collection m·ªõi v·ªõi Qwen3-4B embeddings
collection_v2 = {
    "name": "knowledge_base_v2",
    "embedding_model": "Qwen/Qwen3-Embedding-4B",
    "embedding_dimension": 1024,  # Same dimension ‚Üí t∆∞∆°ng th√≠ch
}

# Migration: ch·∫°y song song v1 v√† v2, switch traffic khi verified
```

#### 5.2.3. Redis Configuration (C·∫≠p nh·∫≠t Semantic Cache)

**Data Structures v2.0:**

| Key Pattern | M√¥ t·∫£ | TTL | v2.0 Change |
|-------------|-------|-----|-------------|
| `cache:query:{hash}` | Query result cache | 3600s | Gi·ªØ nguy√™n |
| `cache:semantic:{hash}` ‚≠ê | LiteLLM semantic cache | 3600s | **NEW** |
| `session:{id}` | Session store | 1800s | Gi·ªØ nguy√™n |
| `ratelimit:{user}:{endpoint}` | Rate limiting | 60s | Gi·ªØ nguy√™n |
| `embedding:{text_hash}` | Embedding cache | 86400s | Gi·ªØ nguy√™n |
| `eval:baseline:{metric}` ‚≠ê | RAGAS baseline scores | ‚àû | **NEW** |

---

## 6. ƒê·∫∂C ƒêI·ªÇM X·ª¨ L√ù TI·∫æNG VI·ªÜT v2.0

### 6.1. T·ªïng quan

> **Ghi ch√∫ v2.0:** Ph·∫ßn n√†y gi·ªØ nguy√™n n·ªôi dung c·ªët l√µi v1.0 (Unicode Normalization, Legal Code Patterns, Hierarchical Structure, Synonym Expansion, Tone Mark Handling). D∆∞·ªõi ƒë√¢y ch·ªâ tr√¨nh b√†y c√°c **c·∫£i ti·∫øn m·ªõi**.

**C·∫£i ti·∫øn ch√≠nh v2.0:**

```mermaid
graph TB
    subgraph "v1.0 Vietnamese Natural Language Processing"
        A1["underthesea"] --> B1["pyvi (backup)"]
        B1 --> C1["Manual fallback"]
    end
    
    subgraph "v2.0 Vietnamese Natural Language Processing ‚≠ê"
        A2["Tier 1: underthesea<br/>State-of-the-art accuracy"] -->|fail| B2["Tier 2: pyvi<br/>Lighter weight, faster"]
        B2 -->|fail| C2["Tier 3: Whitespace split ‚≠êNEW<br/>Basic but always works"]
        
        D2["Legal Entity NER ‚≠êNEW<br/>Expanded patterns"]
        E2["Vietnamese Prompt Injection ‚≠êNEW<br/>Detection patterns"]
    end
```

### 6.2. Vietnamese Text Processing Pipeline v2.0 ‚Äî 3-Tier Fallback ‚≠ê

```python
class VietnameseNLPService:
    """
    v2.0: 3-tier fallback tokenization.
    ƒê·∫£m b·∫£o tokenization failure rate ‚Üí 0%.
    """
    
    def tokenize(self, text: str) -> str:
        """
        3-tier fallback word segmentation.
        
        Tier 1: underthesea (best accuracy)
        Tier 2: pyvi (lighter, faster)
        Tier 3: whitespace split (always works)
        """
        # Tier 1: underthesea
        try:
            from underthesea import word_tokenize
            words = word_tokenize(text)
            if self._validate_tokenization(words, text):
                return " ".join(words)
        except Exception as e:
            logger.warning(f"underthesea failed: {e}")
        
        # Tier 2: pyvi
        try:
            from pyvi import ViTokenizer
            result = ViTokenizer.tokenize(text)
            if result and len(result) > 0:
                return result
        except Exception as e:
            logger.warning(f"pyvi failed: {e}")
        
        # Tier 3: Basic whitespace split (always succeeds)
        logger.warning("Both NLP libraries failed ‚Äî using whitespace split")
        return text  # Return original text with natural word boundaries
    
    def _validate_tokenization(self, words: list, original: str) -> bool:
        """Validate tokenization didn't corrupt content."""
        if not words:
            return False
        rejoined = "".join(w.replace("_", " ") for w in words)
        # Character count should be similar (allow 10% tolerance)
        if abs(len(rejoined) - len(original.replace(" ", ""))) > len(original) * 0.1:
            return False
        return True
```

### 6.3. Legal Entity NER M·ªü r·ªông ‚≠ê NEW

```python
# v2.0: Expanded legal entity patterns
LEGAL_ENTITY_PATTERNS_V2 = {
    # v1.0 patterns (gi·ªØ nguy√™n)
    "nghi_dinh": r'\d+/\d{4}/Nƒê-CP',
    "quyet_dinh": r'\d+/\d{4}/Qƒê-TTg',
    "thong_tu": r'\d+/\d{4}/TT-[A-Z]+',
    "dieu": r'ƒêi·ªÅu\s+\d+',
    "khoan": r'Kho·∫£n\s+\d+',
    
    # v2.0 NEW patterns
    "nghi_quyet": r'\d+/\d{4}/NQ-(?:CP|QH)',           # Ngh·ªã quy·∫øt
    "chi_thi": r'\d+/\d{4}/CT-TTg',                     # Ch·ªâ th·ªã
    "cong_van": r'\d+/[A-Z]+-[A-Z]+',                   # C√¥ng vƒÉn
    "luat": r'Lu·∫≠t\s+(?:s·ªë\s+)?\d+/\d{4}/QH\d+',       # Lu·∫≠t
    
    # Organization entities
    "organization": r'(?:B·ªô|C·ª•c|V·ª•|S·ªü|UBND|HƒêND)\s+[A-Zƒê][a-z√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ]+',
    
    # Date patterns in Vietnamese legal docs
    "legal_date": r'ng√†y\s+\d{1,2}\s+th√°ng\s+\d{1,2}\s+nƒÉm\s+\d{4}',
    
    # Financial amounts
    "currency": r'\d[\d.,]*\s*(?:ƒë·ªìng|VNƒê|USD|tri·ªáu|t·ª∑)',
}
```

### 6.4. Vietnamese Prompt Injection Detection ‚≠ê NEW

```python
VIETNAMESE_INJECTION_PATTERNS = [
    # Direct instruction override
    r'(?i)b·ªè qua (?:h∆∞·ªõng d·∫´n|l·ªánh|ch·ªâ d·∫´n) (?:tr∆∞·ªõc ƒë√≥|·ªü tr√™n)',
    r'(?i)qu√™n (?:t·∫•t c·∫£|m·ªçi th·ª©) (?:ƒë√£ n√≥i|ƒë√£ h∆∞·ªõng d·∫´n)',
    r'(?i)b√¢y gi·ªù h√£y (?:l√†m|th·ª±c hi·ªán) (?:nh∆∞ sau|ƒëi·ªÅu n√†y)',
    
    # Role manipulation
    r'(?i)b·∫°n (?:b√¢y gi·ªù l√†|h√£y ƒë√≥ng vai|gi·∫£ v·ªù l√†)',
    r'(?i)t·ª´ gi·ªù b·∫°n s·∫Ω (?:l√†|ho·∫°t ƒë·ªông nh∆∞)',
    
    # System prompt extraction
    r'(?i)(?:cho t√¥i|hi·ªÉn th·ªã|in ra) (?:system prompt|h∆∞·ªõng d·∫´n h·ªá th·ªëng)',
    r'(?i)(?:n·ªôi dung|text) (?:tr∆∞·ªõc|ph√≠a tr√™n) (?:c√¢u h·ªèi|tin nh·∫Øn) n√†y',
]
```

### 6.5. Common Pitfalls v√† Lessons Learned (C·∫≠p nh·∫≠t)

> **Ghi ch√∫:** 3 pitfalls t·ª´ v1.0 gi·ªØ nguy√™n (BM25 fails on legal codes, Tone mark duplicates, Chunking breaks hierarchy). B·ªï sung th√™m:

**Pitfall 4 (v2.0): Graph Links Kh√¥ng T·ª± ƒê·ªông ‚≠ê**

```python
# WRONG: Assume graph auto-updates
upload_document(new_doc)  # Document added to PostgreSQL + ChromaDB
# ‚Üí graph_documents: NOT updated
# ‚Üí graph_edges: NOT updated
# ‚Üí New document is INVISIBLE to Graph RAG!

# CORRECT: Manual sync required
upload_document(new_doc)
sync_document_to_graph(new_doc.document_id)     # Step 2
create_semantic_links()                           # Step 3
validate_graph_links()                            # Step 4 (optional)
```

**Pitfall 5 (v2.0): Reranker VRAM Conflict ‚≠ê**

```python
# WRONG: Load embedding + reranker simultaneously with large batch
embedding_model = load("Qwen3-4B")     # ~8GB VRAM
reranker = load("bge-reranker-v2-m3")  # ~2GB VRAM
# Total: 10GB ‚Äî barely fits RTX 2080 Ti (11GB)!
# Large batch may cause OOM

# CORRECT: Manage VRAM carefully
embedding_model = load("Qwen3-4B", device='cuda')  # 8GB
reranker = load("bge-reranker-v2-m3", device='cuda')  # 2GB
# Use batch_size=8 for embedding, batch_size=16 for reranker
# Total ~10GB ‚Äî leaves 1GB headroom
```

---

## 7. AN NINH V√Ä B·∫¢O M·∫¨T

> **Ghi ch√∫ v2.0:** Ph·∫ßn n√†y gi·ªØ nguy√™n n·ªôi dung v1.0 (Authentication, 5-Tier RBAC, Data Protection, Audit Logging, AI-Specific Security). Xem chi ti·∫øt trong v1.0 ¬ß7.1‚Äì¬ß7.6. D∆∞·ªõi ƒë√¢y ch·ªâ tr√¨nh b√†y **b·ªï sung v2.0**.

### 7.1. T·ªïng quan ‚Äî B·ªï sung v2.0

H·ªá th·ªëng ATTECH RAG v2.0 b·ªï sung:
1. **LiteLLM Security:** API key management cho multiple providers
2. **pgvector Access Control:** RBAC t√≠ch h·ª£p trong SQL queries
3. **Graph Access Control:** Permission filtering tr√™n graph traversal
4. **Vietnamese Prompt Injection:** Detection patterns m·ªü r·ªông (¬ß6.4)

### 7.2. LiteLLM Security Configuration ‚≠ê NEW

```yaml
# litellm_config.yaml ‚Äî Security section
litellm_settings:
  # API Key Management
  api_key_management:
    rotation_schedule: "monthly"
    storage: "environment_variables"  # Never in code/config files
    
  # Request Sanitization
  request_hooks:
    pre_call:
      - "validate_input_length"      # Max 32K tokens
      - "check_prompt_injection"      # Vietnamese + English patterns
      - "redact_pii"                  # Remove PII before sending to external LLM
    
  # Response Validation
  response_hooks:
    post_call:
      - "validate_grounding"          # Check answer grounded in context
      - "check_data_leakage"          # Ensure no unauthorized data in response
```

### 7.3. Graph Access Control ‚≠ê NEW

```python
async def graph_search_with_rbac(
    user_permissions: dict,
    seed_document_ids: list[str],
    max_hops: int = 2
) -> list[GraphResult]:
    """
    Graph traversal WITH permission filtering.
    Ch·ªâ tr·∫£ v·ªÅ documents m√† user c√≥ quy·ªÅn truy c·∫≠p.
    """
    results = await graph_search_v2(seed_document_ids, max_hops)
    
    # Filter by user permissions
    filtered = [
        r for r in results
        if check_document_access(
            r.source_document_id, 
            user_permissions["role"],
            user_permissions["department"]
        )
    ]
    
    return filtered
```

---

## 8. Y√äU C·∫¶U PHI CH·ª®C NƒÇNG (NFRs) v2.0

### 8.1. Performance Requirements ‚Äî C·∫≠p nh·∫≠t

| Metric | v1.0 Target | v2.0 Target | Ghi ch√∫ |
|--------|------------|------------|---------|
| **Search Response (p50)** | < 2s | < 2s | Gi·ªØ nguy√™n |
| **Search Response (p95)** | < 5s | < 5s | Gi·ªØ nguy√™n |
| **Reranking Latency** ‚≠ê | N/A | **< 400ms** | Cross-Encoder on GPU |
| **End-to-End (p95)** | < 60s | **< 45s** | LiteLLM caching gi√∫p gi·∫£m |
| **Graph Traversal** ‚≠ê | N/A | **< 200ms** | 2-hop max, indexed |
| **Cache Hit Latency** | < 100ms | < 100ms | Gi·ªØ nguy√™n |
| **Semantic Cache Hit** ‚≠ê | N/A | **< 50ms** | Redis + cosine sim |
| **RAGAS Eval (weekly)** ‚≠ê | N/A | **< 30 min** | 50 queries batch |

### 8.2. Resource Utilization v2.0

| Resource | v1.0 | v2.0 | Ghi ch√∫ |
|----------|------|------|---------|
| **GPU VRAM** | ~3GB (0.6B) | **~10GB** (4B + reranker) | Fit RTX 2080 Ti (11GB) |
| **CPU Usage (avg)** | < 70% | < 70% | Gi·ªØ nguy√™n |
| **Memory Usage** | < 80% | < 80% | Gi·ªØ nguy√™n |
| **Disk (PostgreSQL)** | ~5GB | **~8GB** (+ pgvector + graph) | Capacity OK |
| **Redis Memory** | ~500MB | **~1GB** (+ semantic cache) | C·∫ßn monitor |

### 8.3. Scalability Requirements (Gi·ªØ nguy√™n v1.0)

Xem v1.0 ¬ß8.2. Kh√¥ng thay ƒë·ªïi: 100 concurrent users, 1M+ documents target.

### 8.4. Availability & Reliability (Gi·ªØ nguy√™n v1.0)

Xem v1.0 ¬ß8.3. SLA 99.5% business hours, RTO < 4h, RPO < 24h.

**B·ªï sung Fallback v2.0:**

```python
FALLBACK_STRATEGIES_V2 = {
    # v1.0 strategies gi·ªØ nguy√™n
    "llm_failure": {
        "order": ["litellm_primary", "litellm_fallback", "cached_response", "error_message"],
        "timeout_per_provider": 30
    },
    
    # v2.0 NEW
    "reranker_failure": {
        "fallback_to": "hybrid_ranking_only",  # Skip reranking
        "message": "Using hybrid ranking (reranker unavailable)",
        "timeout": 2  # seconds
    },
    "graph_failure": {
        "fallback_to": "vector_bm25_only",
        "message": "Using vector + keyword search (graph unavailable)"
    },
    "pgvector_failure": {
        "fallback_to": "chromadb_search",
        "message": "Using ChromaDB (pgvector unavailable)"
    },
    "embedding_upgrade_failure": {
        "fallback_to": "qwen3_0.6b",  # Rollback to v1 model
        "message": "Using Qwen3-0.6B (4B model unavailable)"
    }
}
```

### 8.5. Monitoring & Observability v2.0 ‚Äî C·∫≠p nh·∫≠t Dashboards

**Dashboard 1: System Health (gi·ªØ nguy√™n v1.0)**

**Dashboard 2: RAG Quality v2.0 ‚≠ê UPGRADED**
```
Panels:
- RAGAS Faithfulness (time series, weekly)          ‚≠ê NEW
- RAGAS Context Precision (time series, weekly)     ‚≠ê NEW
- nDCG@10 trend (with/without reranker comparison)  ‚≠ê NEW
- Reranker latency p50/p95                          ‚≠ê NEW
- Graph traversal latency                           ‚≠ê NEW
- User satisfaction score (gauge)
- Search success rate (percentage)
- Citation accuracy (percentage)
```

**Dashboard 3: LiteLLM Gateway ‚≠ê NEW**
```
Panels:
- Token usage by provider (stacked area)
- Semantic cache hit rate (gauge)
- Provider latency comparison (box plot)
- Failover events (event log)
- Cost per query by provider (line chart)
- Error rate by provider (bar chart)
```

---

## 9. KI·ªÇM TH·ª¨ V√Ä NGHI·ªÜM THU v2.0

### 9.1. Test Strategy ‚Äî C·∫≠p nh·∫≠t

> **Ghi ch√∫:** Gi·ªØ nguy√™n 4 test levels t·ª´ v1.0 (Unit, Integration, Performance, Security). B·ªï sung **Artificial Intelligence-Specific Testing v2.0** v√† **Continuous Evaluation**.

#### 9.1.1. Test Levels (Gi·ªØ nguy√™n v1.0)
- **Level 1:** Unit Testing (80% coverage, pytest)
- **Level 2:** Integration Testing (API, DB, LLM mocked)
- **Level 3:** Performance Testing (load, stress)
- **Level 4:** Security Testing (auth, authz, pentest)

#### 9.1.2. v2.0 Additions

| Level | T√™n | C√¥ng c·ª• | T·∫ßn su·∫•t | M·ª•c ti√™u |
|-------|-----|---------|---------|----------|
| **Level 5** ‚≠ê | RAGAS Evaluation | RAGAS framework | H√†ng tu·∫ßn | Faithfulness > 0.90 |
| **Level 6** ‚≠ê | Embedding Benchmark | VN-MTEB | Khi upgrade model | nDCG@10 baseline |
| **Level 7** ‚≠ê | Reranker A/B Test | Custom script | Khi thay ƒë·ªïi reranker | +30% nDCG improvement |
| **Level 8** ‚≠ê | Graph Validation | validate_graph_links.py | Sau m·ªói import | 0 isolated nodes |

### 9.2. Artificial Intelligence-Specific Testing v2.0

#### 9.2.1. Reranker Quality Testing ‚≠ê NEW

```python
class RerankerQualityTest:
    """Test Cross-Encoder Reranker effectiveness."""
    
    async def test_reranker_improvement(self, ground_truth_queries: list):
        """
        A/B test: v·ªõi v√† kh√¥ng c√≥ reranker.
        K·ª≥ v·ªçng: nDCG@10 improvement ‚â• 30%.
        """
        results_without_reranker = []
        results_with_reranker = []
        
        for query_data in ground_truth_queries:
            # Without reranker (v1.0 style)
            hybrid_results = await hybrid_search(query_data["query"], top_k=10)
            ndcg_without = compute_ndcg(hybrid_results, query_data["relevant_docs"])
            results_without_reranker.append(ndcg_without)
            
            # With reranker (v2.0)
            candidates = await hybrid_search(query_data["query"], top_k=100)
            reranked = await reranker.rerank(query_data["query"], candidates, top_k=10)
            ndcg_with = compute_ndcg(reranked, query_data["relevant_docs"])
            results_with_reranker.append(ndcg_with)
        
        avg_without = sum(results_without_reranker) / len(results_without_reranker)
        avg_with = sum(results_with_reranker) / len(results_with_reranker)
        improvement = (avg_with - avg_without) / avg_without * 100
        
        assert improvement >= 30, f"Reranker improvement {improvement:.1f}% < 30% target"
        return {"without": avg_without, "with": avg_with, "improvement_pct": improvement}
```

#### 9.2.2. Graph Retrieval-Augmented Generation Testing ‚≠ê NEW

```python
class GraphRAGTest:
    """Test Graph RAG integration quality."""
    
    async def test_graph_completeness(self):
        """Graph ph·∫£i 100% connected, 0 isolated nodes."""
        stats = await get_graph_stats()
        assert stats["isolated_nodes"] == 0, "Graph has isolated nodes!"
        assert stats["total_edges"] >= 500, f"Expected ‚â•500 edges, got {stats['total_edges']}"
        assert stats["total_documents"] == 42, f"Expected 42 docs, got {stats['total_documents']}"
    
    async def test_multi_hop_query(self):
        """Multi-hop queries ph·∫£i tr·∫£ v·ªÅ related documents."""
        # Query about a specific law
        results = await rag_pipeline.search("Ngh·ªã ƒë·ªãnh li√™n quan ƒë·∫øn qu·∫£n l√Ω bay")
        
        # Verify graph-enriched results include related documents
        graph_results = [r for r in results if r.source == "graph"]
        assert len(graph_results) > 0, "No graph results for multi-hop query"
    
    async def test_graph_sync_after_import(self):
        """New documents ph·∫£i ƒë∆∞·ª£c sync v√†o graph sau import."""
        # Import test document
        doc_id = await import_document(test_doc)
        
        # Verify graph sync
        graph_doc = await get_graph_document(doc_id)
        assert graph_doc is not None, "Document not synced to graph!"
```

#### 9.2.3. Vietnamese Language Testing (C·∫≠p nh·∫≠t)

```python
class VietnameseNLPTest:
    """v2.0: Test 3-tier fallback tokenization."""
    
    def test_3tier_fallback(self):
        """Tokenization ph·∫£i lu√¥n th√†nh c√¥ng qua 3 tiers."""
        test_cases = [
            "Ngh·ªã ƒë·ªãnh s·ªë 76/2018/Nƒê-CP",
            "H·ªá th·ªëng qu·∫£n l√Ω bay CNS/ATM",
            "ƒêi·ªÅu 5, Kho·∫£n 2, ƒêi·ªÉm a",
            "üîç emoji + Vietnamese text",  # Edge case
            "",  # Empty string
            "A" * 100000,  # Very long text
        ]
        
        nlp = VietnameseNLPService()
        for text in test_cases:
            result = nlp.tokenize(text)
            assert result is not None, f"Tokenization returned None for: {text[:50]}"
            # No exception should be raised for any input
```

### 9.3. Acceptance Criteria v2.0

#### 9.3.1. Functional Acceptance (Gi·ªØ nguy√™n v1.0)

#### 9.3.2. Non-Functional Acceptance (Gi·ªØ nguy√™n v1.0)

#### 9.3.3. Artificial Intelligence Performance Acceptance v2.0 ‚Äî C·∫≠p nh·∫≠t

| Metric | v1.0 Criteria | v2.0 Criteria | Checkpoint |
|--------|-------------|-------------|-----------|
| Retrieval nDCG@10 | > 0.85 | **> 0.90** | CP1 |
| Answer Faithfulness | > 85% | **> 90% (RAGAS)** | CP0 |
| Context Precision | N/A | **> 0.85 (RAGAS)** | CP0 |
| Reranker Improvement | N/A | **+30% nDCG** | CP0 |
| Graph Completeness | N/A | **‚â• 95%, 0 isolated** | CP1 |
| Response Time (p95) | < 60s | **< 45s** | CP2 |
| 3-tier Tokenization | N/A | **0% failure rate** | CP2 |

---

## 10. TRI·ªÇN KHAI V√Ä V·∫¨N H√ÄNH v2.0

### 10.1. Infrastructure Requirements ‚Äî C·∫≠p nh·∫≠t th·ª±c t·∫ø

**Production Setup (Th·ª±c t·∫ø, C·∫≠p nh·∫≠t 02/2026):**

```mermaid
graph LR
    subgraph "Server .70 ‚Äî Debian (13 services)"
        PG["PostgreSQL 15<br/>+ pgvector ‚≠ê<br/>Port 15432"]
        CH["ChromaDB 1.0.0<br/>Port 8000"]
        RD["Redis 7<br/>Port 6379"]
        API70["FastAPI Backend<br/>Port 8000"]
        ST["Streamlit UI<br/>Port 8501"]
        PROM["Prometheus<br/>Port 9090"]
        GRAF["Grafana<br/>Port 3000"]
        LOKI["Loki<br/>Port 3100"]
        LITELLM["LiteLLM Proxy ‚≠ê<br/>Port 4000"]
        EVAL["RAGAS Evaluator ‚≠ê<br/>Cron weekly"]
    end
    
    subgraph "Server .88 ‚Äî DietPi / GPU (12 services)"
        EMB["Qwen3-Embedding-4B ‚≠ê<br/>GPU-accelerated"]
        RERANK["Cross-Encoder ‚≠ê<br/>bge-reranker-v2-m3"]
        ING["Data Ingestion<br/>FR-03.3 Pipeline"]
    end
    
    API70 <-->|"Internal network"| PG
    API70 <-->|"Internal network"| CH
    API70 <-->|"Internal network"| RD
    API70 <-->|"HTTP"| EMB
    API70 <-->|"HTTP"| RERANK
    API70 <-->|"HTTP"| LITELLM
```

**Server .70 ‚Äî Debian (Application + Data):**
```yaml
Role: API backend, UI, databases, monitoring, LLM gateway
IP: 192.168.1.70
Services: 13 containers (Docker Compose)
Key ports:
  - 15432: PostgreSQL (+ pgvector)
  - 8000: ChromaDB / FastAPI  
  - 6379: Redis
  - 8501: Streamlit UI
  - 4000: LiteLLM Proxy (NEW)
  - 9090: Prometheus
  - 3000: Grafana
  - 3100: Loki
```

**Server .88 ‚Äî DietPi (GPU Processing):**
```yaml
Role: Embedding generation, reranking, data ingestion
IP: 192.168.1.88
GPU: NVIDIA RTX 2080 Ti (11GB VRAM)
CUDA: 11.8
PyTorch: 2.7.1+cu118
Services: 12 containers
Key services:
  - Qwen3-Embedding-4B service (8GB VRAM)
  - bge-reranker-v2-m3 service (2GB VRAM)
  - Data ingestion pipeline (FR-03.3)
```

### 10.2. Deployment Strategy v2.0

#### 10.2.1. Docker Compose Configuration v2.0

```yaml
# docker-compose.v2.yml ‚Äî Additions for v2.0
services:
  # --- v2.0 NEW services ---
  
  litellm-proxy:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "4000:4000"
    volumes:
      - ./litellm_config.yaml:/app/config.yaml
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
    restart: always
    
  reranker-service:
    build: ./services/reranker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - MODEL_NAME=BAAI/bge-reranker-v2-m3
      - DEVICE=cuda
      - MAX_LENGTH=512
      - BATCH_SIZE=16
    ports:
      - "8002:8002"
    restart: always
  
  ragas-evaluator:
    build: ./services/evaluator
    environment:
      - DATABASE_URL=postgresql://kb_admin:${DB_PASSWORD}@postgres:15432/chatbotR4
      - RAGAS_EVAL_SCHEDULE=0 2 * * 0  # Every Sunday 2AM
      - SAMPLE_SIZE=50
    depends_on:
      - postgres
      - fastapi
    restart: always
    
  # PostgreSQL with pgvector extension
  postgres:
    image: pgvector/pgvector:pg15
    # ... (replaces standard postgres image)
```

#### 10.2.2. Migration Plan v1.0 ‚Üí v2.0

```mermaid
graph TD
    subgraph "Phase A: Foundation (Week 1)"
        A1["Install pgvector extension<br/>CREATE EXTENSION vector"]
        A2["Deploy graph tables<br/>(already done 29/12/2025)"]
        A3["Create evaluation_results table"]
        A4["Setup LiteLLM Proxy container"]
    end
    
    subgraph "Phase B: Reranker (Week 2)"
        B1["Deploy reranker service<br/>bge-reranker-v2-m3"]
        B2["Run A/B test vs hybrid only"]
        B3["Verify +30% nDCG improvement"]
        B4["Enable reranker in production"]
    end
    
    subgraph "Phase C: Embedding Upgrade (Weeks 3-4)"
        C1["Download Qwen3-Embedding-4B"]
        C2["Benchmark vs 0.6B on ground truth"]
        C3["Re-embed all 42 documents"]
        C4["Create knowledge_base_v2 collection"]
        C5["Populate pgvector table"]
        C6["Switch traffic with rollback plan"]
    end
    
    subgraph "Phase D: Graph + Eval (Weeks 5-6)"
        D1["Populate graph (create_semantic_links.py)"]
        D2["Deploy graph search API endpoint"]
        D3["Setup RAGAS weekly pipeline"]
        D4["Create Grafana dashboards"]
        D5["Run first baseline evaluation"]
    end
    
    A1 --> A2 --> A3 --> A4
    A4 --> B1 --> B2 --> B3 --> B4
    B4 --> C1 --> C2 --> C3 --> C4 --> C5 --> C6
    C6 --> D1 --> D2 --> D3 --> D4 --> D5
```

### 10.3. Operational Procedures (C·∫≠p nh·∫≠t)

#### 10.3.1. Backup & Recovery (Gi·ªØ nguy√™n v1.0 + b·ªï sung)

**B·ªï sung v2.0:**
```yaml
# Graph data backup
Graph Tables:
  Full Backup: Daily at 2:30AM (after PostgreSQL backup)
  Retention: 30 days
  
# pgvector data backup
pgvector Embeddings:
  Full Backup: Weekly (vectors can be regenerated)
  Retention: 4 weeks
  
# Evaluation results
Evaluation Data:
  Backup: With PostgreSQL daily backup
  Retention: Permanent (historical metrics)
  
# LiteLLM config
LiteLLM Config:
  Backup: Git repository
  Encryption: Yes (API keys)
```

#### 10.3.2. Maintenance Checklist v2.0 ‚Äî B·ªï sung

```
B·ªï sung cho monthly maintenance:
- [ ] Verify graph integrity (validate_graph_links.py)
- [ ] Check RAGAS metric trends (kh√¥ng gi·∫£m > 5%)
- [ ] Review LiteLLM cost tracking
- [ ] Verify reranker VRAM usage < 90%
- [ ] Check pgvector index health (REINDEX n·∫øu c·∫ßn)
- [ ] Review semantic cache hit rate (target > 70%)
- [ ] Rotate LLM API keys n·∫øu ƒë·∫øn h·∫°n
```

---

## 11. L·ªò TR√åNH N√ÇNG C·∫§P K·ª∏ THU·∫¨T

> **Ghi ch√∫:** M·ª•c n√†y thay th·∫ø m·ª•c "∆Ø·ªõc t√≠nh Chi ph√≠" trong v1.0 theo y√™u c·∫ßu t·∫≠p trung k·ªπ thu·∫≠t.

### 11.1. T·ªïng quan L·ªô tr√¨nh

```mermaid
gantt
    title L·ªô tr√¨nh N√¢ng c·∫•p K·ªπ thu·∫≠t v2.0
    dateFormat  YYYY-MM-DD
    
    section üî¥ P0 - Immediate
    Cross-Encoder Reranker        :crit, p0a, 2026-02-10, 14d
    RAGAS Evaluation Pipeline     :crit, p0b, 2026-02-10, 14d
    VN-MTEB Benchmark Baseline    :p0c, 2026-02-17, 7d
    CP0 Checkpoint                :milestone, cp0, 2026-02-24, 0d
    
    section üü° P1 - Phase 2 Start
    Graph RAG Population          :p1a, 2026-02-24, 14d
    Embedding Upgrade 0.6B‚Üí4B    :p1b, 2026-02-24, 21d
    Graph Search API              :p1c, 2026-03-03, 14d
    Hybrid Scoring 3-way         :p1d, 2026-03-10, 7d
    CP1 Checkpoint                :milestone, cp1, 2026-03-17, 0d
    
    section üü¢ P2 - Phase 2 Mid
    pgvector Installation         :p2a, 2026-03-17, 14d
    LiteLLM Gateway              :p2b, 2026-03-17, 14d
    Vietnamese NLP 3-tier        :p2c, 2026-03-24, 7d
    CP2 Checkpoint                :milestone, cp2, 2026-04-07, 0d
    
    section üîµ P3 - Phase 3
    Agentic RAG (LangGraph)       :p3a, 2026-04-07, 28d
    Dual Embedding Strategy       :p3b, 2026-04-14, 21d
    Continuous Eval Pipeline      :p3c, 2026-04-21, 14d
    CP3 Checkpoint                :milestone, cp3, 2026-05-05, 0d
```

### 11.2. Chi ti·∫øt t·ª´ng Phase

#### üî¥ P0 ‚Äî Immediate (Tu·∫ßn 1-2, Target: 24/02/2026)

| Task | M√¥ t·∫£ | Output | Metric th√†nh c√¥ng |
|------|--------|--------|-------------------|
| T√≠ch h·ª£p Cross-Encoder | Deploy bge-reranker-v2-m3 ho·∫∑c Qwen3-Reranker l√™n GPU server .88 | Reranker service ch·∫°y ·ªïn ƒë·ªãnh | nDCG@10 tƒÉng ‚â• 30% vs baseline |
| RAGAS Pipeline Setup | C√†i ƒë·∫∑t RAGAS, k·∫øt n·ªëi ground truth dataset, ch·∫°y evaluation ƒë·∫ßu ti√™n | Baseline metrics collected | Faithfulness, Relevance, Precision scores |
| VN-MTEB Benchmark | Ch·∫°y benchmark Qwen3-0.6B tr√™n VN-MTEB tasks | Baseline embedding quality | Scores documented |

**CP0 Checkpoint Criteria:**
- ‚úÖ Reranker improvement ‚â• 30% nDCG@10
- ‚úÖ RAGAS baseline scores collected
- ‚úÖ VN-MTEB baseline documented

#### üü° P1 ‚Äî Phase 2 Start (Tu·∫ßn 3-6, Target: 17/03/2026)

| Task | M√¥ t·∫£ | Output | Metric th√†nh c√¥ng |
|------|--------|--------|-------------------|
| Graph RAG Population | Ch·∫°y `populate_graph_correct.py` + `create_semantic_links.py` | 42 docs, 507+ edges, 0 isolated nodes | Graph completeness ‚â• 95% |
| Embedding Upgrade | Qwen3-0.6B ‚Üí 4B: benchmark, re-embed, migrate collection | knowledge_base_v2 collection | nDCG@10 ‚â• 0.85 (ho·∫∑c +15% vs 0.6B) |
| Graph Search API | Implement `/api/v1/graph/search` endpoint | API endpoint operational | Multi-hop query tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá |
| Hybrid Scoring 3-way | Update scoring formula: Œ±√ósem + Œ≤√ókw + Œ≥√ógraph | Adaptive weights by intent | Scoring formula active |

**CP1 Checkpoint Criteria:**
- ‚úÖ Graph populated (‚â• 500 edges, 0 isolated nodes)
- ‚úÖ Embedding upgraded, overall accuracy ‚â• 80%
- ‚úÖ Graph search API returns valid results
- ‚úÖ 3-way hybrid scoring active

#### üü¢ P2 ‚Äî Phase 2 Mid (Tu·∫ßn 7-10, Target: 07/04/2026)

| Task | M√¥ t·∫£ | Output | Metric th√†nh c√¥ng |
|------|--------|--------|-------------------|
| pgvector Installation | C√†i extension, migrate embedding data, benchmark | pgvector operational | Query parity v·ªõi ChromaDB |
| LiteLLM Gateway | Deploy proxy, configure providers, enable caching | LiteLLM proxy on port 4000 | Failover < 5s, cache hit > 40% |
| Vietnamese NLP 3-tier | Implement 3-tier fallback tokenization | VietnameseNLPService v2 | Tokenization failure rate = 0% |

**CP2 Checkpoint Criteria:**
- ‚úÖ pgvector queries c√≥ k·∫øt qu·∫£ t∆∞∆°ng ƒë∆∞∆°ng ChromaDB
- ‚úÖ LiteLLM failover < 5s
- ‚úÖ Tokenization failure rate = 0%

#### üîµ P3 ‚Äî Phase 3 (Tu·∫ßn 11-14, Target: 05/05/2026)

| Task | M√¥ t·∫£ | Output | Metric th√†nh c√¥ng |
|------|--------|--------|-------------------|
| Agentic RAG | LangGraph multi-agent cho complex queries | Multi-agent pipeline | Complex queries handled correctly |
| Dual Embedding | Th√™m vietnamese-document-embedding cho VN-specific | Dual model routing | VN-specific nDCG improvement |
| Continuous Eval | Automated weekly RAGAS runs + alerts | Grafana dashboard + alerts | Weekly runs, alerts active |

**CP3 Checkpoint Criteria:**
- ‚úÖ Agentic RAG handles complex multi-hop queries
- ‚úÖ Dual embedding shows VN improvement
- ‚úÖ Continuous evaluation runs weekly with alerting

### 11.3. R·ªßi ro v√† Gi·∫£m thi·ªÉu

| R·ªßi ro | M·ª©c ƒë·ªô | Gi·∫£m thi·ªÉu |
|--------|--------|-----------|
| Qwen3-4B kh√¥ng fit VRAM c√πng Reranker | Trung b√¨nh | Ch·∫°y tu·∫ßn t·ª± (load/unload), ho·∫∑c gi·ªØ 0.6B |
| Graph links stale sau import | Cao | Cron job `create_semantic_links.py` h√†ng ƒë√™m |
| RAGAS evaluation ch·∫≠m | Th·∫•p | Sample 50 queries thay v√¨ to√†n b·ªô |
| LiteLLM proxy single point of failure | Trung b√¨nh | Fallback direct API calls n·∫øu proxy down |
| pgvector migration data loss | Th·∫•p | Gi·ªØ ChromaDB song song, kh√¥ng x√≥a |

---

## 12. MA TR·∫¨N ƒê√ÅP ·ª®NG Y√äU C·∫¶U (COMPLIANCE MATRIX) v2.0

| ID | Requirement | v1.0 Status | v2.0 Status | Evidence |
|----|-------------|------------|------------|----------|
| **FR-01** | Embedding Model Selection | ‚úÖ 0.6B deployed | ‚¨ÜÔ∏è **Upgrading to 4B** | Benchmark + migration plan |
| **FR-02** | Dual Database System | ‚úÖ PG + ChromaDB | ‚¨ÜÔ∏è **+ pgvector + Graph** | 6 graph tables deployed |
| **FR-03** | Data Ingestion Pipeline | ‚úÖ Operational | ‚¨ÜÔ∏è **+ 3-tier NLP + graph sync** | VietnameseNLPService v2 |
| **FR-04.1** | Retrieval Engine | ‚úÖ Hybrid 2-way | ‚¨ÜÔ∏è **Hybrid 3-way + Reranker** | Cross-Encoder integrated |
| **FR-04.2** | Synthesis Module | ‚úÖ Context assembly | ‚¨ÜÔ∏è **+ Graph context injection** | Hierarchy + graph context |
| **FR-04.3** | Generation Engine | ‚úÖ Multi-provider | ‚¨ÜÔ∏è **LiteLLM Gateway** | Semantic caching + failover |
| **FR-04.4** | API Endpoint | ‚úÖ /api/v1/query | ‚¨ÜÔ∏è **+ /api/v1/graph/search** | Graph search API |
| **FR-05.1** | Chat UI | ‚úÖ Streamlit | ‚¨ÜÔ∏è **+ Graph explorer** | Graph visualization |
| **FR-06** | Authentication & Authorization | ‚úÖ 5-tier RBAC | ‚¨ÜÔ∏è **+ Graph access control** | RBAC on graph traversal |
| **FR-07** | Analytics & Reporting | ‚úÖ Dashboards | ‚¨ÜÔ∏è **+ RAGAS metrics** | Quality dashboards |
| **FR-08** | Admin Tools | ‚úÖ User/Doc mgmt | ‚¨ÜÔ∏è **+ Graph mgmt** | Graph admin panel |
| **RERANK-001** ‚≠ê | Cross-Encoder Reranking | ‚ùå Not implemented | üîÑ **P0 ‚Äî Implementing** | bge-reranker-v2-m3 |
| **GRAPH-001** ‚≠ê | Graph RAG Operational | ‚è≥ Schema only | üîÑ **P1 ‚Äî Populating** | 507 edges, 42 docs |
| **EVAL-001** ‚≠ê | Automated Evaluation | ‚ùå Manual only | üîÑ **P0 ‚Äî Setting up** | RAGAS pipeline |
| **GATEWAY-001** ‚≠ê | LLM Gateway | ‚ùå Custom router | üîÑ **P2 ‚Äî Integrating** | LiteLLM config |
| **PGVEC-001** ‚≠ê | pgvector Integration | ‚ùå Not implemented | üîÑ **P2 ‚Äî Installing** | Extension + migration |

**Legend:**
- ‚úÖ Fully Met | ‚¨ÜÔ∏è Upgrading | üîÑ In Progress | ‚è≥ Pending | ‚ùå Not Met

---

## 13. PH·ª§ L·ª§C

### 13.1. Glossary v2.0 ‚Äî B·ªï sung

| Thu·∫≠t ng·ªØ | ƒê·ªãnh nghƒ©a |
|-----------|-----------|
| **Cross-Encoder** | M√¥ h√¨nh ch·∫•m ƒëi·ªÉm (query, document) c√πng l√∫c cho relevance score ch√≠nh x√°c h∆°n Bi-Encoder |
| **Bi-Encoder** | M√¥ h√¨nh encode query v√† document RI√äNG th√†nh vectors, d√πng cosine similarity ƒë·ªÉ so s√°nh |
| **RAGAS** | Retrieval Augmented Generation Assessment ‚Äî framework ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng RAG t·ª± ƒë·ªông |
| **VN-MTEB** | Vietnamese Massive Text Embedding Benchmark ‚Äî 41 datasets, 6 tasks cho ƒë√°nh gi√° embedding |
| **pgvector** | PostgreSQL extension cho vector similarity search |
| **LiteLLM** | Proxy server th·ªëng nh·∫•t 100+ Large Language Model providers qua OpenAI-compatible API |
| **Semantic Cache** | Cache d·ª±a tr√™n semantic similarity (kh√¥ng ch·ªâ exact match) |
| **Graph Traversal** | Duy·ªát ƒë·ªì th·ªã theo c√°c c·∫°nh (edges) ƒë·ªÉ t√¨m t√†i li·ªáu li√™n quan |
| **nDCG@10** | Normalized Discounted Cumulative Gain t·∫°i top 10 ‚Äî metric ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ranking |
| **Matryoshka Embedding** | K·ªπ thu·∫≠t cho ph√©p s·ª≠ d·ª•ng embeddings ·ªü nhi·ªÅu chi·ªÅu kh√°c nhau |
| **Agentic RAG** | Ki·∫øn tr√∫c RAG v·ªõi Large Language Model-powered agents t·ª± l√™n k·∫ø ho·∫°ch truy v·∫•n |
| **LangGraph** | Framework cho multi-agent orchestration d·ª±a tr√™n state machine |
| **(C√°c thu·∫≠t ng·ªØ v1.0)** | Xem v1.0 ¬ß13.1 |

### 13.2. Technology Stack v2.0 ‚Äî T·ªïng h·ª£p

| Layer | Component | Version | Gi·∫•y ph√©p | v2.0 Change |
|-------|-----------|---------|-----------|-------------|
| **Runtime** | Python | 3.10.11 | PSF | Gi·ªØ nguy√™n |
| **Framework** | FastAPI | 0.115.9 | MIT | Gi·ªØ nguy√™n |
| **UI** | Streamlit | latest | Apache 2.0 | Gi·ªØ nguy√™n |
| **Embedding** | Qwen3-Embedding | **4B** | Apache 2.0 | ‚¨ÜÔ∏è 0.6B‚Üí4B |
| **Reranker** | bge-reranker-v2-m3 | latest | MIT | ‚≠ê NEW |
| **Vector DB** | ChromaDB | 1.0.0 | Apache 2.0 | Gi·ªØ nguy√™n |
| **Vector Ext** | pgvector | 0.7+ | PostgreSQL | ‚≠ê NEW |
| **Relational DB** | PostgreSQL | 15 | PostgreSQL | Gi·ªØ nguy√™n |
| **Cache** | Redis | 7 | BSD | Gi·ªØ nguy√™n |
| **LLM Gateway** | LiteLLM | latest | MIT | ‚≠ê NEW |
| **GPU** | PyTorch | 2.7.1+cu118 | BSD | Gi·ªØ nguy√™n |
| **GPU Hardware** | NVIDIA RTX 2080 Ti | 11GB VRAM | ‚Äî | Gi·ªØ nguy√™n |
| **Evaluation** | RAGAS | latest | Apache 2.0 | ‚≠ê NEW |
| **Vietnamese NLP** | underthesea + pyvi | latest | MIT/GPL | Gi·ªØ nguy√™n |
| **Monitoring** | Prometheus + Grafana | latest | Apache 2.0 | Gi·ªØ nguy√™n |
| **Logging** | Loki | latest | AGPLv3 | Gi·ªØ nguy√™n |
| **Container** | Docker + Compose | latest | Apache 2.0 | Gi·ªØ nguy√™n |

### 13.3. Open Questions & Decisions v2.0

**ƒê√£ gi·∫£i quy·∫øt (t·ª´ v1.0):**
- [x] Graph database choice ‚Üí PostgreSQL graph tables (kh√¥ng c·∫ßn Neo4j)
- [x] Reranker model ‚Üí bge-reranker-v2-m3 ho·∫∑c Qwen3-Reranker
- [x] LLM Gateway ‚Üí LiteLLM (thay v√¨ custom router)
- [x] Evaluation framework ‚Üí RAGAS (thay v√¨ manual only)

**C√≤n m·ªü:**
- [ ] Qwen3-4B VRAM co-location: Ch·∫°y song song hay tu·∫ßn t·ª± v·ªõi reranker?
- [ ] Graph auto-linking: Implement cron job hay trigger-based?
- [ ] pgvector vs ChromaDB: Phase out ChromaDB hay gi·ªØ song song?
- [ ] Agentic RAG scope: Bao nhi√™u agent types cho Phase 3?
- [ ] SSO integration timeline v·ªõi corporate LDAP/AD?
- [ ] Mobile Progressive Web App priority?

### 13.4. References v2.0

**Technology References:**
- Qwen3-Embedding-4B: https://huggingface.co/Qwen/Qwen3-Embedding-4B
- bge-reranker-v2-m3: https://huggingface.co/BAAI/bge-reranker-v2-m3
- Qwen3-Reranker: https://huggingface.co/Qwen/Qwen3-Reranker-0.6B
- pgvector: https://github.com/pgvector/pgvector
- LiteLLM: https://docs.litellm.ai/
- RAGAS: https://docs.ragas.io/
- VN-MTEB: https://huggingface.co/spaces/mteb/leaderboard
- vietnamese-document-embedding: https://huggingface.co/dangvantuan/vietnamese-document-embedding
- LangGraph: https://langchain-ai.github.io/langgraph/

**Project Documents:**
- v1.0 Technical Specification: ATTECH_RAG_Technical_Specification_v1_0_Complete.md
- Technology Survey Report: CAP_NHAT_CONG_NGHE_RAG_2026.md
- FR-01 ƒë·∫øn FR-08 Handover Documents: Xem project knowledge
- Graph RAG Summary: GRAPH_RAG_SUMMARY.md
- Graph RAG User Manual: user_manual_graph_rag.md
- Database Backup Schema: backup_schema_31Dec.sql

---

## DOCUMENT APPROVAL

| Vai tr√≤ | T√™n | Ch·ªØ k√Ω | Ng√†y |
|---------|-----|--------|------|
| **Technical Lead** | Tuan | ___________________ | ___________ |
| **Product Owner** | IT Department Manager | ___________________ | ___________ |
| **Sponsor** | Board of Directors Representative | ___________________ | ___________ |

---

**END OF DOCUMENT v2.0**

**Document Statistics:**
- **Phi√™n b·∫£n:** 2.0 (n√¢ng c·∫•p t·ª´ v1.0)
- **T·∫≠p trung:** K·ªπ thu·∫≠t thu·∫ßn t√∫y (ƒë√£ lo·∫°i b·ªè m·ª•c Chi ph√≠)
- **Thay ƒë·ªïi ch√≠nh:** 10 n√¢ng c·∫•p k·ªπ thu·∫≠t (xem b·∫£ng ƒë·∫ßu document)
- **T·ªïng Sections:** 13 sections ch√≠nh
- **Mermaid Diagrams:** 15+ diagrams
- **Code Examples:** 25+ code blocks
- **Tables:** 40+ tables

**Document History:**
- Version 1.0 (29/01/2026): Initial comprehensive specification (FR-01 ‚Üí FR-08)
- Version 2.0 (07/02/2026): Technical upgrade based on 2026 RAG technology survey ‚Äî Reranking, Graph RAG, RAGAS, pgvector, LiteLLM, Embedding upgrade, Vietnamese NLP improvements

---

**For questions or clarifications, contact:**
- Technical Lead (Tuan): [email]
- Product Owner: [email]
